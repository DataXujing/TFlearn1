{
    "docs": [
        {
            "location": "/",
            "text": "Welcome to TensorFlow Learning Base 1\n\n\nMore learning: XuJing'Home \nhttps://dataxujing.coding.me/\n\n\n\n\n\n\nTensorFlow\uff08\u4e0b\u9762\u7b80\u79f0TF)\u662fGoogle\u4e8e2015\u5e7411\u67089\u65e5\u6b63\u5f0f\u5f00\u6e90\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\n\n\n\n\n\n\n\n\n\u524d\u4e24\u5929\u7684Google\u5f00\u53d1\u8005\u5927\u4f1a\u5728\u4e0a\u6d77\u4e3e\u529e\uff0c\u4f1a\u4e0a\u5ba3\u5e03\uff0cTensorFlow \u5fae\u4fe1\u516c\u4f17\u53f7\u6b63\u5f0f\u53d1\u5e03\uff01\u5c06\u4e3a\u4e2d\u56fd\u5f00\u53d1\u8005\u63d0\u4f9b\u6700\u65b0\u7684 TensorFlow \u65b0\u95fb\u3001\u5b9e\u7528\u7684\u6280\u672f\u8d44\u6e90\u3001\u672a\u6765\u5c55\u671b\u4ee5\u53ca\u7ebf\u4e0b\u7684\u6d3b\u52a8\u4fe1\u606f\uff0c\u8ba9\u4e2d\u56fd\u7684\u5f00\u53d1\u8005\u4eec\u80fd\u591f\u66f4\u4fbf\u6377\u5730\u4f7f\u7528 TensorFlow \u6253\u9020\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u3002\n\n\n\n\n\n\n\u56fe1\uff1aTensorFlow\u5fae\u4fe1\u516c\u4f17\u53f7\n\n\n\n\n\n\nTF\u8ba1\u7b97\u6846\u67b6\u53ef\u4ee5\u5f88\u597d\u7684\u652f\u6301\u6df1\u5ea6\u5b66\u4e60\u7684\u5404\u79cd\u7b97\u6cd5\uff0c\u4f46\u5176\u5e94\u7528\u4e5f\u4e0d\u5c40\u9650\u4e8e\u6df1\u5ea6\u5b66\u4e60\uff08\u672c\u6559\u7a0b\u4f1a\u5ffd\u7565\u6389\u5bf9\u5176\u4ed6\u7b97\u6cd5\u7684\u652f\u6301\uff09\n\n\n\n\n\n\n\n\nTF\u662fJeff Dean\u9886\u5934\u7684Google Brain\u56e2\u961f\u57fa\u4e8eGoogle\u7684\u5185\u90e8\u7b2c\u4e00\u4ee3\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edfDistBelief\uff082011\u5e74\uff09\u6539\u8fdb\u800c\u6765\u7684\u901a\u7528\u8ba1\u7b97\u6846\u67b6\n\n\n\n\n\n\n\n\nDistBelief\u7684\u4e1a\u7ee9\uff1aInmageNet2014\u51a0\u519b\uff0c\u5728\u6d77\u91cf\u7684\u975e\u6807\u6ce8\u7684YouTube\u89c6\u5c4f\u4e2d\u4e60\u5f97\u4e86\u2018\u732b\u2019\u7684\u6982\u5ff5\uff0c\u5e76\u5728Google\u56fe\u7247\u4e2d\u5f00\u521b\u4e86\u56fe\u7247\u641c\u7d22\u7684\u529f\u80fd\uff0c\u4f7f\u7528DistBelief\u6846\u67b6\u8bad\u7ec3\u7684\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\u6210\u529f\u5c06\u8bc6\u522b\u7684\u9519\u8bef\u7387\u964d\u4f4e\u4e8625%\uff08\u8fd9\u4e2a\u63d0\u9ad8\u662f\u8fc7\u53bb\u5341\u5e74\u63d0\u9ad8\u7387\u7684\u603b\u548c\uff09\u9057\u61be\u7684\u662fDistBelief\u4f9d\u6258\u4e8eGoogle\u5185\u90e8\u7cfb\u7edf\u67b6\u6784\u5f88\u96be\u5bf9\u5916\u5f00\u6e90\u3002\n\n\n\n\n\n\n\n\n2011\u5e7411\u6708\u4efd\u6b63\u5f0f\u53d1\u5e03\u4e86\u57fa\u4e8eApache2.0\u7684\u5f00\u6e90\u534f\u8bae\u6846\u67b6TensorFlow(\u652f\u6301\u591a\u5e73\u53f0\uff0c\u8ba1\u7b97\u901f\u5ea6\u66f4\u5feb\uff0c\u652f\u6301\u7b97\u6cd5\u66f4\u5e7f\uff0c\u7cfb\u7edf\u66f4\u7a33\u5b9a)\n\n\n\n\n\n\n\n\nTF\u5728Google\u7684\u5e94\u7528\uff1aRankBrain\uff08Google\u6838\u5fc3\u7f51\u9875\u641c\u7d22\u7b97\u6cd5\uff09\uff0c\u8bed\u97f3\u641c\u7d22\uff0c\u5e7f\u544a\uff0c\u7535\u5546\uff0c\u56fe\u7247\uff0c\u8857\u666f\uff0c\u7ffb\u8bd1\uff0cYouTube\u90fd\u53ef\u4ee5\u770b\u5230\u57fa\u4e8eTensorFlow\u7684\u7cfb\u7edf\n\n\n\n\n\n\n\n\nGoogle DeepMind\u56e2\u961f\u5ba3\u5e03\u5728\u4e4b\u540e\u7684\u6240\u6709\u7814\u7a76\u90fd\u662f\u7528TF\u4f5c\u4e3a\u5b9e\u73b0\u6df1\u5ea6\u5b66\u4e60\u7684\u5de5\u5177\u3002\n\n\n\n\n\n\n\n\n\n\n\u4e2d\u5c71\u5927\u5b66\u7684\u7814\u7a76\u4eba\u5458\u5229\u7528 TensorFlow \u76d1\u6d4b\u57ce\u5e02\u571f\u5730\u7684\u5229\u7528\u6a21\u5f0f (https://arxiv.org/pdf/1708.01580.pdf)\u3002\u968f\u7740\u4e2d\u56fd\u7ecf\u6d4e\u7684\u9ad8\u901f\u589e\u957f\uff0c\u571f\u5730\u76d1\u6d4b\u5229\u7528\u5bf9\u57ce\u5e02\u89c4\u5212\u3001\u73af\u5883\u76d1\u6d4b\u548c\u53d1\u5c55\u5177\u6709\u5341\u5206\u91cd\u8981\u7684\u610f\u4e49\u3002\n\n\n\n\n\n\n\u6e05\u534e\u5927\u5b66\u7684 AI \u7814\u7a76\u56e2\u961f\u6269\u5c55\u4e86 TensorFlow\uff0c\u5f00\u6e90\u4e86 Python \u6982\u7387\u7f16\u7a0b\u5e93 Zhusuan\uff08\u73e0\u7b97\uff1ahttp://zhusuan.readthedocs.io/en/latest)\uff0c\u7ed3\u5408\u4e86\u8d1d\u53f6\u65af\u65b9\u6cd5\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u4f18\u70b9\u3002\n\n\n\n\n\n\n\u4eac\u4e1c\u628a TensorFlow \u4f7f\u7528\u5728\u591a\u4e2a\u4ea7\u54c1\u4e2d\uff0c\u5305\u62ec\u5e7f\u544a\u3001OCR\u3001\u5ba2\u670d\u673a\u5668\u4eba\u548c\u667a\u80fd\u97f3\u7bb1\u7b49\uff0c\u5e76\u4e14\u6784\u5efa\u4e86\u57fa\u4e8e TensorFlow \u7684\u5927\u89c4\u6a21\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u3002\n\n\n\n\n\n\n\u4e0b\u56fe\u4e2d\u7684\u6240\u6709\u516c\u53f8\uff0c\u6bd4\u5982\u5c0f\u7c73\u3001360\u3001\u7f51\u6613\u3001\u65b0\u6d6a\u3001\u8054\u60f3\u548c\u4e2d\u5174\u7b49\u90fd\u5e7f\u6cdb\u4f7f\u7528\u4e86 TensorFlow\uff0c\u6765\u89e3\u51b3\u56fe\u50cf\u3001\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u3001\u8bed\u97f3\u548c\u63a8\u8350\u7b49\u591a\u6837\u7684\u95ee\u9898\u3002\u66f4\u591a\u7684\u6848\u4f8b\u6b63\u5728\u6574\u7406\u5f53\u4e2d\u3002\n\n\n\n\n\n\n\n\n\u56fe2\uff1a\u4f7f\u7528TensorFlow\u7684\u4f01\u4e1a\n\n\n\u9664\u4e86TF\u8fd8\u6709\u5176\u4ed6\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\n\n\n\u88681\uff1a\u4e3b\u6d41\u7684\u6df1\u5ea6\u5b66\u4e60\u5f00\u6e90\u5de5\u5177\u603b\u7ed3\u8868\n\n\n\n\n\n\n\n\n\u5de5\u5177\u540d\u79f0\n\n\n\u4e3b\u8981\u7ef4\u62a4\u56e2\u961f\n\n\n\u652f\u6301\u8bed\u8a00\n\n\n\u652f\u6301\u7cfb\u7edf\n\n\n\n\n\n\n\n\n\n\nCaffe\n\n\n\u52a0\u5dde\u5927\u5b66\u4f2f\u514b\u5229\u5206\u6821\u89c6\u89c9\u4e0e\u5b66\u4e60\u4e2d\u5fc3\n\n\nC++\n1\n,pyhon,Matlab\n\n\nlinux,win,Mac\n\n\n\n\n\n\nDeeplearning4j\n\n\nSkymind\n\n\nJava\n2\n.Scale,Clojure\n\n\n3+Android\n\n\n\n\n\n\nCNTK\n\n\n\u5fae\u8f6f\u7814\u7a76\u9662\n\n\nPython,C++,BrainScript\n\n\nLinux,Win\n\n\n\n\n\n\nMxNet\n\n\nDMLC\n\n\nC++,Python,Julia,Matlab,Go,R,Scale\n\n\n3+Android+ ios\n\n\n\n\n\n\nPaddlePaddle\n\n\n\u767e\u5ea6\n\n\nC++,Python\n\n\nLinux,Mac\n\n\n\n\n\n\nTensorflow\n\n\n\u8c37\u6b4c\n\n\nC++,Python,Java,Go,(R\u975e\u5b98\u65b9)\n\n\n3+Android+ios\n\n\n\n\n\n\nTheano\n\n\n\u8499\u7279\u5229\u5c14\u5927\u5b66\n\n\nPython\n\n\nLinux,Win,Mac\n\n\n\n\n\n\nToech\n\n\nFaceBook,Twitter,Google\n\n\nC,Lua\n\n\n3+Android+ ios\n\n\n\n\n\n\nKeras\n\n\nTaehoon Lee(\u4e00\u4e2a\u4eba)\n\n\nPython,(R\u975e\u5b98\u65b9\u7684)\n\n\nLinux,Win,Mac\n\n\n\n\n\n\n\n\n[1] \nC\uff0cC++\uff0cC#\u4e09\u8005\u533a\u522b\n:\n\u7ee7\u627f\u5173\u7cfb\u662fC->C++->C# C++\u5b8c\u5168\u5411C\u517c\u5bb9,C\u7a0b\u5e8f\u51e0\u4e4e\u4e0d\u7528\u4fee\u6539\u5373\u53ef\u5728C++\u7684\u7f16\u8bd1\u5668\u4e0a\u8fd0\u884c.C++\u4e5f\u79f0\u4e3a\u5e26\u7c7b\u7684C,\u5728C\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u8bb8\u591a\u9762\u5411\u5bf9\u8c61\u7684\u6982\u5ff5.\u867d\u7136\u662fC\u7684\u6269\u5c55,\u4f46 \u5e76\u4e0d\u610f\u5473\u7740C\u529f\u80fd\u4e0d\u5982C++,\u6700\u725b\u7684\u64cd\u4f5c\u7cfb\u7edf\u662f\u7528C\u5199\u7684(\u4e0d\u662fC++\u54e6). \nC#\u662f\u5fae\u8f6f\u5f04\u7684\u4e00\u4e2a\u4e1c\u4e1c,\u7ee7\u627f\u4e86C\u548cC++\u7684\u8bb8\u591a\u4e1c\u897f,\u4f46\u548c\u4e24\u8005\u57fa\u672c\u4e0a \u5df2\u5b8c\u5168\u4e0d\u4e00\u6837\u4e86.\u4f60\u53ef\u4ee5\u628a\u5b83\u5f53\u4f5c\u4e00\u79cd\u5168\u65b0\u7684\u8bed\u8a00\u6765\u5b66. \n\n\n[2] \njava\u4e0ejavascript\u4e24\u8005\u7684\u5173\u7cfb\n Java\u662f\u4e00\u95e8\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\u8bed\u8a00\uff0c\u4e0d\u4ec5\u5438\u6536\u4e86C++\u8bed\u8a00\u7684\u5404\u79cd\u4f18\u70b9\uff0c\u8fd8\u6452\u5f03\u4e86C++\u91cc\u96be\u4ee5\u7406\u89e3\u7684\u591a\u7ee7\u627f\u3001\u6307\u9488\u7b49\u6982\u5ff5\uff0c\u56e0\u6b64Java\u8bed\u8a00\u5177\u6709\u529f\u80fd\u5f3a\u5927\u548c\u7b80\u5355\u6613\u7528\u4e24\u4e2a\u7279\u5f81\u3002Java\u8bed\u8a00\u4f5c\u4e3a\u9759\u6001\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\u8bed\u8a00\u7684\u4ee3\u8868\uff0c\u6781\u597d\u5730\u5b9e\u73b0\u4e86\u9762\u5411\u5bf9\u8c61\u7406\u8bba\uff0c\u5141\u8bb8\u7a0b\u5e8f\u5458\u4ee5\u4f18\u96c5\u7684\u601d\u7ef4\u65b9\u5f0f\u8fdb\u884c\u590d\u6742\u7684\u7f16\u7a0b\u3002\nJava\u5177\u6709\u7b80\u5355\u6027\u3001\u9762\u5411\u5bf9\u8c61\u3001\u5206\u5e03\u5f0f\u3001\u5065\u58ee\u6027\u3001\u5b89\u5168\u6027\u3001\u5e73\u53f0\u72ec\u7acb\u4e0e\u53ef\u79fb\u690d\u6027\u3001\u591a\u7ebf\u7a0b\u3001\u52a8\u6001\u6027\u7b49\u7279\u70b9\u3002Java\u53ef\u4ee5\u7f16\u5199\u684c\u9762\u5e94\u7528\u7a0b\u5e8f\u3001Web\u5e94\u7528\u7a0b\u5e8f\uff08\u6210\u4e3a\u4e3b\u6d41\uff09\u3001\u5206\u5e03\u5f0f\u7cfb\u7edf\u548c\u5d4c\u5165\u5f0f\u7cfb\u7edf\u5e94\u7528\u7a0b\u5e8f\u7b49,Netscape\u4e3a\u4e86\u642d\u4e0a\u5a92\u4f53\u70ed\u7092Java\u7684\u987a\u98ce\u8f66\uff0c\u4e34\u65f6\u628aLiveScript\u6539\u540d\u4e3aJavaScript\uff0c\u6240\u4ee5\u4ece\u672c\u8d28\u4e0a\u6765\u8bf4JavaScript\u548cJava\u6ca1\u4ec0\u4e48\u5173\u7cfb\u3002JavaScript\u4e00\u79cd\u76f4\u8bd1\u5f0f\u811a\u672c\u8bed\u8a00\uff0c\u662f\u4e00\u79cd\u52a8\u6001\u7c7b\u578b\u3001\u5f31\u7c7b\u578b\u3001\u57fa\u4e8e\u539f\u578b\u7684\u8bed\u8a00\uff0c\u5185\u7f6e\u652f\u6301\u7c7b\u578b\u3002\u5b83\u7684\u89e3\u91ca\u5668\u88ab\u79f0\u4e3aJavaScript\u5f15\u64ce\uff0c\u4e3a\u6d4f\u89c8\u5668\u7684\u4e00\u90e8\u5206\uff0c\u5e7f\u6cdb\u7528\u4e8e\u5ba2\u6237\u7aef\u7684\u811a\u672c\u8bed\u8a00\uff0c\u6700\u65e9\u662f\u5728HTML\uff08\u6807\u51c6\u901a\u7528\u6807\u8bb0\u8bed\u8a00\u4e0b\u7684\u4e00\u4e2a\u5e94\u7528\uff09\u7f51\u9875\u4e0a\u4f7f\u7528\uff0c\u7528\u6765\u7ed9HTML\u7f51\u9875\u589e\u52a0\u52a8\u6001\u529f\u80fd\u3002\n\n\n[\u6ce8] TensorFlow Lite\uff0c\u8fd9\u4e2a\u7248\u672c\u662f TensorFlow \u9762\u5411\u79fb\u52a8\u548c\u5d4c\u5165\u5f0f\u8bbe\u5907\u7684\u8f7b\u91cf\u7ea7\u89e3\u51b3\u65b9\u6848\uff08\u4e5f\u5c31\u662f\u8bf4TensorFlow\u5f00\u59cb\u652f\u6301 Android\u7cfb\u7edf\uff09",
            "title": "\u4e3b\u9875"
        },
        {
            "location": "/#welcome-to-tensorflow-learning-base-1",
            "text": "More learning: XuJing'Home  https://dataxujing.coding.me/    TensorFlow\uff08\u4e0b\u9762\u7b80\u79f0TF)\u662fGoogle\u4e8e2015\u5e7411\u67089\u65e5\u6b63\u5f0f\u5f00\u6e90\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6     \u524d\u4e24\u5929\u7684Google\u5f00\u53d1\u8005\u5927\u4f1a\u5728\u4e0a\u6d77\u4e3e\u529e\uff0c\u4f1a\u4e0a\u5ba3\u5e03\uff0cTensorFlow \u5fae\u4fe1\u516c\u4f17\u53f7\u6b63\u5f0f\u53d1\u5e03\uff01\u5c06\u4e3a\u4e2d\u56fd\u5f00\u53d1\u8005\u63d0\u4f9b\u6700\u65b0\u7684 TensorFlow \u65b0\u95fb\u3001\u5b9e\u7528\u7684\u6280\u672f\u8d44\u6e90\u3001\u672a\u6765\u5c55\u671b\u4ee5\u53ca\u7ebf\u4e0b\u7684\u6d3b\u52a8\u4fe1\u606f\uff0c\u8ba9\u4e2d\u56fd\u7684\u5f00\u53d1\u8005\u4eec\u80fd\u591f\u66f4\u4fbf\u6377\u5730\u4f7f\u7528 TensorFlow \u6253\u9020\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u3002    \u56fe1\uff1aTensorFlow\u5fae\u4fe1\u516c\u4f17\u53f7    TF\u8ba1\u7b97\u6846\u67b6\u53ef\u4ee5\u5f88\u597d\u7684\u652f\u6301\u6df1\u5ea6\u5b66\u4e60\u7684\u5404\u79cd\u7b97\u6cd5\uff0c\u4f46\u5176\u5e94\u7528\u4e5f\u4e0d\u5c40\u9650\u4e8e\u6df1\u5ea6\u5b66\u4e60\uff08\u672c\u6559\u7a0b\u4f1a\u5ffd\u7565\u6389\u5bf9\u5176\u4ed6\u7b97\u6cd5\u7684\u652f\u6301\uff09     TF\u662fJeff Dean\u9886\u5934\u7684Google Brain\u56e2\u961f\u57fa\u4e8eGoogle\u7684\u5185\u90e8\u7b2c\u4e00\u4ee3\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edfDistBelief\uff082011\u5e74\uff09\u6539\u8fdb\u800c\u6765\u7684\u901a\u7528\u8ba1\u7b97\u6846\u67b6     DistBelief\u7684\u4e1a\u7ee9\uff1aInmageNet2014\u51a0\u519b\uff0c\u5728\u6d77\u91cf\u7684\u975e\u6807\u6ce8\u7684YouTube\u89c6\u5c4f\u4e2d\u4e60\u5f97\u4e86\u2018\u732b\u2019\u7684\u6982\u5ff5\uff0c\u5e76\u5728Google\u56fe\u7247\u4e2d\u5f00\u521b\u4e86\u56fe\u7247\u641c\u7d22\u7684\u529f\u80fd\uff0c\u4f7f\u7528DistBelief\u6846\u67b6\u8bad\u7ec3\u7684\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\u6210\u529f\u5c06\u8bc6\u522b\u7684\u9519\u8bef\u7387\u964d\u4f4e\u4e8625%\uff08\u8fd9\u4e2a\u63d0\u9ad8\u662f\u8fc7\u53bb\u5341\u5e74\u63d0\u9ad8\u7387\u7684\u603b\u548c\uff09\u9057\u61be\u7684\u662fDistBelief\u4f9d\u6258\u4e8eGoogle\u5185\u90e8\u7cfb\u7edf\u67b6\u6784\u5f88\u96be\u5bf9\u5916\u5f00\u6e90\u3002     2011\u5e7411\u6708\u4efd\u6b63\u5f0f\u53d1\u5e03\u4e86\u57fa\u4e8eApache2.0\u7684\u5f00\u6e90\u534f\u8bae\u6846\u67b6TensorFlow(\u652f\u6301\u591a\u5e73\u53f0\uff0c\u8ba1\u7b97\u901f\u5ea6\u66f4\u5feb\uff0c\u652f\u6301\u7b97\u6cd5\u66f4\u5e7f\uff0c\u7cfb\u7edf\u66f4\u7a33\u5b9a)     TF\u5728Google\u7684\u5e94\u7528\uff1aRankBrain\uff08Google\u6838\u5fc3\u7f51\u9875\u641c\u7d22\u7b97\u6cd5\uff09\uff0c\u8bed\u97f3\u641c\u7d22\uff0c\u5e7f\u544a\uff0c\u7535\u5546\uff0c\u56fe\u7247\uff0c\u8857\u666f\uff0c\u7ffb\u8bd1\uff0cYouTube\u90fd\u53ef\u4ee5\u770b\u5230\u57fa\u4e8eTensorFlow\u7684\u7cfb\u7edf     Google DeepMind\u56e2\u961f\u5ba3\u5e03\u5728\u4e4b\u540e\u7684\u6240\u6709\u7814\u7a76\u90fd\u662f\u7528TF\u4f5c\u4e3a\u5b9e\u73b0\u6df1\u5ea6\u5b66\u4e60\u7684\u5de5\u5177\u3002      \u4e2d\u5c71\u5927\u5b66\u7684\u7814\u7a76\u4eba\u5458\u5229\u7528 TensorFlow \u76d1\u6d4b\u57ce\u5e02\u571f\u5730\u7684\u5229\u7528\u6a21\u5f0f (https://arxiv.org/pdf/1708.01580.pdf)\u3002\u968f\u7740\u4e2d\u56fd\u7ecf\u6d4e\u7684\u9ad8\u901f\u589e\u957f\uff0c\u571f\u5730\u76d1\u6d4b\u5229\u7528\u5bf9\u57ce\u5e02\u89c4\u5212\u3001\u73af\u5883\u76d1\u6d4b\u548c\u53d1\u5c55\u5177\u6709\u5341\u5206\u91cd\u8981\u7684\u610f\u4e49\u3002    \u6e05\u534e\u5927\u5b66\u7684 AI \u7814\u7a76\u56e2\u961f\u6269\u5c55\u4e86 TensorFlow\uff0c\u5f00\u6e90\u4e86 Python \u6982\u7387\u7f16\u7a0b\u5e93 Zhusuan\uff08\u73e0\u7b97\uff1ahttp://zhusuan.readthedocs.io/en/latest)\uff0c\u7ed3\u5408\u4e86\u8d1d\u53f6\u65af\u65b9\u6cd5\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u4f18\u70b9\u3002    \u4eac\u4e1c\u628a TensorFlow \u4f7f\u7528\u5728\u591a\u4e2a\u4ea7\u54c1\u4e2d\uff0c\u5305\u62ec\u5e7f\u544a\u3001OCR\u3001\u5ba2\u670d\u673a\u5668\u4eba\u548c\u667a\u80fd\u97f3\u7bb1\u7b49\uff0c\u5e76\u4e14\u6784\u5efa\u4e86\u57fa\u4e8e TensorFlow \u7684\u5927\u89c4\u6a21\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u3002    \u4e0b\u56fe\u4e2d\u7684\u6240\u6709\u516c\u53f8\uff0c\u6bd4\u5982\u5c0f\u7c73\u3001360\u3001\u7f51\u6613\u3001\u65b0\u6d6a\u3001\u8054\u60f3\u548c\u4e2d\u5174\u7b49\u90fd\u5e7f\u6cdb\u4f7f\u7528\u4e86 TensorFlow\uff0c\u6765\u89e3\u51b3\u56fe\u50cf\u3001\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u3001\u8bed\u97f3\u548c\u63a8\u8350\u7b49\u591a\u6837\u7684\u95ee\u9898\u3002\u66f4\u591a\u7684\u6848\u4f8b\u6b63\u5728\u6574\u7406\u5f53\u4e2d\u3002     \u56fe2\uff1a\u4f7f\u7528TensorFlow\u7684\u4f01\u4e1a  \u9664\u4e86TF\u8fd8\u6709\u5176\u4ed6\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6  \u88681\uff1a\u4e3b\u6d41\u7684\u6df1\u5ea6\u5b66\u4e60\u5f00\u6e90\u5de5\u5177\u603b\u7ed3\u8868     \u5de5\u5177\u540d\u79f0  \u4e3b\u8981\u7ef4\u62a4\u56e2\u961f  \u652f\u6301\u8bed\u8a00  \u652f\u6301\u7cfb\u7edf      Caffe  \u52a0\u5dde\u5927\u5b66\u4f2f\u514b\u5229\u5206\u6821\u89c6\u89c9\u4e0e\u5b66\u4e60\u4e2d\u5fc3  C++ 1 ,pyhon,Matlab  linux,win,Mac    Deeplearning4j  Skymind  Java 2 .Scale,Clojure  3+Android    CNTK  \u5fae\u8f6f\u7814\u7a76\u9662  Python,C++,BrainScript  Linux,Win    MxNet  DMLC  C++,Python,Julia,Matlab,Go,R,Scale  3+Android+ ios    PaddlePaddle  \u767e\u5ea6  C++,Python  Linux,Mac    Tensorflow  \u8c37\u6b4c  C++,Python,Java,Go,(R\u975e\u5b98\u65b9)  3+Android+ios    Theano  \u8499\u7279\u5229\u5c14\u5927\u5b66  Python  Linux,Win,Mac    Toech  FaceBook,Twitter,Google  C,Lua  3+Android+ ios    Keras  Taehoon Lee(\u4e00\u4e2a\u4eba)  Python,(R\u975e\u5b98\u65b9\u7684)  Linux,Win,Mac     [1]  C\uff0cC++\uff0cC#\u4e09\u8005\u533a\u522b :\n\u7ee7\u627f\u5173\u7cfb\u662fC->C++->C# C++\u5b8c\u5168\u5411C\u517c\u5bb9,C\u7a0b\u5e8f\u51e0\u4e4e\u4e0d\u7528\u4fee\u6539\u5373\u53ef\u5728C++\u7684\u7f16\u8bd1\u5668\u4e0a\u8fd0\u884c.C++\u4e5f\u79f0\u4e3a\u5e26\u7c7b\u7684C,\u5728C\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u8bb8\u591a\u9762\u5411\u5bf9\u8c61\u7684\u6982\u5ff5.\u867d\u7136\u662fC\u7684\u6269\u5c55,\u4f46 \u5e76\u4e0d\u610f\u5473\u7740C\u529f\u80fd\u4e0d\u5982C++,\u6700\u725b\u7684\u64cd\u4f5c\u7cfb\u7edf\u662f\u7528C\u5199\u7684(\u4e0d\u662fC++\u54e6). \nC#\u662f\u5fae\u8f6f\u5f04\u7684\u4e00\u4e2a\u4e1c\u4e1c,\u7ee7\u627f\u4e86C\u548cC++\u7684\u8bb8\u591a\u4e1c\u897f,\u4f46\u548c\u4e24\u8005\u57fa\u672c\u4e0a \u5df2\u5b8c\u5168\u4e0d\u4e00\u6837\u4e86.\u4f60\u53ef\u4ee5\u628a\u5b83\u5f53\u4f5c\u4e00\u79cd\u5168\u65b0\u7684\u8bed\u8a00\u6765\u5b66.   [2]  java\u4e0ejavascript\u4e24\u8005\u7684\u5173\u7cfb  Java\u662f\u4e00\u95e8\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\u8bed\u8a00\uff0c\u4e0d\u4ec5\u5438\u6536\u4e86C++\u8bed\u8a00\u7684\u5404\u79cd\u4f18\u70b9\uff0c\u8fd8\u6452\u5f03\u4e86C++\u91cc\u96be\u4ee5\u7406\u89e3\u7684\u591a\u7ee7\u627f\u3001\u6307\u9488\u7b49\u6982\u5ff5\uff0c\u56e0\u6b64Java\u8bed\u8a00\u5177\u6709\u529f\u80fd\u5f3a\u5927\u548c\u7b80\u5355\u6613\u7528\u4e24\u4e2a\u7279\u5f81\u3002Java\u8bed\u8a00\u4f5c\u4e3a\u9759\u6001\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\u8bed\u8a00\u7684\u4ee3\u8868\uff0c\u6781\u597d\u5730\u5b9e\u73b0\u4e86\u9762\u5411\u5bf9\u8c61\u7406\u8bba\uff0c\u5141\u8bb8\u7a0b\u5e8f\u5458\u4ee5\u4f18\u96c5\u7684\u601d\u7ef4\u65b9\u5f0f\u8fdb\u884c\u590d\u6742\u7684\u7f16\u7a0b\u3002\nJava\u5177\u6709\u7b80\u5355\u6027\u3001\u9762\u5411\u5bf9\u8c61\u3001\u5206\u5e03\u5f0f\u3001\u5065\u58ee\u6027\u3001\u5b89\u5168\u6027\u3001\u5e73\u53f0\u72ec\u7acb\u4e0e\u53ef\u79fb\u690d\u6027\u3001\u591a\u7ebf\u7a0b\u3001\u52a8\u6001\u6027\u7b49\u7279\u70b9\u3002Java\u53ef\u4ee5\u7f16\u5199\u684c\u9762\u5e94\u7528\u7a0b\u5e8f\u3001Web\u5e94\u7528\u7a0b\u5e8f\uff08\u6210\u4e3a\u4e3b\u6d41\uff09\u3001\u5206\u5e03\u5f0f\u7cfb\u7edf\u548c\u5d4c\u5165\u5f0f\u7cfb\u7edf\u5e94\u7528\u7a0b\u5e8f\u7b49,Netscape\u4e3a\u4e86\u642d\u4e0a\u5a92\u4f53\u70ed\u7092Java\u7684\u987a\u98ce\u8f66\uff0c\u4e34\u65f6\u628aLiveScript\u6539\u540d\u4e3aJavaScript\uff0c\u6240\u4ee5\u4ece\u672c\u8d28\u4e0a\u6765\u8bf4JavaScript\u548cJava\u6ca1\u4ec0\u4e48\u5173\u7cfb\u3002JavaScript\u4e00\u79cd\u76f4\u8bd1\u5f0f\u811a\u672c\u8bed\u8a00\uff0c\u662f\u4e00\u79cd\u52a8\u6001\u7c7b\u578b\u3001\u5f31\u7c7b\u578b\u3001\u57fa\u4e8e\u539f\u578b\u7684\u8bed\u8a00\uff0c\u5185\u7f6e\u652f\u6301\u7c7b\u578b\u3002\u5b83\u7684\u89e3\u91ca\u5668\u88ab\u79f0\u4e3aJavaScript\u5f15\u64ce\uff0c\u4e3a\u6d4f\u89c8\u5668\u7684\u4e00\u90e8\u5206\uff0c\u5e7f\u6cdb\u7528\u4e8e\u5ba2\u6237\u7aef\u7684\u811a\u672c\u8bed\u8a00\uff0c\u6700\u65e9\u662f\u5728HTML\uff08\u6807\u51c6\u901a\u7528\u6807\u8bb0\u8bed\u8a00\u4e0b\u7684\u4e00\u4e2a\u5e94\u7528\uff09\u7f51\u9875\u4e0a\u4f7f\u7528\uff0c\u7528\u6765\u7ed9HTML\u7f51\u9875\u589e\u52a0\u52a8\u6001\u529f\u80fd\u3002  [\u6ce8] TensorFlow Lite\uff0c\u8fd9\u4e2a\u7248\u672c\u662f TensorFlow \u9762\u5411\u79fb\u52a8\u548c\u5d4c\u5165\u5f0f\u8bbe\u5907\u7684\u8f7b\u91cf\u7ea7\u89e3\u51b3\u65b9\u6848\uff08\u4e5f\u5c31\u662f\u8bf4TensorFlow\u5f00\u59cb\u652f\u6301 Android\u7cfb\u7edf\uff09",
            "title": "Welcome to TensorFlow Learning Base 1"
        },
        {
            "location": "/chapter1/",
            "text": "\u6211\u4eec\u5f00\u59cb\u4eca\u5929\u7684\u5b66\u4e60\u4ea4\u6d41\n\n\nTF\u6709\u5927\u91cf\u7684\u7f51\u7edc\u5b66\u4e60\u8d44\u6e90\uff0c\u6846\u67b6\u66f4\u65b0\u9891\u7e41\uff0c\u53ef\u80fd\u4e09\u56db\u672c\u4e66\u7684\u4f53\u91cf\u624d\u53ef\u4ee5\u5b8c\u6574\u7684\u4ecb\u7ecdTF\u7684\u6574\u4e2a\u6846\u67b6\uff0c\u672c\u6559\u7a0b\u4e3b\u8981\u76ee\u7684\uff1a\nTF\u73af\u5883\u642d\u5efa\n\uff0c\nTF\u5165\u95e8\u6559\u7a0b\n\uff0c\nTF\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u4e3e\u4f8b\n\uff0c\nTF\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u4e3e\u4f8b\n\uff0c\nTF\u5b9e\u73b0CNN\n,\nTF\u5b9e\u73b0RNN\n,\nTensorBoard\u7684\u53ef\u89c6\u5316\n\u3002\u5173\u4e8e\u5176\u4ed6\u7684\uff1a\nTF\u7684\u6570\u636e\u8bfb\u53d6\n\uff0c\nTF\u5b9e\u73b0NLP\n,\nTF\u7684\u56fe\u50cf\u5904\u7406\n\uff0c\nTF\u5728\u65f6\u95f4\u5e8f\u5217\u4e0a\u7684\u5e94\u7528\n\uff0c\nTF\u5b9e\u73b0\u751f\u6210\u7f51\u7edc\n\uff0c\nTF\u5b9e\u73b0\u5bf9\u6297\u7f51\u7edc\n\uff0c\nTF\u7684GPU\u8c03\u8bd5\n\uff0c\nTF\u7684\u9ad8\u5c42\u5c01\u88c5TFlearn\n\uff0c\nTF\u8ba1\u7b97\u52a0\u901f\n\uff0c\nTF\u505a\u6210\u6570\u636e\u4ea7\u54c1\n\u7b49\u7684\u5185\u5bb9\u6211\u4eec\u4eca\u5929\u80af\u5b9a\u662f\u6ca1\u6709\u65f6\u95f4\u8bb2\u89e3\u3002\n\n\n\u6211\u7684TensorFlow\u7684\u7248\u672c\u662f1.2.1\uff0c\u6240\u6709\u4ee3\u7801\u57281.2.1\u4e2d\u8fd0\u884c\u901a\u8fc7\u3002",
            "title": "TensorFlow\u57f9\u8bad\u5185\u5bb9"
        },
        {
            "location": "/chapter1/#_1",
            "text": "TF\u6709\u5927\u91cf\u7684\u7f51\u7edc\u5b66\u4e60\u8d44\u6e90\uff0c\u6846\u67b6\u66f4\u65b0\u9891\u7e41\uff0c\u53ef\u80fd\u4e09\u56db\u672c\u4e66\u7684\u4f53\u91cf\u624d\u53ef\u4ee5\u5b8c\u6574\u7684\u4ecb\u7ecdTF\u7684\u6574\u4e2a\u6846\u67b6\uff0c\u672c\u6559\u7a0b\u4e3b\u8981\u76ee\u7684\uff1a TF\u73af\u5883\u642d\u5efa \uff0c TF\u5165\u95e8\u6559\u7a0b \uff0c TF\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u4e3e\u4f8b \uff0c TF\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u4e3e\u4f8b \uff0c TF\u5b9e\u73b0CNN , TF\u5b9e\u73b0RNN , TensorBoard\u7684\u53ef\u89c6\u5316 \u3002\u5173\u4e8e\u5176\u4ed6\u7684\uff1a TF\u7684\u6570\u636e\u8bfb\u53d6 \uff0c TF\u5b9e\u73b0NLP , TF\u7684\u56fe\u50cf\u5904\u7406 \uff0c TF\u5728\u65f6\u95f4\u5e8f\u5217\u4e0a\u7684\u5e94\u7528 \uff0c TF\u5b9e\u73b0\u751f\u6210\u7f51\u7edc \uff0c TF\u5b9e\u73b0\u5bf9\u6297\u7f51\u7edc \uff0c TF\u7684GPU\u8c03\u8bd5 \uff0c TF\u7684\u9ad8\u5c42\u5c01\u88c5TFlearn \uff0c TF\u8ba1\u7b97\u52a0\u901f \uff0c TF\u505a\u6210\u6570\u636e\u4ea7\u54c1 \u7b49\u7684\u5185\u5bb9\u6211\u4eec\u4eca\u5929\u80af\u5b9a\u662f\u6ca1\u6709\u65f6\u95f4\u8bb2\u89e3\u3002  \u6211\u7684TensorFlow\u7684\u7248\u672c\u662f1.2.1\uff0c\u6240\u6709\u4ee3\u7801\u57281.2.1\u4e2d\u8fd0\u884c\u901a\u8fc7\u3002",
            "title": "\u6211\u4eec\u5f00\u59cb\u4eca\u5929\u7684\u5b66\u4e60\u4ea4\u6d41"
        },
        {
            "location": "/chapter2/",
            "text": "TF\u73af\u5883\u642d\u5efa\n\n\n1.TF\u4e3b\u8981\u4f9d\u8d56\u7684\u5305\n\n\nProtocol Buffer\n\n\n\u662f\u8c37\u6b4c\u5f00\u53d1\u7684\u5904\u7406\u7ed3\u6784\u5316\u6570\u636e\u7684\u5de5\u5177\uff0cProtocol Buffer\u5e8f\u5217\u5316\uff08\u5c06\u7ed3\u6784\u5316\u7684\u6570\u636e\u53d8\u6210\u6570\u636e\u6d41\u7684\u683c\u5f0f\uff0c\u767d\u8bdd\u5c31\u662f\u53d8\u6210\u4e00\u4e2a\u5b57\u7b26\u4e32\uff09\u540e\u5f97\u5230\u7684\u6570\u636e\u662f\u4e0d\u53ef\u8bfb\u7684\u5b57\u7b26\u4e32\uff0c\u800c\u662f\u4e8c\u8fdb\u5236\u6d41\u3002\u5982\u4f55\u4ece\u7ed3\u6784\u5316\u7684\u6570\u636e\u5e8f\u5217\u5316\uff0c\u4ece\u5e8f\u5217\u5316\u4e4b\u540e\u7684\u6570\u636e\u6d41\u4e2d\u8fd8\u539f\u539f\u6765\u7684\u6570\u636e\u7ed3\u6784\uff0c\u8fd9\u662fProtocol Buffer\u89e3\u51b3\u7684\u4e3b\u8981\u95ee\u9898\u3002\u662fTensorflow\u7cfb\u7edf\u7528\u5230\u7684\u91cd\u8981\u5de5\u5177\u3002\n\n\nBazel\n\n\nBazel\u662f\u4ece\u8c37\u6b4c\u5f00\u6e90\u7684\u81ea\u52a8\u5316\u6784\u5efa\u5de5\u5177\uff0c\u8c37\u6b4c\u5185\u90e8\u5927\u90e8\u5206\u7684\u5e94\u7528\u90fd\u662f\u901a\u8fc7\u5b83\u6765\n\u7f16\u8bd1\n\u7684\uff0cTensorflow\u4e5f\u662f\u901a\u8fc7Bazel\u7f16\u8bd1\u7684\u3002\n\n\n2.TF\u5b89\u88c5\n\n\nTensorFlow\u63d0\u4f9b\u4e86\u591a\u79cd\u4e0d\u540c\u7684\u5b89\u88c5\u65b9\u5f0f\uff0c\u6211\u4eec\u4e3b\u8981\u4ecb\u7ecd\u901a\u8fc7Docker\u5b89\u88c5\uff0c\u901a\u8fc7Pip\u5b89\u88c5\u53ca\u4ece\u6e90\u7801\u5b89\u88c5\u3002\n\n\nDocker\u5b89\u88c5\n\n\nDocker\u662f\u65b0\u4e00\u4ee3\u7684\u865a\u62df\u5316\u6280\u672f\uff0c\u53ef\u4ee5\u5c06TF\u53caTF\u7684\u6240\u6709\u4f9d\u8d56\u5173\u7cfb\u5c01\u88c5\u5728Docker\u955c\u50cf\u4e2d\uff0c\u5927\u5927\u7b80\u5316\u5b89\u88c5\u8fc7\u7a0b\uff08\u6211\u7684Tensorflow\u5c31\u662f\u901a\u8fc7Docker\u5b89\u88c5\u7684\uff0c\u5f53\u65f6Tensorflow\u8fd8\u4e0d\u80fd\u5f88\u597d\u7684\u652f\u6301Windows)\u3002\u90a3\u9996\u5148\u9700\u8981\u5b89\u88c5Docker(Docker\u7684\u5b89\u88c5\u548c\u4f7f\u7528\u4e0d\u662f\u672c\u8282\u7684\u91cd\u70b9)\uff0c\u5b89\u88c5\u597d\u540e\u4f7f\u7528\u4e00\u4e2a\u6253\u5305\u597d\u7684Docker\u955c\u50cf\uff0cTensorFlow\u5b98\u65b9\u63d0\u4f9b\u4e86\u591a\u4e2aDocker\u955c\u50cf\uff0c\u56fd\u5185\u7684\uff08eg\u624d\u4e91\u79d1\u6280\uff09\u4e5f\u63d0\u4f9b\u4e86\u76f8\u5173\u7684\u955c\u50cf\n\n\ndocker run -it -p 8888:8888 -p 6006:6006\n#\u542f\u52a8\u4e00\u4e2aTensorFlow\u5bb9\u5668\n\n\n\n\nPip\u5b89\u88c5\n\n\n\u524d\u671f\u65f6pip\u5728Windows\u4e0b\u662f\u65e0\u6cd5\u5b89\u88c5\u7684\uff0c\u73b0\u5728\u53ef\u4ee5\u5728python3\u7684\u73af\u5883\u4e0b\u76f4\u63a5\npip install tensorflow\n\u5373\u53ef\u5b8c\u6210\u5b89\u88c5\u3002\u6781\u529b\u63a8\u8350\u8fd9\u79cd\u5b89\u88c5\u65b9\u5f0f\n\n\n\u6e90\u7801\u7f16\u8bd1\u5b89\u88c5\n\n\n\u8fd9\u79cd\u5b89\u88c5\u65b9\u5f0f\u4e0d\u5efa\u8bae\u5927\u5bb6\u91c7\u7528\uff0c\u56e0\u4e3aTensorFlow\u4f9d\u8d56\u4e8e\u5176\u4ed6\u5305\uff0c\u4f60\u9700\u8981\u63d0\u524d\u628a\u5176\u4ed6\u4f9d\u8d56\u5305\u5b89\u88c5\u597d\u4e4b\u540e\u624d\u53ef\u6b63\u5e38\u901a\u8fc7\u6e90\u7801\u5b89\u88c5TF\u3002\n\n\n\u5b89\u88c5\u597d\u540e\u6d4b\u8bd5\u4e00\u4e0b\u4f60\u7684TensorFlow\u80fd\u5426\u6b63\u5e38\u4f7f\u7528,\u5982\u679c\u6b63\u5e38\u4f7f\u7528\uff0c\u606d\u559c\u4f60\u5b89\u88c5\u6210\u529f\u3002\n\n\nimport tensorflow as tf\na = tf.constant([1.0,2.0],name='a')\nb = tf.constant([2.0,3.0],name='b')\nresult =a + b\n\nsess = tf.session()\nsess.run(result)\nsess.close()",
            "title": "TensorFlow\u73af\u5883\u642d\u5efa"
        },
        {
            "location": "/chapter2/#tf",
            "text": "1.TF\u4e3b\u8981\u4f9d\u8d56\u7684\u5305  Protocol Buffer  \u662f\u8c37\u6b4c\u5f00\u53d1\u7684\u5904\u7406\u7ed3\u6784\u5316\u6570\u636e\u7684\u5de5\u5177\uff0cProtocol Buffer\u5e8f\u5217\u5316\uff08\u5c06\u7ed3\u6784\u5316\u7684\u6570\u636e\u53d8\u6210\u6570\u636e\u6d41\u7684\u683c\u5f0f\uff0c\u767d\u8bdd\u5c31\u662f\u53d8\u6210\u4e00\u4e2a\u5b57\u7b26\u4e32\uff09\u540e\u5f97\u5230\u7684\u6570\u636e\u662f\u4e0d\u53ef\u8bfb\u7684\u5b57\u7b26\u4e32\uff0c\u800c\u662f\u4e8c\u8fdb\u5236\u6d41\u3002\u5982\u4f55\u4ece\u7ed3\u6784\u5316\u7684\u6570\u636e\u5e8f\u5217\u5316\uff0c\u4ece\u5e8f\u5217\u5316\u4e4b\u540e\u7684\u6570\u636e\u6d41\u4e2d\u8fd8\u539f\u539f\u6765\u7684\u6570\u636e\u7ed3\u6784\uff0c\u8fd9\u662fProtocol Buffer\u89e3\u51b3\u7684\u4e3b\u8981\u95ee\u9898\u3002\u662fTensorflow\u7cfb\u7edf\u7528\u5230\u7684\u91cd\u8981\u5de5\u5177\u3002  Bazel  Bazel\u662f\u4ece\u8c37\u6b4c\u5f00\u6e90\u7684\u81ea\u52a8\u5316\u6784\u5efa\u5de5\u5177\uff0c\u8c37\u6b4c\u5185\u90e8\u5927\u90e8\u5206\u7684\u5e94\u7528\u90fd\u662f\u901a\u8fc7\u5b83\u6765 \u7f16\u8bd1 \u7684\uff0cTensorflow\u4e5f\u662f\u901a\u8fc7Bazel\u7f16\u8bd1\u7684\u3002  2.TF\u5b89\u88c5  TensorFlow\u63d0\u4f9b\u4e86\u591a\u79cd\u4e0d\u540c\u7684\u5b89\u88c5\u65b9\u5f0f\uff0c\u6211\u4eec\u4e3b\u8981\u4ecb\u7ecd\u901a\u8fc7Docker\u5b89\u88c5\uff0c\u901a\u8fc7Pip\u5b89\u88c5\u53ca\u4ece\u6e90\u7801\u5b89\u88c5\u3002  Docker\u5b89\u88c5  Docker\u662f\u65b0\u4e00\u4ee3\u7684\u865a\u62df\u5316\u6280\u672f\uff0c\u53ef\u4ee5\u5c06TF\u53caTF\u7684\u6240\u6709\u4f9d\u8d56\u5173\u7cfb\u5c01\u88c5\u5728Docker\u955c\u50cf\u4e2d\uff0c\u5927\u5927\u7b80\u5316\u5b89\u88c5\u8fc7\u7a0b\uff08\u6211\u7684Tensorflow\u5c31\u662f\u901a\u8fc7Docker\u5b89\u88c5\u7684\uff0c\u5f53\u65f6Tensorflow\u8fd8\u4e0d\u80fd\u5f88\u597d\u7684\u652f\u6301Windows)\u3002\u90a3\u9996\u5148\u9700\u8981\u5b89\u88c5Docker(Docker\u7684\u5b89\u88c5\u548c\u4f7f\u7528\u4e0d\u662f\u672c\u8282\u7684\u91cd\u70b9)\uff0c\u5b89\u88c5\u597d\u540e\u4f7f\u7528\u4e00\u4e2a\u6253\u5305\u597d\u7684Docker\u955c\u50cf\uff0cTensorFlow\u5b98\u65b9\u63d0\u4f9b\u4e86\u591a\u4e2aDocker\u955c\u50cf\uff0c\u56fd\u5185\u7684\uff08eg\u624d\u4e91\u79d1\u6280\uff09\u4e5f\u63d0\u4f9b\u4e86\u76f8\u5173\u7684\u955c\u50cf  docker run -it -p 8888:8888 -p 6006:6006\n#\u542f\u52a8\u4e00\u4e2aTensorFlow\u5bb9\u5668  Pip\u5b89\u88c5  \u524d\u671f\u65f6pip\u5728Windows\u4e0b\u662f\u65e0\u6cd5\u5b89\u88c5\u7684\uff0c\u73b0\u5728\u53ef\u4ee5\u5728python3\u7684\u73af\u5883\u4e0b\u76f4\u63a5 pip install tensorflow \u5373\u53ef\u5b8c\u6210\u5b89\u88c5\u3002\u6781\u529b\u63a8\u8350\u8fd9\u79cd\u5b89\u88c5\u65b9\u5f0f  \u6e90\u7801\u7f16\u8bd1\u5b89\u88c5  \u8fd9\u79cd\u5b89\u88c5\u65b9\u5f0f\u4e0d\u5efa\u8bae\u5927\u5bb6\u91c7\u7528\uff0c\u56e0\u4e3aTensorFlow\u4f9d\u8d56\u4e8e\u5176\u4ed6\u5305\uff0c\u4f60\u9700\u8981\u63d0\u524d\u628a\u5176\u4ed6\u4f9d\u8d56\u5305\u5b89\u88c5\u597d\u4e4b\u540e\u624d\u53ef\u6b63\u5e38\u901a\u8fc7\u6e90\u7801\u5b89\u88c5TF\u3002  \u5b89\u88c5\u597d\u540e\u6d4b\u8bd5\u4e00\u4e0b\u4f60\u7684TensorFlow\u80fd\u5426\u6b63\u5e38\u4f7f\u7528,\u5982\u679c\u6b63\u5e38\u4f7f\u7528\uff0c\u606d\u559c\u4f60\u5b89\u88c5\u6210\u529f\u3002  import tensorflow as tf\na = tf.constant([1.0,2.0],name='a')\nb = tf.constant([2.0,3.0],name='b')\nresult =a + b\n\nsess = tf.session()\nsess.run(result)\nsess.close()",
            "title": "TF\u73af\u5883\u642d\u5efa"
        },
        {
            "location": "/chapter3/",
            "text": "TF\u5165\u95e8\n\n\n\u5173\u4e8etf\u4e2d\u7684\u51fd\u6570\uff0c\u5728\u8fd9\u91cc\u4e0d\u4f1a\u8bb2\u5f88\u591a\uff0c\u81ea\u5df1\u7528\u5230\u53bb\u5b66\u4e60\uff0c\u5e76\u4e14\u6709\u4e9b\u51fd\u6570\u66f4\u65b0\u6bd4\u8f83\u5feb\u4f1a\u66ff\u6362\u6210\u522b\u7684\u51fd\u6570\u540d\u3002\n\n\n1. TF\u8ba1\u7b97\u6a21\u578b--\u8ba1\u7b97\u56fe\n\n\nI \u8ba1\u7b97\u56fe\u7684\u6982\u5ff5\n\n\nTensorFlow\u540d\u5b57\u5c31\u8bf4\u660e\u4e86\u4ed6\u6700\u91cd\u8981\u7684\u4e24\u4e2a\u6982\u5ff5--Tensor\u548cFlow.Tensor\u5c31\u662f\u5f20\u91cf\uff08\u53ef\u7406\u89e3\u4e3a\u591a\u4e3a\u6570\u7ec4\uff09\uff0cFlow(\u6d41)\uff0c\u76f4\u89c2\u7684\u5c55\u73b0\u4e86\u5f20\u91cf\u4e4b\u95f4\u901a\u8fc7\u8ba1\u7b97\u76f8\u4e92\u8f6c\u5316\u7684\u8fc7\u7a0b\u3002TF\u662f\u901a\u8fc7\u8ba1\u7b97\u56fe\u7684\u5f62\u5f0f\u5c55\u73b0\u8ba1\u7b97\u7684\u7f16\u7a0b\u7cfb\u7edf\uff0cTensorFlow\u4e2d\u7684\u6bcf\u4e00\u4e2a\u8ba1\u7b97\u90fd\u662f\u8ba1\u7b97\u56fe\u4e0a\u7684\u4e00\u4e2a\u8282\u70b9\uff0c\u800c\u51e0\u70b9\u4e4b\u95f4\u8fb9\u63cf\u8ff0\u4e86\u8ba1\u7b97\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\n\n\n\n\n\u56fe1\uff1a\u901a\u8fc7TensorBoard\u53ef\u89c6\u5316\u7684\u795e\u7ecf\u5143\u56fe\n\n\nII \u8ba1\u7b97\u56fe\u7684\u4f7f\u7528\n\n\nTensorFlow\u7a0b\u5e8f\u4e00\u822c\u53ef\u4ee5\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff0c\u7b2c\u4e00\u4e2a\u9636\u6bb5\u4e00\u822c\u5b9a\u4e49\u8ba1\u7b97\u56fe\u4e2d\u7684\u6240\u6709\u8ba1\u7b97\uff0c\u6bd4\u5982\u5728\u9a8c\u8bc1TF\u5b89\u88c5\u6210\u529f\u7684\u4ee3\u7801\u4e2d\uff0c\u5148\u5b9a\u4e49\u4e86\u4e24\u4e2a\u8f93\u5165\uff0c\u7136\u540e\u8ba1\u7b97\u4e86\u4e00\u4e2a\u8ba1\u7b97\u5f97\u5230\u4ed6\u4eec\u7684\u548c\u3002\u7b2c\u4e8c\u4e2a\u9636\u6bb5\u4e3a\u6267\u884c\u8ba1\u7b97\uff08\u7b2c3\u8282\u4ecb\u7ecd\uff09\uff0c\u5b9a\u4e49\u9636\u6bb5\u7684\u6837\u4f8b\uff1a\n\n\nimport tensorflow as tf\n\na = tf.constant([1.0,2.0],name='a')\nb = tf.constant([2.0,3.0],name='b')\n\nresult = a + b\n\n\n\n\n\u5728\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\uff0ctf\u4f1a\u81ea\u52a8\u5c06\u5b9a\u4e49\u7684\u8ba1\u7b97\u8f6c\u5316\u4e3a\u8ba1\u7b97\u56fe\u4e0a\u7684\u8282\u70b9\uff0c\u5728TF\u4e2d\u7cfb\u7edf\u4f1a\u81ea\u52a8\u7ef4\u62a4\u4e00\u4e2a\u9ed8\u8ba4\u7684\u8ba1\u7b97\u56fe\uff0c\u901a\u8fc7tf.get_default_graph\u51fd\u6570\u53ef\u4ee5\u83b7\u5f97\u5f53\u524d\u9ed8\u8ba4\u7684\u8ba1\u7b97\u56fe\n\n\n#\u901a\u8fc7a.graph\u53ef\u4ee5\u67e5\u770b\u5f20\u91cf\u6240\u5728\u7684\u8ba1\u7b97\u56fe\nprint(a.graph is tf.get_default_graph())\n\n\n\n\n\u5f53\u7136\u9664\u4e86\u9ed8\u8ba4\u7684\u8ba1\u7b97\u56fe\uff0cTF\u652f\u6301\u901a\u8fc7tf.graph\u51fd\u6570\u6765\u751f\u6210\u65b0\u7684\u8ba1\u7b97\u56fe\u3002\u4e0d\u540c\u8ba1\u7b97\u56fe\u7684\u5f20\u91cf\u548c\u8fd0\u7b97\u90fd\u4e0d\u4f1a\u5171\u4eab\n\n\nimport tensorflow as tf\n\ng1 = tf.Graph()\nwith g1.as_default():\n    #\u5728\u8ba1\u7b97\u56feg1\u4e2d\u5b9a\u4e49\u53d8\u91cfv\n    v = tf.get_variable('v',initializer=tf.zero_initializer(shape=[1]))\n\ng2 = tf.Graph()\nwith g2.as_default():\n    #g2\u4e2d\u5b9a\u4e49v\n    v = tf.get_variable('v',initializer=tf.ones_initializer(shape=[1]))\n\n#g1\u4e2d\u8bfb\u53d6v\nwith tf.Session(graph=g1) as sess:\n    initialize_op = tf.global_variables_initializer ()\n    sess.run(initialize_op)\n    with tf.variable_scope(\"\",reuse=True):\n        print(sess.run(tf.get_variable('v')))\n\n\n\n\n\nTF\u4e2d\u7684\u8ba1\u7b97\u56fe\u4e0d\u4ec5\u53ef\u4ee5\u7528\u6765\u9694\u79bb\u5f20\u91cf\u548c\u8ba1\u7b97\u3002\u8fd8\u63d0\u4f9b\u4e86\u7ba1\u7406\u5f20\u91cf\u548c\u8ba1\u7b97\u7684\u673a\u5236\uff0c\u8ba1\u7b97\u56fe\u53ef\u4ee5\u901a\u8fc7tf.Graph.device\u51fd\u6570\u6765\u6307\u5b9a\u8fd0\u7b97\u8ba1\u7b97\u7684\u8bbe\u5907\uff0c\u8fd9\u4f4dTF\u4f7f\u7528GPU\u63d0\u4f9b\u673a\u5236\u3002\u4e0b\u9762\u7684\u7a0b\u5e8f\u5c06\u52a0\u6cd5\u8dd1\u5728GPU\u4e0a\n\n\ng = tf.Graph()\n#\u6307\u5b9a\u8ba1\u7b97\u8fd0\u884c\u7684\u8bbe\u5907\nwith g.device('/gpu:0'):\n    result = a + b\n\n\n\n\n\u6b64\u5916\u6709\u6548\u7684\u6574\u7406TF\u7a0b\u5e8f\u4e2d\u7684\u8d44\u6e90\u4e5f\u662f\u8ba1\u7b97\u56fe\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u529f\u80fd\u3002\u5728\u4e00\u4e2a\u8ba1\u7b97\u56fe\u4e2d\uff0c\u53ef\u4ee5\u901a\u8fc7\u96c6\u5408\uff08collection)\u6765\u7ba1\u7406\u4e0d\u540c\u7c7b\u522b\u7684\u8d44\u6e90\u3002\u6bd4\u5982\u53ef\u4ee5\u901a\u8fc7tf.add_to_collection\u51fd\u6570\u53ef\u4ee5\u5c06\u8d44\u6e90\u52a0\u5165\u4e00\u4e2a\u6216\u591a\u4e2a\u96c6\u5408\uff0c\u7136\u540e\u901a\u8fc7tf.get_collection\u83b7\u53d6\u4e00\u4e2a\u96c6\u5408\u91cc\u7684\u6240\u6709\u8d44\u6e90\u3002\u8fd9\u91cc\u7684\u8d44\u6e90\u53ef\u4ee5\u662f\u5f20\u91cf\uff0c\u53d8\u91cf\uff0c\u7a0b\u5e8f\u961f\u5217\uff0c\u7b49\u7b49\u3002\n\n\n\n\n2. TF\u6570\u636e\u6a21\u578b--\u5f20\u91cf\n\n\n\u5f20\u91cf\u662fTF\u4e2d\u7ba1\u7406\u6570\u636e\u7684\u5f62\u5f0f\uff0cTF\u4e2d\u6240\u6709\u7684\u6570\u636e\u90fd\u662f\u901a\u8fc7\u5f20\u91cf\u7684\u5f62\u5f0f\u6765\u8868\u793a\u7684\uff0c\u529f\u80fd\u4e0a\u53ef\u4ee5\u628a\u5f20\u91cf\u7406\u89e3\u4e3a\u591a\u7ef4\u6570\u7ec4\uff0c\u96f6\u9636\u5f20\u91cf\u5c31\u662f\u4e00\u4e2a\u6570\uff0c\u4e00\u9636\u5f20\u91cf\u662f\u5411\u91cf\uff081D\u6570\u7ec4\uff09,n\u9636\u5f20\u91cf\u53ef\u4ee5\u7406\u89e3\u4e3anD\u6570\u7ec4\u3002TF\u4e2d\u5e76\u4e0d\u662f\u91c7\u7528\u8fd9\u79cd\u6570\u7ec4\u7684\u5f62\u5f0f\uff0c\u5b83\u53ea\u662f\u5bf9\u8fd0\u7b97\u7ed3\u679c\u7684\u5f15\u7528\uff0c\u5728\u5f20\u91cf\u4e2d\u5e76\u6ca1\u6709\u4fdd\u5b58\u6570\u5b57\uff0c\u5b83\u4fdd\u5b58\u7684\u662f\u5982\u4f55\u5f97\u5230\u8fd9\u4e9b\u6570\u5b57\u7684\u8ba1\u7b97\u8fc7\u7a0b\u3002\n\n\nimport tensorflow as tf\n#tf.constant\u662f\u4e00\u4e2a\u8ba1\u7b97\uff0c\u8fd9\u4e2a\u8ba1\u7b97\u7684\u7ed3\u679c\u4fdd\u5b58\u4e3a\u4e00\u4e2a\u5f20\u91cf\uff0c\u4fdd\u5b58\u5728\u53d8\u91cfa\u4e2d\n\na = tf.constant([1.,2.],name='a')\nb = tf.constant([2.,3.],name='b')\n\nresult = a + b\n\nprint(result)\n\n#\u8f93\u51fa\u7ed3\u679c\uff1a\n\nTensor('add:0',shape=(2,),dtype=float32)\n\n\n\n\n\u4ece\u7ed3\u679c\u53ef\u4ee5\u770b\u51fa\uff0cTF\u548cNumpy\u4e0d\u540c\uff0cTF\u8ba1\u7b97\u7684\u7ed3\u679c\u4e0d\u662f\u4e00\u4e2a\u5177\u4f53\u7684\u6570\uff0c\u800c\u662f\u4e00\u4e2a\u5f20\u91cf\u7ed3\u6784\uff0c\u4e00\u4e2a\u5f20\u91cf\u4e2d\u4e3b\u8981\u7684\u7ed3\u6784\u6709\uff1a\u540d\u5b57\uff0c\u7ef4\u5ea6\uff0c\u7c7b\u578b\u3002\n\n\n\n\n\n\n\u540d\u5b57(name)\uff1a \u662f\u5f20\u91cf\u7684\u552f\u4e00\u6807\u8bc6\uff0c\u540c\u65f6\u7ed9\u51fa\u8fd9\u4e2a\u5f20\u91cf\u662f\u5982\u4f55\u8ba1\u7b97\u51fa\u6765\u7684\uff0c\u5f20\u91cf\u548c\u8ba1\u7b97\u56fe\u8282\u70b9\u6240\u8ba1\u7b97\u7684\u7ed3\u679c\u662f\u5bf9\u5e94\u7684\uff0c\u540d\u5b57\u683c\u5f0f\u4e3a\uff0c\n\u8282\u70b9\u540d\u79f0\uff1a\u5f20\u91cf\u6765\u81ea\u8282\u70b9\u7684\u7b2c\u51e0\u4e2a\u8f93\u51fa\n \uff0cadd:0\u8868\u793aadd\u8282\u70b9\u7684\u8f93\u51fa\u7684\u7b2c\u4e00\u4e2a\u7ed3\u679c\n\n\n\n\n\n\n\u7ef4\u5ea6(shape): \u63cf\u8ff0\u4e86\u5f20\u91cf\u7684\u7ef4\u5ea6\u4fe1\u606f\uff0cshape=(2,)\u8868\u793a\u5f20\u91cf\u662f\u4e00\u4e2a1D\u6570\u7ec4\uff0c\u6570\u7ec4\u7684\u957f\u5ea6\u662f2\uff0c\u7ef4\u5ea6\u662f\u5f20\u91cf\u5f88\u91cd\u8981\u7684\u4e00\u4e2a\u6982\u5ff5\uff08\u4e00\u5b9a\u8981\u6ce8\u610f\uff09\n\n\n\n\n\n\n\u7c7b\u578b(type): \u6bcf\u4e00\u4e2a\u5f20\u91cf\u90fd\u6709\u4e00\u4e2a\u552f\u4e00\u7c7b\u578b\uff0c\u81ea\u52a8\u8fdb\u884c\u7c7b\u578b\u68c0\u67e5\uff0c\u4e0d\u5339\u914d\u4f1a\u62a5\u9519\u7684\n\n\n\n\n\n\nimport tensorflow as tf\na = tf.constant([1,2],name='a')\n#a = tf.constant([1,2],name='a'\uff0cdtype=tf.float32)\nb = tf.constant([2.,3.],name='b')\n\nresult = a + b\n#\u7ed3\u679c\u4f1a\u62a5\u9519\u3002\u3002\u3002\u3002\u3002\u3002\n\n\n\n\n\u6ce8\u610f1\uff1a TF\u652f\u630114\u79cd\u4e0d\u540c\u7684\u6570\u636e\u7c7b\u578b\uff08tf.float32,tf.float64,tf.int8,tf.int16,tf.int32,tf.int64,tf.unit8,tf.bool,tf.complex64,tf.complex128)\n\n\n\u6ce8\u610f2\uff1a \u5f20\u91cf\u7684\u4f7f\u7528\u65b9\u5f0f\uff0ca.\u5bf9\u4e2d\u95f4\u8ba1\u7b97\u7ed3\u679c\u7684\u5f15\u7528\uff08\u5982\u4e0a\u6817\uff09b.\u8ba1\u7b97\u56fe\u6784\u9020\u5b8c\u6210\u540e\uff0c\u5f20\u91cf\u53ef\u4ee5\u83b7\u5f97\u8ba1\u7b97\u7ed3\u679c\uff0c\u5373\u5f97\u5230\u771f\u5b9e\u6570\u5b57\uff0c\u867d\u7136\u5f20\u91cf\u672c\u8eab\u6ca1\u6709\u5b58\u50a8\u5177\u4f53\u6570\u5b57\uff0c\u901a\u8fc7\u4f1a\u8bdd(session)\u5373\u53ef\u5f97\u5230\n\n\ntf.Session().run(result)\n\n\n\n\n\n\n3. TF\u8fd0\u884c\u6a21\u578b--\u4f1a\u8bdd\n\n\nTF\u901a\u8fc7\u4f1a\u8bdd(Session)\u6765\u6267\u884c\u5b9a\u4e49\u597d\u7684\u8fd0\u7b97\u3002\u4f1a\u8bdd\u62e5\u6709\u5e76\u7ba1\u7406TF\u7a0b\u5e8f\u8fd0\u884c\u7684\u6240\u6709\u8d44\u6e90\uff0c\u5f53\u6240\u6709\u8ba1\u7b97\u5b8c\u6210\u540e\u5173\u95ed\u4f1a\u8bdd\u5e2e\u52a9\u7cfb\u7edf\u56de\u6536\u8d44\u6e90\uff0c\u4e00\u822c\u7531\u4e24\u79cd\u4f7f\u7528\u65b9\u5f0f\n\n\n#\u521b\u5efa\u4e00\u4e2a\u4f1a\u8bdd\nsess = tf.Session()\n#\u4f7f\u7528\u521b\u5efa\u597d\u7684\u4f1a\u8bdd\u6765\u5f97\u5230\u81ea\u5df1\u5173\u5fc3\u7684\u8ba1\u7b97\u7ed3\u679c\nsess.run(...)\n#\u5173\u95ed\u4f1a\u8bdd\u4f7f\u5f97\u672c\u6b21\u8fd0\u884c\u4e2d\u4f7f\u7528\u7684\u8d44\u6e90\u53ef\u4ee5\u88ab\u91ca\u653e\nsess.close()\n#\u5f88\u50cf\u6211\u4eecPython\u4e2d\u7684I/O\u7cfb\u7edf\n\n\n\n\n\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u597d\uff0c\u539f\u56e0\u662f\u5f53\u7a0b\u5e8f\u51fa\u73b0\u5f02\u5e38\u5bfc\u81f4\u9000\u51fa\u65f6\uff0c\u5173\u95ed\u4f1a\u8bdd\u53ef\u80fd\u4e0d\u4f1a\u88ab\u6267\u884c\uff0c\u4f1a\u5bfc\u81f4\u8d44\u6e90\u6cc4\u9732\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898TF\u53ef\u4ee5\u901a\u8fc7Python\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\u6765\u4f7f\u7528\u4f1a\u8bdd\n\n\n#\u901a\u8fc7Py\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\u6765\u521b\u5efa\nwith tf.Session() as sess:\n    sess.run(...)\n#\u4e0d\u9700\u8981close()\u5f53\u9000\u51fa\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\u65f6\u8d44\u6e90\u4f1a\u88ab\u81ea\u52a8\u91ca\u653e\n\n\n\n\n\u4e0a\u6587\u4e2d\u4ecb\u7ecd\u4e86TF\u4f1a\u81ea\u52a8\u751f\u6210\u4e00\u4e2a\u9ed8\u8ba4\u7684\u8ba1\u7b97\u56fe\uff0c\u5982\u679c\u8ba1\u7b97\u56fe\u6ca1\u6709\u88ab\u6307\u5b9a\u8fd0\u7b97\u4f1a\u81ea\u52a8\u52a0\u5165\u5230\u9ed8\u8ba4\u8ba1\u7b97\u56fe\u4e2d\uff0cTF\u7684\u4f1a\u8bdd\u4e5f\u6709\u7c7b\u4f3c\u7684\u673a\u5236\uff0c\u4f46TF\u4e0d\u4f1a\u751f\u6210\u9ed8\u8ba4\u4f1a\u8bdd\uff0c\u9700\u8981\u624b\u52a8\u6307\u5b9a\uff0c\u9ed8\u8ba4\u4f1a\u8bdd\u6307\u5b9a\u540e\u53ef\u4ee5\u901a\u8fc7tf.Tensr.eval\u51fd\u6570\u6765\u8ba1\u7b97\u4e00\u4e2a\u5f20\u91cf\u7684\u53d6\u503c\n\n\nsess = tf.session()\nwith sess.as_default():\n    print(result.eval())\n    print(sess.run(result))\n\n\n\n\n\u800c\u5728\u4e00\u4e9b\u4ea4\u4e92\u7684\u811a\u672c\u73af\u5883\u4e2d(Ipython,jupyter),\u901a\u8fc7\u8fd9\u79cd\u9ed8\u8ba4\u65b9\u5f0f\u6765\u83b7\u53d6\u5f20\u91cf\u7684\u53d6\u503c\u4f1a\u66f4\u65b9\u4fbf\uff0c\u6240\u4ee5TF\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728\u4ea4\u4e92\u73af\u5883\u4e0b\u76f4\u63a5\u6784\u5efa\u9ed8\u8ba4\u4f1a\u8bdd\u7684\u51fd\u6570\uff1atf.InteractiveSession()\n\n\nsess = tf.InteractiveSession()\nprint(result.eval())\nsess.close()\n\n\n\n\n\u6ce8\u610f\uff1a\u65e0\u8bba\u4f7f\u7528\u54ea\u79cd\u65b9\u6cd5\u90fd\u53ef\u4ee5\u901a\u8fc7ConfigProto Protocol Buffer\u6765\u914d\u7f6e\u9700\u8981\u751f\u6210\u7684\u4f1a\u8bdd\n\n\nconfig = tf.ConfigProto(all_solft_placement = True,log_device_placement=True)\n#all_solft_placement GPU \u81ea\u52a8\u8df3\u8f6cCPU\n#log_device_placement=True \u65e5\u5fd7\u4e2d\u8bb0\u5f55\u6bcf\u4e2a\u8282\u70b9\u8ba1\u7b97\u88ab\u5b89\u6392\u5728\u54ea\u4e2a\u8bbe\u5907\nsess1 = tf.InteractiveSession(config = config)\nsess2 = tf.Session(config = config)\n\n\n\n\n\n\n4. TF\u6e38\u4e50\u573a\n\n\nTensorFlow\u6e38\u4e50\u573a(http://playground.tensorflow.org)\u662f\u901a\u8fc7\u7f51\u9875\u6d4f\u89c8\u5668\u53ef\u4ee5\u8bad\u7ec3\u7b80\u5355\u795e\u7ecf\u7f51\u7edc\u7684\u53ef\u89c6\u5316\u5de5\u5177\n\n\n\n\n\u56fe2\uff1aTensorFlow\u6e38\u4e50\u573a\u622a\u56fe",
            "title": "TensorFlow\u5165\u95e8"
        },
        {
            "location": "/chapter3/#tf",
            "text": "\u5173\u4e8etf\u4e2d\u7684\u51fd\u6570\uff0c\u5728\u8fd9\u91cc\u4e0d\u4f1a\u8bb2\u5f88\u591a\uff0c\u81ea\u5df1\u7528\u5230\u53bb\u5b66\u4e60\uff0c\u5e76\u4e14\u6709\u4e9b\u51fd\u6570\u66f4\u65b0\u6bd4\u8f83\u5feb\u4f1a\u66ff\u6362\u6210\u522b\u7684\u51fd\u6570\u540d\u3002  1. TF\u8ba1\u7b97\u6a21\u578b--\u8ba1\u7b97\u56fe  I \u8ba1\u7b97\u56fe\u7684\u6982\u5ff5  TensorFlow\u540d\u5b57\u5c31\u8bf4\u660e\u4e86\u4ed6\u6700\u91cd\u8981\u7684\u4e24\u4e2a\u6982\u5ff5--Tensor\u548cFlow.Tensor\u5c31\u662f\u5f20\u91cf\uff08\u53ef\u7406\u89e3\u4e3a\u591a\u4e3a\u6570\u7ec4\uff09\uff0cFlow(\u6d41)\uff0c\u76f4\u89c2\u7684\u5c55\u73b0\u4e86\u5f20\u91cf\u4e4b\u95f4\u901a\u8fc7\u8ba1\u7b97\u76f8\u4e92\u8f6c\u5316\u7684\u8fc7\u7a0b\u3002TF\u662f\u901a\u8fc7\u8ba1\u7b97\u56fe\u7684\u5f62\u5f0f\u5c55\u73b0\u8ba1\u7b97\u7684\u7f16\u7a0b\u7cfb\u7edf\uff0cTensorFlow\u4e2d\u7684\u6bcf\u4e00\u4e2a\u8ba1\u7b97\u90fd\u662f\u8ba1\u7b97\u56fe\u4e0a\u7684\u4e00\u4e2a\u8282\u70b9\uff0c\u800c\u51e0\u70b9\u4e4b\u95f4\u8fb9\u63cf\u8ff0\u4e86\u8ba1\u7b97\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb   \u56fe1\uff1a\u901a\u8fc7TensorBoard\u53ef\u89c6\u5316\u7684\u795e\u7ecf\u5143\u56fe  II \u8ba1\u7b97\u56fe\u7684\u4f7f\u7528  TensorFlow\u7a0b\u5e8f\u4e00\u822c\u53ef\u4ee5\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff0c\u7b2c\u4e00\u4e2a\u9636\u6bb5\u4e00\u822c\u5b9a\u4e49\u8ba1\u7b97\u56fe\u4e2d\u7684\u6240\u6709\u8ba1\u7b97\uff0c\u6bd4\u5982\u5728\u9a8c\u8bc1TF\u5b89\u88c5\u6210\u529f\u7684\u4ee3\u7801\u4e2d\uff0c\u5148\u5b9a\u4e49\u4e86\u4e24\u4e2a\u8f93\u5165\uff0c\u7136\u540e\u8ba1\u7b97\u4e86\u4e00\u4e2a\u8ba1\u7b97\u5f97\u5230\u4ed6\u4eec\u7684\u548c\u3002\u7b2c\u4e8c\u4e2a\u9636\u6bb5\u4e3a\u6267\u884c\u8ba1\u7b97\uff08\u7b2c3\u8282\u4ecb\u7ecd\uff09\uff0c\u5b9a\u4e49\u9636\u6bb5\u7684\u6837\u4f8b\uff1a  import tensorflow as tf\n\na = tf.constant([1.0,2.0],name='a')\nb = tf.constant([2.0,3.0],name='b')\n\nresult = a + b  \u5728\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\uff0ctf\u4f1a\u81ea\u52a8\u5c06\u5b9a\u4e49\u7684\u8ba1\u7b97\u8f6c\u5316\u4e3a\u8ba1\u7b97\u56fe\u4e0a\u7684\u8282\u70b9\uff0c\u5728TF\u4e2d\u7cfb\u7edf\u4f1a\u81ea\u52a8\u7ef4\u62a4\u4e00\u4e2a\u9ed8\u8ba4\u7684\u8ba1\u7b97\u56fe\uff0c\u901a\u8fc7tf.get_default_graph\u51fd\u6570\u53ef\u4ee5\u83b7\u5f97\u5f53\u524d\u9ed8\u8ba4\u7684\u8ba1\u7b97\u56fe  #\u901a\u8fc7a.graph\u53ef\u4ee5\u67e5\u770b\u5f20\u91cf\u6240\u5728\u7684\u8ba1\u7b97\u56fe\nprint(a.graph is tf.get_default_graph())  \u5f53\u7136\u9664\u4e86\u9ed8\u8ba4\u7684\u8ba1\u7b97\u56fe\uff0cTF\u652f\u6301\u901a\u8fc7tf.graph\u51fd\u6570\u6765\u751f\u6210\u65b0\u7684\u8ba1\u7b97\u56fe\u3002\u4e0d\u540c\u8ba1\u7b97\u56fe\u7684\u5f20\u91cf\u548c\u8fd0\u7b97\u90fd\u4e0d\u4f1a\u5171\u4eab  import tensorflow as tf\n\ng1 = tf.Graph()\nwith g1.as_default():\n    #\u5728\u8ba1\u7b97\u56feg1\u4e2d\u5b9a\u4e49\u53d8\u91cfv\n    v = tf.get_variable('v',initializer=tf.zero_initializer(shape=[1]))\n\ng2 = tf.Graph()\nwith g2.as_default():\n    #g2\u4e2d\u5b9a\u4e49v\n    v = tf.get_variable('v',initializer=tf.ones_initializer(shape=[1]))\n\n#g1\u4e2d\u8bfb\u53d6v\nwith tf.Session(graph=g1) as sess:\n    initialize_op = tf.global_variables_initializer ()\n    sess.run(initialize_op)\n    with tf.variable_scope(\"\",reuse=True):\n        print(sess.run(tf.get_variable('v')))  TF\u4e2d\u7684\u8ba1\u7b97\u56fe\u4e0d\u4ec5\u53ef\u4ee5\u7528\u6765\u9694\u79bb\u5f20\u91cf\u548c\u8ba1\u7b97\u3002\u8fd8\u63d0\u4f9b\u4e86\u7ba1\u7406\u5f20\u91cf\u548c\u8ba1\u7b97\u7684\u673a\u5236\uff0c\u8ba1\u7b97\u56fe\u53ef\u4ee5\u901a\u8fc7tf.Graph.device\u51fd\u6570\u6765\u6307\u5b9a\u8fd0\u7b97\u8ba1\u7b97\u7684\u8bbe\u5907\uff0c\u8fd9\u4f4dTF\u4f7f\u7528GPU\u63d0\u4f9b\u673a\u5236\u3002\u4e0b\u9762\u7684\u7a0b\u5e8f\u5c06\u52a0\u6cd5\u8dd1\u5728GPU\u4e0a  g = tf.Graph()\n#\u6307\u5b9a\u8ba1\u7b97\u8fd0\u884c\u7684\u8bbe\u5907\nwith g.device('/gpu:0'):\n    result = a + b  \u6b64\u5916\u6709\u6548\u7684\u6574\u7406TF\u7a0b\u5e8f\u4e2d\u7684\u8d44\u6e90\u4e5f\u662f\u8ba1\u7b97\u56fe\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u529f\u80fd\u3002\u5728\u4e00\u4e2a\u8ba1\u7b97\u56fe\u4e2d\uff0c\u53ef\u4ee5\u901a\u8fc7\u96c6\u5408\uff08collection)\u6765\u7ba1\u7406\u4e0d\u540c\u7c7b\u522b\u7684\u8d44\u6e90\u3002\u6bd4\u5982\u53ef\u4ee5\u901a\u8fc7tf.add_to_collection\u51fd\u6570\u53ef\u4ee5\u5c06\u8d44\u6e90\u52a0\u5165\u4e00\u4e2a\u6216\u591a\u4e2a\u96c6\u5408\uff0c\u7136\u540e\u901a\u8fc7tf.get_collection\u83b7\u53d6\u4e00\u4e2a\u96c6\u5408\u91cc\u7684\u6240\u6709\u8d44\u6e90\u3002\u8fd9\u91cc\u7684\u8d44\u6e90\u53ef\u4ee5\u662f\u5f20\u91cf\uff0c\u53d8\u91cf\uff0c\u7a0b\u5e8f\u961f\u5217\uff0c\u7b49\u7b49\u3002   2. TF\u6570\u636e\u6a21\u578b--\u5f20\u91cf  \u5f20\u91cf\u662fTF\u4e2d\u7ba1\u7406\u6570\u636e\u7684\u5f62\u5f0f\uff0cTF\u4e2d\u6240\u6709\u7684\u6570\u636e\u90fd\u662f\u901a\u8fc7\u5f20\u91cf\u7684\u5f62\u5f0f\u6765\u8868\u793a\u7684\uff0c\u529f\u80fd\u4e0a\u53ef\u4ee5\u628a\u5f20\u91cf\u7406\u89e3\u4e3a\u591a\u7ef4\u6570\u7ec4\uff0c\u96f6\u9636\u5f20\u91cf\u5c31\u662f\u4e00\u4e2a\u6570\uff0c\u4e00\u9636\u5f20\u91cf\u662f\u5411\u91cf\uff081D\u6570\u7ec4\uff09,n\u9636\u5f20\u91cf\u53ef\u4ee5\u7406\u89e3\u4e3anD\u6570\u7ec4\u3002TF\u4e2d\u5e76\u4e0d\u662f\u91c7\u7528\u8fd9\u79cd\u6570\u7ec4\u7684\u5f62\u5f0f\uff0c\u5b83\u53ea\u662f\u5bf9\u8fd0\u7b97\u7ed3\u679c\u7684\u5f15\u7528\uff0c\u5728\u5f20\u91cf\u4e2d\u5e76\u6ca1\u6709\u4fdd\u5b58\u6570\u5b57\uff0c\u5b83\u4fdd\u5b58\u7684\u662f\u5982\u4f55\u5f97\u5230\u8fd9\u4e9b\u6570\u5b57\u7684\u8ba1\u7b97\u8fc7\u7a0b\u3002  import tensorflow as tf\n#tf.constant\u662f\u4e00\u4e2a\u8ba1\u7b97\uff0c\u8fd9\u4e2a\u8ba1\u7b97\u7684\u7ed3\u679c\u4fdd\u5b58\u4e3a\u4e00\u4e2a\u5f20\u91cf\uff0c\u4fdd\u5b58\u5728\u53d8\u91cfa\u4e2d\n\na = tf.constant([1.,2.],name='a')\nb = tf.constant([2.,3.],name='b')\n\nresult = a + b\n\nprint(result)\n\n#\u8f93\u51fa\u7ed3\u679c\uff1a\n\nTensor('add:0',shape=(2,),dtype=float32)  \u4ece\u7ed3\u679c\u53ef\u4ee5\u770b\u51fa\uff0cTF\u548cNumpy\u4e0d\u540c\uff0cTF\u8ba1\u7b97\u7684\u7ed3\u679c\u4e0d\u662f\u4e00\u4e2a\u5177\u4f53\u7684\u6570\uff0c\u800c\u662f\u4e00\u4e2a\u5f20\u91cf\u7ed3\u6784\uff0c\u4e00\u4e2a\u5f20\u91cf\u4e2d\u4e3b\u8981\u7684\u7ed3\u6784\u6709\uff1a\u540d\u5b57\uff0c\u7ef4\u5ea6\uff0c\u7c7b\u578b\u3002    \u540d\u5b57(name)\uff1a \u662f\u5f20\u91cf\u7684\u552f\u4e00\u6807\u8bc6\uff0c\u540c\u65f6\u7ed9\u51fa\u8fd9\u4e2a\u5f20\u91cf\u662f\u5982\u4f55\u8ba1\u7b97\u51fa\u6765\u7684\uff0c\u5f20\u91cf\u548c\u8ba1\u7b97\u56fe\u8282\u70b9\u6240\u8ba1\u7b97\u7684\u7ed3\u679c\u662f\u5bf9\u5e94\u7684\uff0c\u540d\u5b57\u683c\u5f0f\u4e3a\uff0c \u8282\u70b9\u540d\u79f0\uff1a\u5f20\u91cf\u6765\u81ea\u8282\u70b9\u7684\u7b2c\u51e0\u4e2a\u8f93\u51fa  \uff0cadd:0\u8868\u793aadd\u8282\u70b9\u7684\u8f93\u51fa\u7684\u7b2c\u4e00\u4e2a\u7ed3\u679c    \u7ef4\u5ea6(shape): \u63cf\u8ff0\u4e86\u5f20\u91cf\u7684\u7ef4\u5ea6\u4fe1\u606f\uff0cshape=(2,)\u8868\u793a\u5f20\u91cf\u662f\u4e00\u4e2a1D\u6570\u7ec4\uff0c\u6570\u7ec4\u7684\u957f\u5ea6\u662f2\uff0c\u7ef4\u5ea6\u662f\u5f20\u91cf\u5f88\u91cd\u8981\u7684\u4e00\u4e2a\u6982\u5ff5\uff08\u4e00\u5b9a\u8981\u6ce8\u610f\uff09    \u7c7b\u578b(type): \u6bcf\u4e00\u4e2a\u5f20\u91cf\u90fd\u6709\u4e00\u4e2a\u552f\u4e00\u7c7b\u578b\uff0c\u81ea\u52a8\u8fdb\u884c\u7c7b\u578b\u68c0\u67e5\uff0c\u4e0d\u5339\u914d\u4f1a\u62a5\u9519\u7684    import tensorflow as tf\na = tf.constant([1,2],name='a')\n#a = tf.constant([1,2],name='a'\uff0cdtype=tf.float32)\nb = tf.constant([2.,3.],name='b')\n\nresult = a + b\n#\u7ed3\u679c\u4f1a\u62a5\u9519\u3002\u3002\u3002\u3002\u3002\u3002  \u6ce8\u610f1\uff1a TF\u652f\u630114\u79cd\u4e0d\u540c\u7684\u6570\u636e\u7c7b\u578b\uff08tf.float32,tf.float64,tf.int8,tf.int16,tf.int32,tf.int64,tf.unit8,tf.bool,tf.complex64,tf.complex128)  \u6ce8\u610f2\uff1a \u5f20\u91cf\u7684\u4f7f\u7528\u65b9\u5f0f\uff0ca.\u5bf9\u4e2d\u95f4\u8ba1\u7b97\u7ed3\u679c\u7684\u5f15\u7528\uff08\u5982\u4e0a\u6817\uff09b.\u8ba1\u7b97\u56fe\u6784\u9020\u5b8c\u6210\u540e\uff0c\u5f20\u91cf\u53ef\u4ee5\u83b7\u5f97\u8ba1\u7b97\u7ed3\u679c\uff0c\u5373\u5f97\u5230\u771f\u5b9e\u6570\u5b57\uff0c\u867d\u7136\u5f20\u91cf\u672c\u8eab\u6ca1\u6709\u5b58\u50a8\u5177\u4f53\u6570\u5b57\uff0c\u901a\u8fc7\u4f1a\u8bdd(session)\u5373\u53ef\u5f97\u5230  tf.Session().run(result)   3. TF\u8fd0\u884c\u6a21\u578b--\u4f1a\u8bdd  TF\u901a\u8fc7\u4f1a\u8bdd(Session)\u6765\u6267\u884c\u5b9a\u4e49\u597d\u7684\u8fd0\u7b97\u3002\u4f1a\u8bdd\u62e5\u6709\u5e76\u7ba1\u7406TF\u7a0b\u5e8f\u8fd0\u884c\u7684\u6240\u6709\u8d44\u6e90\uff0c\u5f53\u6240\u6709\u8ba1\u7b97\u5b8c\u6210\u540e\u5173\u95ed\u4f1a\u8bdd\u5e2e\u52a9\u7cfb\u7edf\u56de\u6536\u8d44\u6e90\uff0c\u4e00\u822c\u7531\u4e24\u79cd\u4f7f\u7528\u65b9\u5f0f  #\u521b\u5efa\u4e00\u4e2a\u4f1a\u8bdd\nsess = tf.Session()\n#\u4f7f\u7528\u521b\u5efa\u597d\u7684\u4f1a\u8bdd\u6765\u5f97\u5230\u81ea\u5df1\u5173\u5fc3\u7684\u8ba1\u7b97\u7ed3\u679c\nsess.run(...)\n#\u5173\u95ed\u4f1a\u8bdd\u4f7f\u5f97\u672c\u6b21\u8fd0\u884c\u4e2d\u4f7f\u7528\u7684\u8d44\u6e90\u53ef\u4ee5\u88ab\u91ca\u653e\nsess.close()\n#\u5f88\u50cf\u6211\u4eecPython\u4e2d\u7684I/O\u7cfb\u7edf  \u8fd9\u79cd\u65b9\u6cd5\u4e0d\u597d\uff0c\u539f\u56e0\u662f\u5f53\u7a0b\u5e8f\u51fa\u73b0\u5f02\u5e38\u5bfc\u81f4\u9000\u51fa\u65f6\uff0c\u5173\u95ed\u4f1a\u8bdd\u53ef\u80fd\u4e0d\u4f1a\u88ab\u6267\u884c\uff0c\u4f1a\u5bfc\u81f4\u8d44\u6e90\u6cc4\u9732\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898TF\u53ef\u4ee5\u901a\u8fc7Python\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\u6765\u4f7f\u7528\u4f1a\u8bdd  #\u901a\u8fc7Py\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\u6765\u521b\u5efa\nwith tf.Session() as sess:\n    sess.run(...)\n#\u4e0d\u9700\u8981close()\u5f53\u9000\u51fa\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\u65f6\u8d44\u6e90\u4f1a\u88ab\u81ea\u52a8\u91ca\u653e  \u4e0a\u6587\u4e2d\u4ecb\u7ecd\u4e86TF\u4f1a\u81ea\u52a8\u751f\u6210\u4e00\u4e2a\u9ed8\u8ba4\u7684\u8ba1\u7b97\u56fe\uff0c\u5982\u679c\u8ba1\u7b97\u56fe\u6ca1\u6709\u88ab\u6307\u5b9a\u8fd0\u7b97\u4f1a\u81ea\u52a8\u52a0\u5165\u5230\u9ed8\u8ba4\u8ba1\u7b97\u56fe\u4e2d\uff0cTF\u7684\u4f1a\u8bdd\u4e5f\u6709\u7c7b\u4f3c\u7684\u673a\u5236\uff0c\u4f46TF\u4e0d\u4f1a\u751f\u6210\u9ed8\u8ba4\u4f1a\u8bdd\uff0c\u9700\u8981\u624b\u52a8\u6307\u5b9a\uff0c\u9ed8\u8ba4\u4f1a\u8bdd\u6307\u5b9a\u540e\u53ef\u4ee5\u901a\u8fc7tf.Tensr.eval\u51fd\u6570\u6765\u8ba1\u7b97\u4e00\u4e2a\u5f20\u91cf\u7684\u53d6\u503c  sess = tf.session()\nwith sess.as_default():\n    print(result.eval())\n    print(sess.run(result))  \u800c\u5728\u4e00\u4e9b\u4ea4\u4e92\u7684\u811a\u672c\u73af\u5883\u4e2d(Ipython,jupyter),\u901a\u8fc7\u8fd9\u79cd\u9ed8\u8ba4\u65b9\u5f0f\u6765\u83b7\u53d6\u5f20\u91cf\u7684\u53d6\u503c\u4f1a\u66f4\u65b9\u4fbf\uff0c\u6240\u4ee5TF\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728\u4ea4\u4e92\u73af\u5883\u4e0b\u76f4\u63a5\u6784\u5efa\u9ed8\u8ba4\u4f1a\u8bdd\u7684\u51fd\u6570\uff1atf.InteractiveSession()  sess = tf.InteractiveSession()\nprint(result.eval())\nsess.close()  \u6ce8\u610f\uff1a\u65e0\u8bba\u4f7f\u7528\u54ea\u79cd\u65b9\u6cd5\u90fd\u53ef\u4ee5\u901a\u8fc7ConfigProto Protocol Buffer\u6765\u914d\u7f6e\u9700\u8981\u751f\u6210\u7684\u4f1a\u8bdd  config = tf.ConfigProto(all_solft_placement = True,log_device_placement=True)\n#all_solft_placement GPU \u81ea\u52a8\u8df3\u8f6cCPU\n#log_device_placement=True \u65e5\u5fd7\u4e2d\u8bb0\u5f55\u6bcf\u4e2a\u8282\u70b9\u8ba1\u7b97\u88ab\u5b89\u6392\u5728\u54ea\u4e2a\u8bbe\u5907\nsess1 = tf.InteractiveSession(config = config)\nsess2 = tf.Session(config = config)   4. TF\u6e38\u4e50\u573a  TensorFlow\u6e38\u4e50\u573a(http://playground.tensorflow.org)\u662f\u901a\u8fc7\u7f51\u9875\u6d4f\u89c8\u5668\u53ef\u4ee5\u8bad\u7ec3\u7b80\u5355\u795e\u7ecf\u7f51\u7edc\u7684\u53ef\u89c6\u5316\u5de5\u5177   \u56fe2\uff1aTensorFlow\u6e38\u4e50\u573a\u622a\u56fe",
            "title": "TF\u5165\u95e8"
        },
        {
            "location": "/chapter4/",
            "text": "TF\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u4e3e\u4f8b\n\n\n\u7528TensorFlow\u505a\u673a\u5668\u5b66\u4e60\u5e76\u4e0d\u662f\u4e00\u4e2a\u597d\u7684\u9009\u62e9\uff0cPython\u4e2d\u670920\u591a\u4e2a\u6a21\u5757\u505a\u673a\u5668\u5b66\u4e60\uff0c\u7b80\u5355\u7684\u56de\u5f52\u6765\u8bf4\u53ef\u4ee5\u4f7f\u7528statsmodels\u548csklearn\uff0c\u8981\u6bd4\u7528TF\u66f4\u4fbf\u6377\u3002\u4e3a\u4e86\u4f53\u73b0TF\u7684\u5176\u5728\u673a\u5668\u5b66\u4e60\u7684\u4f5c\u7528\uff0c\u6211\u4eec\u4ee5\u7b80\u5355\u7684\u5f39\u6027\u7f51\u56de\u5f52\u548clogistic\u56de\u5f52\u4e3a\u4f8b\u770b\u4e00\u770b\u5982\u4f55\u4f7f\u7528TF\u505a\u673a\u5668\u5b66\u4e60\uff08\u6211\u7684GitHub\u4e0a\u6258\u7ba1\u4e86\u7528TensorFlow\u5b9e\u73b0\u5e38\u7528\u673a\u5668\u5b66\u4e60\u7684\u6240\u6709\u6e90\u4ee3\u7801\uff0c\u6bd4\u5982\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u51b3\u7b56\u6811\uff0cKNN,SVM\u53ca\u975e\u76d1\u7763\u5b66\u4e60\u7684\u4e00\u4e9b\u7b97\u6cd5\uff0c\u53ef\u5728\u6211\u7684GitHub\u4e3b\u9875\u4e2d\u627e\u5230\uff09\n\n\n1.TF\u505a\u5f39\u6027\u7f51\u56de\u5f52\n\n\n\u76f4\u63a5\u4e0a\u4ee3\u7801\uff0c\u8fb9\u770b\u6211\u4eec\u8fb9\u89e3\u91ca\n\n\n\n# Elastic Net Regression\n#----------------------------------\n\n# y = Ax + b\n#  y = Sepal Length\n#  x = Pedal Length, Petal Width, Sepal Width\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn import datasets\nfrom tensorflow.python.framework import ops\n\n\nops.reset_default_graph()\n# \u521b\u5efa\u8ba1\u7b97\u56fe\nsess = tf.Session()\n\n# \u52a0\u8f7d\u6570\u636e\n# iris.data = [(Sepal Length, Sepal Width, Petal Length, Petal Width)]\niris = datasets.load_iris()\nx_vals = np.array([[x[1], x[2], x[3]] for x in iris.data])\ny_vals = np.array([y[0] for y in iris.data])\n\n#\u5efa\u6a21\n\nseed = 13\nnp.random.seed(seed)\ntf.set_random_seed(seed)\n\nbatch_size = 50\n\n# \u521d\u59cb\u5316 placeholders  \u5565\u662fplaceholders?\nx_data = tf.placeholder(shape=[None, 3], dtype=tf.float32)\ny_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n\n# \u521d\u59cb\u5316\u53d8\u91cf\nA = tf.Variable(tf.random_normal(shape=[3,1]))\nb = tf.Variable(tf.random_normal(shape=[1,1]))\n\n# \u5b9a\u4e49\u6a21\u578b y=AX+b\nmodel_output = tf.add(tf.matmul(x_data, A), b)\n\n# \u5b9a\u4e49\u6210\u672c\u51fd\u6570\nelastic_param1 = tf.constant(1.)\nelastic_param2 = tf.constant(1.)\nl1_a_loss = tf.reduce_mean(tf.abs(A))\nl2_a_loss = tf.reduce_mean(tf.square(A))\ne1_term = tf.multiply(elastic_param1, l1_a_loss)\ne2_term = tf.multiply(elastic_param2, l2_a_loss)\n#\u8fd9\u4e00\u5768\u8c01\u80fd\u7ed9\u6211\u89e3\u91ca\u4e00\u4e0b\uff1f\nloss = tf.expand_dims(tf.add(tf.add(tf.reduce_mean(tf.square(y_target - model_output)), e1_term), e2_term), 0)\n\n# \u58f0\u660e\u4f18\u5316\u7b97\u6cd5\uff08\u4f18\u5316\u5668\u58f0\u660e\uff09\u6ce8\u610f\u5f20\u91cf\u7684\u4f20\u9012\u5173\u7cfb\uff01\uff01\uff01\nmy_opt = tf.train.GradientDescentOptimizer(0.001)\ntrain_step = my_opt.minimize(loss)\n\n#---------\u4e0a\u8fb9\u7684\u8fc7\u7a0b\u53ef\u4ee5\u7406\u89e3\u4e3a\u6211\u4eec\u94fa\u597d\u4e86\u7ba1\u9053\uff0c\u4f46\u662f\u7ba1\u9053\u91cc\u6211\u4eec\u8fd8\u6ca1\u6709\u653e\u6c34-----\n\n#\u5f00\u59cb\u653e\u6c34\uff08\u6a21\u578b\u8bad\u7ec3\uff09\n# \u521d\u59cb\u5316\u53d8\u91cf2\u53e5\uff0c\u662f\u6a21\u677f\u8981\u8bb0\u4f4f\ninit = tf.global_variables_initializer()\nsess.run(init)  \n\n# \u8bad\u7ec3\u7684\u8fc7\u7a0b\nloss_vec = []\nfor i in range(1000):\n    rand_index = np.random.choice(len(x_vals), size=batch_size)\n    rand_x = x_vals[rand_index]\n    rand_y = np.transpose([y_vals[rand_index]])  #\u90a3\u4e48\u7b80\u5355\u5c0f\u95ee\u9898\u6765\u4e86\uff0c\u4e3a\u5565\u8981\u8f6c\u7f6e\uff1f\n    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y}) #\u5411\u5bb9\u5668\u5185\u704c\u6c34\n    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n    loss_vec.append(temp_loss[0])\n    if (i+1)%250==0:\n        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)) + ' b = ' + str(sess.run(b)))\n        #\u4e0a\u884c\u4ee3\u7801\uff0c\u4f53\u73b0\u4e86\u5f20\u91cf\u548c\u6570\u7ec4\u7684\u533a\u522b\n        print('Loss = ' + str(temp_loss))\n\n#\u63d0\u53d6\u6a21\u578b\u6700\u7ec8\u7ed3\u679c\n\n[[sw_coef], [pl_coef], [pw_ceof]] = sess.run(A)\n[y_intercept] = sess.run(b)\n\n\u53ef\u89c6\u5316\u6211\u7684\u6a21\u578b\n\nplt.plot(loss_vec, 'k-')\nplt.title(\"XUJING's Loss per Generation\")\nplt.xlabel('Generation')\nplt.ylabel('Loss')\nplt.show()\n\nsess.close()\n\n\n\n\n\n\n\n2.TF\u505aLogsitic\u56de\u5f52\n\n\n\u592a\u719f\u4e0d\u8fc7\u7684model\uff0c\u76f4\u63a5\u4ee3\u7801\u5427\n\n\n# Logistic Regression\n#----------------------------------\n#\n# y = sigmoid(Ax + b)\n#\n#  y = 0 or 1 \n#  x = demographic and medical history data\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport requests\nfrom tensorflow.python.framework import ops\nimport os.path\nimport csv\n\n\nops.reset_default_graph()\n\n# \u521b\u5efa\u8ba1\u7b97\u56fe\nsess = tf.Session()\n\n# \u6570\u636e\u5bfc\u5165\nbirth_weight_file = 'birth_weight.csv'\n\n# \u4f60\u6ca1\u6709\u6570\u636e\u544a\u8bc9\u4f60\u600e\u4e48\u4e0b\u8f7d\nif not os.path.exists(birth_weight_file):\n    birthdata_url = 'https://github.com/DataXujing/tensorflow_cookbook/raw/master/01_Introduction/07_Working_with_Data_Sources/birthweight_data/birthweight.dat'\n    birth_file = requests.get(birthdata_url)\n    birth_data = birth_file.text.split('\\r\\n')\n    birth_header = birth_data[0].split('\\t')\n    birth_data = [[float(x) for x in y.split('\\t') if len(x)>=1] for y in birth_data[1:] if len(y)>=1]\n    with open(birth_weight_file, \"w\") as f:\n        writer = csv.writer(f)\n        writer.writerow(birth_header)\n        writer.writerows(birth_data)\n        f.close()\n\n# \u628a\u4e0b\u597d\u7684\u6570\u636e\u8bfb\u5230\u5185\u5b58\u91cc\u53bb\nbirth_data = []\nwith open(birth_weight_file, newline='') as csvfile:\n     csv_reader = csv.reader(csvfile)\n     birth_header = next(csv_reader)  #\u4e3a\u4ec0\u4e48\u53ef\u4ee5\u7528next()?\n     for row in csv_reader:\n         birth_data.append(row)\n\nbirth_data = [[float(x) for x in row] for row in birth_data]\n\n# \u628alabel\u62ff\u51fa\u6765\ny_vals = np.array([x[0] for x in birth_data])\n# \u62ff\u51faX_vals(not id, not target, and not birthweight)\nx_vals = np.array([x[1:8] for x in birth_data])\n\n# \u8bbe\u7f6e\u968f\u673a\u6570\u79cd\u5b50\nseed = 99\nnp.random.seed(seed)\ntf.set_random_seed(seed)\n\n#\u5212\u5206\u6570\u636e\u96c6 train/test = 80%/20%\ntrain_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)\ntest_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\nx_vals_train = x_vals[train_indices]\nx_vals_test = x_vals[test_indices]\ny_vals_train = y_vals[train_indices]\ny_vals_test = y_vals[test_indices]\n\n# \u6309\u5217\u505a\u5f52\u4e00\u5316\ndef normalize_cols(m):\n    col_max = m.max(axis=0)\n    col_min = m.min(axis=0)\n    return (m-col_min) / (col_max - col_min)\n\nx_vals_train = np.nan_to_num(normalize_cols(x_vals_train))\nx_vals_test = np.nan_to_num(normalize_cols(x_vals_test))\n\n#\u4ee5\u4e0a\u90fd\u662f\u6bd4\u8f83\u4f20\u7edf\u7684Py\u4ee3\u7801\u6ca1\u4ec0\u4e48\u96be\u70b9\n\n#\u5f00\u59cb\u4e0atf\n\n\nbatch_size = 25\n\n# \u521d\u59cb\u5316 placeholders\nx_data = tf.placeholder(shape=[None, 7], dtype=tf.float32) #None\u662f\u5565\u4e1c\u4e1c\uff1f\ny_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n\n# \u521d\u59cb\u5316\u53d8\u91cf\uff08\u597d\u591a\u79cd\u521d\u59cb\u5316\u53d8\u91cf\u7684\u65b9\u6cd5\u3002\u3002\u3002\u3002\u3002\uff09\nA = tf.Variable(tf.random_normal(shape=[7,1]))\nb = tf.Variable(tf.random_normal(shape=[1,1]))\n\n# \u5b9a\u4e49\u6a21\u578b \u4e0d\u662fy = sigmoid(Ax + b)\uff1f\nmodel_output = tf.add(tf.matmul(x_data, A), b)\n\n# \u5b9a\u4e49\u635f\u5931\u51fd\u6570\nloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=model_output, labels=y_target))\n\n# \u5b9a\u4e49\u4f18\u5316\u5668\nmy_opt = tf.train.GradientDescentOptimizer(0.01)\ntrain_step = my_opt.minimize(loss)\n\n# \u8bad\u7ec3\u6a21\u578b\uff0c\u5f00\u59cb\u653e\u6c34\n\n# \u521d\u59cb\u5316\u53d8\u91cf\ninit = tf.global_variables_initializer()\nsess.run(init)\n\n\n# \u505a\u7684\u8bc4\u4ef7\u6307\u6807acc\nprediction = tf.round(tf.sigmoid(model_output))\npredictions_correct = tf.cast(tf.equal(prediction, y_target), tf.float32)\n#\u8c01\u80fd\u544a\u8bc9\u6211tf.cast()\u5e72\u5565\u7684\uff1f\naccuracy = tf.reduce_mean(predictions_correct)\n\n# \u653e\u6c34\nloss_vec = []\ntrain_acc = []\ntest_acc = []\nfor i in range(1500):\n    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n    rand_x = x_vals_train[rand_index]\n    rand_y = np.transpose([y_vals_train[rand_index]])\n    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n\n    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n    loss_vec.append(temp_loss)\n    temp_acc_train = sess.run(accuracy, feed_dict={x_data: x_vals_train, y_target: np.transpose([y_vals_train])})\n    train_acc.append(temp_acc_train)\n    temp_acc_test = sess.run(accuracy, feed_dict={x_data: x_vals_test, y_target: np.transpose([y_vals_test])})\n    test_acc.append(temp_acc_test)\n    if (i+1)%300==0:\n        print('Loss = ' + str(temp_loss))\n\n\n\n# \u6a21\u578b\u53ef\u89c6\u5316\n\nplt.plot(loss_vec, 'k-')\nplt.title('Cross Entropy Loss per Generation')\nplt.xlabel('Generation')\nplt.ylabel('Cross Entropy Loss')\nplt.show()\n\nplt.plot(train_acc, 'k-', label='Train Set Accuracy')\nplt.plot(test_acc, 'r--', label='Test Set Accuracy')\nplt.title('Train and Test Accuracy')\nplt.xlabel('Generation')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.show()\n\n\n\n\n\n\n\n\n\n\u770b\u770b\u6211\u4eec\u5199\u7684\u4ee3\u7801\u5c31\u77e5\u9053\u505a\u673a\u5668\u5b66\u4e60\u7528TensorFlow\u4e0d\u5212\u7b97\uff01\uff01\uff01\n\u771f\u6b63\u4f53\u73b0TF\u4e0e\u4f17\u4e0d\u540c\u7684\u7279\u70b9\u7684\u8fd8\u662f\u5728\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u3002",
            "title": "TensorFlow\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u4e3e\u4f8b"
        },
        {
            "location": "/chapter4/#tf",
            "text": "\u7528TensorFlow\u505a\u673a\u5668\u5b66\u4e60\u5e76\u4e0d\u662f\u4e00\u4e2a\u597d\u7684\u9009\u62e9\uff0cPython\u4e2d\u670920\u591a\u4e2a\u6a21\u5757\u505a\u673a\u5668\u5b66\u4e60\uff0c\u7b80\u5355\u7684\u56de\u5f52\u6765\u8bf4\u53ef\u4ee5\u4f7f\u7528statsmodels\u548csklearn\uff0c\u8981\u6bd4\u7528TF\u66f4\u4fbf\u6377\u3002\u4e3a\u4e86\u4f53\u73b0TF\u7684\u5176\u5728\u673a\u5668\u5b66\u4e60\u7684\u4f5c\u7528\uff0c\u6211\u4eec\u4ee5\u7b80\u5355\u7684\u5f39\u6027\u7f51\u56de\u5f52\u548clogistic\u56de\u5f52\u4e3a\u4f8b\u770b\u4e00\u770b\u5982\u4f55\u4f7f\u7528TF\u505a\u673a\u5668\u5b66\u4e60\uff08\u6211\u7684GitHub\u4e0a\u6258\u7ba1\u4e86\u7528TensorFlow\u5b9e\u73b0\u5e38\u7528\u673a\u5668\u5b66\u4e60\u7684\u6240\u6709\u6e90\u4ee3\u7801\uff0c\u6bd4\u5982\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u51b3\u7b56\u6811\uff0cKNN,SVM\u53ca\u975e\u76d1\u7763\u5b66\u4e60\u7684\u4e00\u4e9b\u7b97\u6cd5\uff0c\u53ef\u5728\u6211\u7684GitHub\u4e3b\u9875\u4e2d\u627e\u5230\uff09  1.TF\u505a\u5f39\u6027\u7f51\u56de\u5f52  \u76f4\u63a5\u4e0a\u4ee3\u7801\uff0c\u8fb9\u770b\u6211\u4eec\u8fb9\u89e3\u91ca  \n# Elastic Net Regression\n#----------------------------------\n\n# y = Ax + b\n#  y = Sepal Length\n#  x = Pedal Length, Petal Width, Sepal Width\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn import datasets\nfrom tensorflow.python.framework import ops\n\n\nops.reset_default_graph()\n# \u521b\u5efa\u8ba1\u7b97\u56fe\nsess = tf.Session()\n\n# \u52a0\u8f7d\u6570\u636e\n# iris.data = [(Sepal Length, Sepal Width, Petal Length, Petal Width)]\niris = datasets.load_iris()\nx_vals = np.array([[x[1], x[2], x[3]] for x in iris.data])\ny_vals = np.array([y[0] for y in iris.data])\n\n#\u5efa\u6a21\n\nseed = 13\nnp.random.seed(seed)\ntf.set_random_seed(seed)\n\nbatch_size = 50\n\n# \u521d\u59cb\u5316 placeholders  \u5565\u662fplaceholders?\nx_data = tf.placeholder(shape=[None, 3], dtype=tf.float32)\ny_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n\n# \u521d\u59cb\u5316\u53d8\u91cf\nA = tf.Variable(tf.random_normal(shape=[3,1]))\nb = tf.Variable(tf.random_normal(shape=[1,1]))\n\n# \u5b9a\u4e49\u6a21\u578b y=AX+b\nmodel_output = tf.add(tf.matmul(x_data, A), b)\n\n# \u5b9a\u4e49\u6210\u672c\u51fd\u6570\nelastic_param1 = tf.constant(1.)\nelastic_param2 = tf.constant(1.)\nl1_a_loss = tf.reduce_mean(tf.abs(A))\nl2_a_loss = tf.reduce_mean(tf.square(A))\ne1_term = tf.multiply(elastic_param1, l1_a_loss)\ne2_term = tf.multiply(elastic_param2, l2_a_loss)\n#\u8fd9\u4e00\u5768\u8c01\u80fd\u7ed9\u6211\u89e3\u91ca\u4e00\u4e0b\uff1f\nloss = tf.expand_dims(tf.add(tf.add(tf.reduce_mean(tf.square(y_target - model_output)), e1_term), e2_term), 0)\n\n# \u58f0\u660e\u4f18\u5316\u7b97\u6cd5\uff08\u4f18\u5316\u5668\u58f0\u660e\uff09\u6ce8\u610f\u5f20\u91cf\u7684\u4f20\u9012\u5173\u7cfb\uff01\uff01\uff01\nmy_opt = tf.train.GradientDescentOptimizer(0.001)\ntrain_step = my_opt.minimize(loss)\n\n#---------\u4e0a\u8fb9\u7684\u8fc7\u7a0b\u53ef\u4ee5\u7406\u89e3\u4e3a\u6211\u4eec\u94fa\u597d\u4e86\u7ba1\u9053\uff0c\u4f46\u662f\u7ba1\u9053\u91cc\u6211\u4eec\u8fd8\u6ca1\u6709\u653e\u6c34-----\n\n#\u5f00\u59cb\u653e\u6c34\uff08\u6a21\u578b\u8bad\u7ec3\uff09\n# \u521d\u59cb\u5316\u53d8\u91cf2\u53e5\uff0c\u662f\u6a21\u677f\u8981\u8bb0\u4f4f\ninit = tf.global_variables_initializer()\nsess.run(init)  \n\n# \u8bad\u7ec3\u7684\u8fc7\u7a0b\nloss_vec = []\nfor i in range(1000):\n    rand_index = np.random.choice(len(x_vals), size=batch_size)\n    rand_x = x_vals[rand_index]\n    rand_y = np.transpose([y_vals[rand_index]])  #\u90a3\u4e48\u7b80\u5355\u5c0f\u95ee\u9898\u6765\u4e86\uff0c\u4e3a\u5565\u8981\u8f6c\u7f6e\uff1f\n    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y}) #\u5411\u5bb9\u5668\u5185\u704c\u6c34\n    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n    loss_vec.append(temp_loss[0])\n    if (i+1)%250==0:\n        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)) + ' b = ' + str(sess.run(b)))\n        #\u4e0a\u884c\u4ee3\u7801\uff0c\u4f53\u73b0\u4e86\u5f20\u91cf\u548c\u6570\u7ec4\u7684\u533a\u522b\n        print('Loss = ' + str(temp_loss))\n\n#\u63d0\u53d6\u6a21\u578b\u6700\u7ec8\u7ed3\u679c\n\n[[sw_coef], [pl_coef], [pw_ceof]] = sess.run(A)\n[y_intercept] = sess.run(b)\n\n\u53ef\u89c6\u5316\u6211\u7684\u6a21\u578b\n\nplt.plot(loss_vec, 'k-')\nplt.title(\"XUJING's Loss per Generation\")\nplt.xlabel('Generation')\nplt.ylabel('Loss')\nplt.show()\n\nsess.close()   2.TF\u505aLogsitic\u56de\u5f52  \u592a\u719f\u4e0d\u8fc7\u7684model\uff0c\u76f4\u63a5\u4ee3\u7801\u5427  # Logistic Regression\n#----------------------------------\n#\n# y = sigmoid(Ax + b)\n#\n#  y = 0 or 1 \n#  x = demographic and medical history data\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport requests\nfrom tensorflow.python.framework import ops\nimport os.path\nimport csv\n\n\nops.reset_default_graph()\n\n# \u521b\u5efa\u8ba1\u7b97\u56fe\nsess = tf.Session()\n\n# \u6570\u636e\u5bfc\u5165\nbirth_weight_file = 'birth_weight.csv'\n\n# \u4f60\u6ca1\u6709\u6570\u636e\u544a\u8bc9\u4f60\u600e\u4e48\u4e0b\u8f7d\nif not os.path.exists(birth_weight_file):\n    birthdata_url = 'https://github.com/DataXujing/tensorflow_cookbook/raw/master/01_Introduction/07_Working_with_Data_Sources/birthweight_data/birthweight.dat'\n    birth_file = requests.get(birthdata_url)\n    birth_data = birth_file.text.split('\\r\\n')\n    birth_header = birth_data[0].split('\\t')\n    birth_data = [[float(x) for x in y.split('\\t') if len(x)>=1] for y in birth_data[1:] if len(y)>=1]\n    with open(birth_weight_file, \"w\") as f:\n        writer = csv.writer(f)\n        writer.writerow(birth_header)\n        writer.writerows(birth_data)\n        f.close()\n\n# \u628a\u4e0b\u597d\u7684\u6570\u636e\u8bfb\u5230\u5185\u5b58\u91cc\u53bb\nbirth_data = []\nwith open(birth_weight_file, newline='') as csvfile:\n     csv_reader = csv.reader(csvfile)\n     birth_header = next(csv_reader)  #\u4e3a\u4ec0\u4e48\u53ef\u4ee5\u7528next()?\n     for row in csv_reader:\n         birth_data.append(row)\n\nbirth_data = [[float(x) for x in row] for row in birth_data]\n\n# \u628alabel\u62ff\u51fa\u6765\ny_vals = np.array([x[0] for x in birth_data])\n# \u62ff\u51faX_vals(not id, not target, and not birthweight)\nx_vals = np.array([x[1:8] for x in birth_data])\n\n# \u8bbe\u7f6e\u968f\u673a\u6570\u79cd\u5b50\nseed = 99\nnp.random.seed(seed)\ntf.set_random_seed(seed)\n\n#\u5212\u5206\u6570\u636e\u96c6 train/test = 80%/20%\ntrain_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)\ntest_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\nx_vals_train = x_vals[train_indices]\nx_vals_test = x_vals[test_indices]\ny_vals_train = y_vals[train_indices]\ny_vals_test = y_vals[test_indices]\n\n# \u6309\u5217\u505a\u5f52\u4e00\u5316\ndef normalize_cols(m):\n    col_max = m.max(axis=0)\n    col_min = m.min(axis=0)\n    return (m-col_min) / (col_max - col_min)\n\nx_vals_train = np.nan_to_num(normalize_cols(x_vals_train))\nx_vals_test = np.nan_to_num(normalize_cols(x_vals_test))\n\n#\u4ee5\u4e0a\u90fd\u662f\u6bd4\u8f83\u4f20\u7edf\u7684Py\u4ee3\u7801\u6ca1\u4ec0\u4e48\u96be\u70b9\n\n#\u5f00\u59cb\u4e0atf\n\n\nbatch_size = 25\n\n# \u521d\u59cb\u5316 placeholders\nx_data = tf.placeholder(shape=[None, 7], dtype=tf.float32) #None\u662f\u5565\u4e1c\u4e1c\uff1f\ny_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n\n# \u521d\u59cb\u5316\u53d8\u91cf\uff08\u597d\u591a\u79cd\u521d\u59cb\u5316\u53d8\u91cf\u7684\u65b9\u6cd5\u3002\u3002\u3002\u3002\u3002\uff09\nA = tf.Variable(tf.random_normal(shape=[7,1]))\nb = tf.Variable(tf.random_normal(shape=[1,1]))\n\n# \u5b9a\u4e49\u6a21\u578b \u4e0d\u662fy = sigmoid(Ax + b)\uff1f\nmodel_output = tf.add(tf.matmul(x_data, A), b)\n\n# \u5b9a\u4e49\u635f\u5931\u51fd\u6570\nloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=model_output, labels=y_target))\n\n# \u5b9a\u4e49\u4f18\u5316\u5668\nmy_opt = tf.train.GradientDescentOptimizer(0.01)\ntrain_step = my_opt.minimize(loss)\n\n# \u8bad\u7ec3\u6a21\u578b\uff0c\u5f00\u59cb\u653e\u6c34\n\n# \u521d\u59cb\u5316\u53d8\u91cf\ninit = tf.global_variables_initializer()\nsess.run(init)\n\n\n# \u505a\u7684\u8bc4\u4ef7\u6307\u6807acc\nprediction = tf.round(tf.sigmoid(model_output))\npredictions_correct = tf.cast(tf.equal(prediction, y_target), tf.float32)\n#\u8c01\u80fd\u544a\u8bc9\u6211tf.cast()\u5e72\u5565\u7684\uff1f\naccuracy = tf.reduce_mean(predictions_correct)\n\n# \u653e\u6c34\nloss_vec = []\ntrain_acc = []\ntest_acc = []\nfor i in range(1500):\n    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n    rand_x = x_vals_train[rand_index]\n    rand_y = np.transpose([y_vals_train[rand_index]])\n    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n\n    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n    loss_vec.append(temp_loss)\n    temp_acc_train = sess.run(accuracy, feed_dict={x_data: x_vals_train, y_target: np.transpose([y_vals_train])})\n    train_acc.append(temp_acc_train)\n    temp_acc_test = sess.run(accuracy, feed_dict={x_data: x_vals_test, y_target: np.transpose([y_vals_test])})\n    test_acc.append(temp_acc_test)\n    if (i+1)%300==0:\n        print('Loss = ' + str(temp_loss))\n\n\n\n# \u6a21\u578b\u53ef\u89c6\u5316\n\nplt.plot(loss_vec, 'k-')\nplt.title('Cross Entropy Loss per Generation')\nplt.xlabel('Generation')\nplt.ylabel('Cross Entropy Loss')\nplt.show()\n\nplt.plot(train_acc, 'k-', label='Train Set Accuracy')\nplt.plot(test_acc, 'r--', label='Test Set Accuracy')\nplt.title('Train and Test Accuracy')\nplt.xlabel('Generation')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.show()    \u770b\u770b\u6211\u4eec\u5199\u7684\u4ee3\u7801\u5c31\u77e5\u9053\u505a\u673a\u5668\u5b66\u4e60\u7528TensorFlow\u4e0d\u5212\u7b97\uff01\uff01\uff01\n\u771f\u6b63\u4f53\u73b0TF\u4e0e\u4f17\u4e0d\u540c\u7684\u7279\u70b9\u7684\u8fd8\u662f\u5728\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u3002",
            "title": "TF\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u4e3e\u4f8b"
        },
        {
            "location": "/chapter5/",
            "text": "TF\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u4e3e\u4f8b\n\n\n\u672c\u8282\u6211\u4eec\u4e3b\u8981\u770b\u4e00\u4e0bTensorFlow\u5982\u4f55\u6109\u5feb\u7684\u505a\u795e\u7ecf\u7f51\u7edc\uff01\u795e\u7ecf\u7f51\u7edc\u7684\u7ed3\u6784\u53ca\u8bad\u7ec3\u8fc7\u7a0b\u6211\u5c31\u4e0d\u8bf4\u4e86\uff0c\u6211\u4eec\u73b0\u5728\u53ef\u4ee5\u7528Python\u4e2d\u7684Numpy\u72ec\u7acb\u7684\u5b8c\u6210\u795e\u7ecf\u7f51\u8def\u7684\u8bbe\u8ba1\u8fc7\u7a0b\uff0c\u90a3\u4e48\u5982\u4f55\u7528tensorflow\u5b8c\u6210\u5462\uff1f\n\n\n1.TF\u8bad\u7ec3DNN\n\n\n\u8001\u89c4\u77e9\u76f4\u63a5\u89e3\u91ca\u4ee3\u7801\uff1a\n\n\n\u6cd51\uff1a\u4ee5\u4e00\u79cd\u7b80\u5355\u7684\u5f62\u5f0f\n\n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport requests\nimport numpy as np\nsess = tf.Session()\n\ndef fully_connected(input_layer, weights, biases):\n    #1st\n    layer = tf.add(tf.matmul(input_layer, weights), biases)\n    return(tf.nn.relu(layer))\n\n    # 2 (25 hidden nodes)\n    weight_1 = init_weight(shape=[8, 25], st_dev=10.0)\n    bias_1 = init_bias(shape=[25], st_dev=10.0)\n    layer_1 = fully_connected(x_data, weight_1, bias_1)\n\n    # 3 (10 hidden nodes)\n    weight_2 = init_weight(shape=[25, 10], st_dev=10.0)\n    bias_2 = init_bias(shape=[10], st_dev=10.0)\n    layer_2 = fully_connected(layer_1, weight_2, bias_2)\n\n    # 4 (3 hidden nodes)\n    weight_3 = init_weight(shape=[10, 3], st_dev=10.0)\n    bias_3 = init_bias(shape=[3], st_dev=10.0)\n    layer_3 = fully_connected(layer_2, weight_3, bias_3)\n\n    # output layer (1 output value)\n    weight_4 = init_weight(shape=[3, 1], st_dev=10.0)\n    bias_4 = init_bias(shape=[1], st_dev=10.0)\n    final_output = fully_connected(layer_3, weight_4, bias_4)\n\nloss = tf.reduce_mean(tf.abs(y_target - final_output))\nmy_opt = tf.train.AdamOptimizer(0.05)\ntrain_step = my_opt.minimize(loss)\ninit = tf.initialize_all_variables()\nsess.run(init)\n\n# Initialize the loss vectors\nloss_vec = []\ntest_loss = []\nfor i in range(200):\n    # \u5212\u5206\u8bad\u7ec3\u96c6\n    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n\n    rand_x = x_vals_train[rand_index]\n    rand_y = np.transpose([y_vals_train[rand_index]])\n    # \u8bad\u7ec3\u6a21\u578b\n    sess.run(train_step, feed_dict={x_data: rand_x, y_target:rand_y})\n    #loss\n    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target:rand_y})\n    loss_vec.append(temp_loss)\n    # test loss\n    test_temp_loss = sess.run(loss, feed_dict={x_data: x_vals_test, y_target: np.transpose([y_vals_test])})\n    test_loss.append(test_temp_loss)\n    if (i+1)%25==0:\n        print('Generation: ' + str(i+1) + '. Loss = ' + str(temp_loss))\n\n# metrics\u7684\u53ef\u89c6\u5316\nplt.plot(loss_vec, 'k-', label='Train Loss')\nplt.plot(test_loss, 'r--', label='Test Loss')\nplt.title('Loss per Generation')\n\nplt.xlabel('Generation')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')\nplt.show()\n\n\n\n\n\u4e0a\u9762\u7684\u4ee3\u7801\u5f88\u7b80\u5355\uff0c\u5982\u679c\u6211\u4eec\u7684DNN\u670950\u5c42\uff0c\u662f\u4e0d\u662f\u6211\u4eec\u8981\u5199\u597d\u591a\u53d8\u91cf\uff0cweight1,weight2,...\uff0c\u5728def\u4e2d\u8981\u7f57\u5217\u597d\u591a\u53d8\u91cf\uff0c\u81ea\u5df1\u53ef\u80fd\u5c31\u6655\u6389\u4e86\uff0c\u5728\u540e\u671f\u53ef\u89c6\u5316\u6a21\u578b\u65f6\u4e5f\u4e0d\u53ef\u4ee5\u3002\u5e76\u4e14\u6211\u4eec\u5e76\u6ca1\u6709\u91c7\u53d6\u4e00\u4e9b\u50cf\u6b63\u5219\u5316\uff0c\u53d8\u91cf\u7684\u6ed1\u52a8\u5e73\u5747\uff08\u63d0\u9ad8\u6d4b\u8bd5\u6570\u636e\u5728\u6a21\u578b\u4e2d\u7684\u7a33\u5065\u6027\uff0c\u63a5\u89e6\u8fc7\u65f6\u95f4\u5e8f\u5217\u53ef\u4ee5\u5bf9\u6b64\u6709\u66f4\u6df1\u5165\u7684\u7406\u89e3\uff0c\u8fd9\u91cc\u4e0d\u662f\u6211\u4eec\u7684\u91cd\u70b9\uff09\uff0cdropout\u7b49\u7684\u4e00\u4e9b\u8f85\u52a9\u4f18\u5316\u6280\u672f\uff0c\u5982\u679c\u52a0\u4e0a\u8fd9\u4e9b\u662f\u4e0d\u662f\u8fd9\u79cd\u529e\u6cd5\u663e\u7684\u66f4\u7b28\u62d9\uff1f\n\n\n\u6cd52\uff1a\u5bf9\u4ee3\u4ee3\u7801\u505a\u53d8\u91cf\u7ba1\u7406\n\n\ndef inference(input_tensor,resuse=False):\n    #1st\n    with tf.variable_scope\uff08\"layer1\",resuse=resuse):\n        #\u6839\u636e\u4f20\u8fdb\u6765\u7684resuse\u6765\u5224\u65ad\u662f\u521b\u5efa\u65b0\u53d8\u91cf\u8fd8\u662f\u4f7f\u7528\u5df2\u7ecf\u521b\u5efa\u597d\u7684\uff0c\u5728\u7b2c\u4e00\u6b21\u6784\u9020\u7f51\u7edc\u65f6\n        #\u9700\u8981\u521b\u5efa\u65b0\u7684\u53d8\u91cf\uff0c\u4ee5\u540e\u6bcf\u6b21\u8c03\u7528\u8fd9\u4e2a\u51fd\u6570\u76f4\u63a5\u4f7f\u7528resuse=True\u5c31\u4e0d\u9700\u8981\u6bcf\u6b21\u5c06\u53d8\u91cf\u4f20\u8fdb\u6765\u4e86\n        weights = tf.get_variable('weights',[INPUT_NODE,LAYER1_NODE],\n            initializer = tf.truncated_normal_initializer(stddev = 0.1))\n        biases = tf.get_varible('biases',[LAYER1_NODE],initializer = tf.constant_initializer(0.))\n        layer1 = tf.nn.relu(tf.matmul(input_tensor,weights) + biases)\n    #\u7c7b\u4f3c\u7684\u5b9a\u4e49layer2\n    with tf.variable_scope\uff08\"layer2\",resuse=resuse):\n        #\u6839\u636e\u4f20\u8fdb\u6765\u7684resuse\u6765\u5224\u65ad\u662f\u521b\u5efa\u65b0\u53d8\u91cf\u8fd8\u662f\u4f7f\u7528\u5df2\u7ecf\u521b\u5efa\u597d\u7684\uff0c\u5728\u7b2c\u4e00\u6b21\u6784\u9020\u7f51\u7edc\u65f6\n        #\u9700\u8981\u521b\u5efa\u65b0\u7684\u53d8\u91cf\uff0c\u4ee5\u540e\u6bcf\u6b21\u8c03\u7528\u8fd9\u4e2a\u51fd\u6570\u76f4\u63a5\u4f7f\u7528resuse=True\u5c31\u4e0d\u9700\u8981\u6bcf\u6b21\u5c06\u53d8\u91cf\u4f20\u8fdb\u6765\u4e86\n        weights = tf.get_variable('weights',[INPUT_NODE,OUTPUT_NODE],\n            initializer = tf.truncated_normal_initializer(stddev = 0.1))\n        biases = tf.get_varible('biases',[OUTPUT_NODE],initializer = tf.constant_initializer(0.))\n        layer2 = tf.nn.relu(tf.matmul(input_tensor,weights) + biases)\n    #\u8fd4\u56de\u6700\u540e\u7684\u524d\u5411\u4f20\u64ad\u7ed3\u679c\n\n    return layer2\n\nx = tf.placeholder(tf.float32,[None,INPUT_NODE],name='x-input')\ny = inference(x)\n\n#\u5728\u7a0b\u5e8f\u4e2d\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u63a8\u5012\u65f6\uff0c\u53ef\u4ee5\u76f4\u63a5\u8c03\u7528inference(new_x,True)\n#\u5f53\u52a0\u5165\u6307\u6570\u6ed1\u52a8\u5e73\u5747\u7b49\u65b9\u6cd5\u65f6\uff0c\u53d8\u91cf\u7ba1\u7406\u673a\u5236\u4f1a\u4f1a\u4f53\u73b0\u51fa\u66f4\u65b9\u4fbf\u3002\n#\u6ce8\u610f\uff1a\u5f53resuse=True\u65f6\uff0ctf.get_variable\u51fd\u6570\u5c06\u76f4\u63a5\u83b7\u53d6\u5df2\u7ecf\u58f0\u660e\u7684\u53d8\u91cf\uff0c\u5982\u679c\u53d8\u91cf\u5728\u547d\u540d\u7a7a\u95f4\u4e2d\u6ca1\u6709\u88ab\u58f0\u660e\u8fc7\uff0c\u6b64\u65f6\u4f1a\u62a5\u9519\u3002\n\n\n\n\n\n\n\n2.TF\u6a21\u578b\u7684\u6301\u4e45\u5316\n\n\n\u6211\u4eec\u8bad\u7ec3\u4e00\u4e2a\u6df1\u5c42\u6a21\u578b\u53ef\u80fd\u9700\u8981\u51e0\u5468\u6216\u51e0\u4e2a\u6708\u7684\u65f6\u95f4\uff0c\u8bad\u7ec3\u5b8c\u4e86\uff0c\u5982\u679c\u4e0d\u53bb\u4fdd\u5b58\u4e0b\u6b21\u4f7f\u7528\u8fd8\u5f97\u51e0\u5468\u7684\u65f6\u95f4,\u6a21\u578b\u7684\u6301\u4e45\u5316\u5c31\u662f\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u77e5\u9053\u5728MXNet\u548cKeras\u4e2d\u90fd\u6709\u76f8\u5e94\u7684\u673a\u5236\uff0c\u8fd9\u4e5f\u4e3a\u8fc1\u79fb\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b9\u4fbf\u3002\n\n\nTensorFlow\u63d0\u4f9b\u4e86\u4e00\u4e2a\u975e\u5e38\u7b80\u5355\u7684API\u6765\u4fdd\u5b58\u548c\u8fd8\u539f\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u8fd9\u4e2aAPI\u5c31\u662ftf.train.Saver\u7c7b\n\n\nimport tensorflow as tf\n\nv1 = tf.Variable(tf.constant(1.0,shape=[1]),name='v1')\nv2 = tf.Variable(tf.constant(2.0,shape=[1]),name='v2')\n\nresult = v1 + v2\ninit_op = tf.global_variables_initializer()\n\n#\u58f0\u660etf.train.Saver\u7c7b\u7528\u4e8e\u4fdd\u5b58\u6a21\u578b\n\nsaver = tf.train.Saver()\n\nwith tf.Session() as sess:\n    sess.run(init_op)\n    #\u5c06\u6a21\u578b\u4fdd\u5b58\u5728C:/model/model.ckpt\u6587\u4ef6\n    path = \"C:/model/model.ckpt\"\n    saver.save(sess,path)\n\n\n\n\nTF\u6a21\u578b\u4e00\u822c\u4f1a\u4fdd\u5b58\u5728\u540e\u7f00\u4e3a.ckpt(CheckPoint),\u867d\u7136\u4e0a\u9762\u7684\u7a0b\u5e8f\u6307\u5b9a\u4e86\u4e00\u4e2a\u6587\u4ef6\u8def\u5f84\uff0c\u4f46\u5728\u8fd9\u4e2a\u6587\u4ef6\u8def\u5f84\u4e0b\u4f1a\u51fa\u73b0\u4e09\u4e2a\u6587\u4ef6\uff0c\u8fd9\u662f\u56e0\u4e3aTensorFlow\u4f1a\u5c06\u8ba1\u7b97\u56fe\u7684\u7ed3\u6784\u548c\u56fe\u4e0a\u53c2\u6570\u53d6\u503c\u5206\u5f00\u6765\u4fdd\u5b58\n\n\n\n\n\n\nmodel.ckpt.meta\uff1a \u4fdd\u5b58\u4e86\u8ba1\u7b97\u56fe\u7684\u7ed3\u6784\uff08\u7b80\u5355\u7684\u53ef\u4ee5\u7406\u89e3\u4e3a\u795e\u7ecf\u7f51\u7edc\u7684\u7f51\u7edc\u7ed3\u6784\uff09\n\n\n\n\n\n\nmodel.ckpt: \u8fd9\u4e2a\u6587\u4ef6\u4fdd\u5b58\u4e86TensorFlow\u7a0b\u5e8f\u4e2d\u6bcf\u4e00\u4e2a\u53d8\u91cf\u7684\u53d6\u503c\n\n\n\n\n\n\ncheckpoint\u6587\u4ef6\uff1a\u8fd9\u4e2a\u6587\u4ef6\u4fdd\u5b58\u4e86\u4e00\u4e2a\u76ee\u5f55\u4e0b\u6240\u6709\u7684\u6a21\u578b\u6587\u4ef6\u5217\u8868\n\n\n\n\n\n\n\u4e86\u89e3\u66f4\u591a\u8fd9\u4e9b\u6587\u4ef6\u53ef\u641c\u7d22\u5927\u91cf\u7684\u4ecb\u7ecd\u4fe1\u606f\n\n\n\n\n\u52a0\u8f7d\u5df2\u7ecf\u4fdd\u5b58\u7684TensorFlow\u6a21\u578b\n\n\n\n\nimport tensorflow as tf\n#\u4f7f\u7528\u548c\u4fdd\u5b58\u6a21\u578b\u4ee3\u7801\u4e2d\u4e00\u6837\u7684\u65b9\u5f0f\u6765\u58f0\u660e\u53d8\u91cf\n\nv1 = tf.Variable(tf.constant(1.0,shape=[1]),name='v1')\nv2 = tf.Variable(tf.constant(2.0,shape=[1]),name='v2')\n\nresult = v1 + v2\n\nsaver = tf.train.Saver()\n\nwith tf.Session() as sess:\n    #\u52a0\u8f7d\u4ee5\u4fdd\u5b58\u7684\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5df2\u4fdd\u5b58\u7684\u6a21\u578b\u4e2d\u7684\u53d8\u91cf\u6765\u8ba1\u7b97\u52a0\u6cd5\n    saver.restore(sess,path)\n    print sess.run(result)\n\n\n\n\n\n\u533a\u522b\uff1a\u52a0\u8f7d\u6a21\u578b\u7684\u4ee3\u7801\u4e2d\u6ca1\u6709\u8fd0\u884c\u53d8\u91cf\u521d\u59cb\u5316\u8fc7\u7a0b\uff0c\u800c\u662f\u5c06\u53d8\u91cf\u7684\u503c\u901a\u8fc7\u5df2\u7ecf\u4fdd\u5b58\u7684\u5417\u6a21\u578b\u52a0\u8f7d\u8fdb\u6765\u3002\n\n\n\n\n\u5982\u679c\u4e0d\u5e0c\u671b\u91cd\u590d\u5b9a\u4e49\u56fe\u4e0a\u7684\u8fd0\u7b97\uff0c\u53ef\u4ee5\u52a0\u8f7d\u5df2\u7ecf\u6301\u4e45\u5316\u7684\u56fe\n\n\n\n\nimport tensorflow as tf\n\n#\u76f4\u63a5\u52a0\u8f7d\u6301\u4e45\u5316\u7684\u56fe\nsaver = tf.train.import_meta_graph(path+'.meta')\nwith tf.Session() as sess:\n    saver.restore(ress,path)\n    #\u901a\u8fc7\u5f20\u91cf\u7684\u540d\u79f0\u6765\u83b7\u53d6\u5f20\u91cf\n    print sess.run(tf.get_default_graph().get_tensor_by_name('add:0'))\n\n#\u8f93\u51fa\u7ed3\u679c\uff1a[3.]\n\n\n\n\n\n\n\u4fdd\u5b58\u6216\u52a0\u8f7d\u90e8\u5206\u53d8\u91cf\n\n\n\n\n\u9ed8\u8ba4\u52a0\u8f7d\u548c\u4fdd\u5b58TF\u8ba1\u7b97\u56fe\u4e0a\u7684\u6240\u6709\u53d8\u91cf\uff0c\u4f46\u6709\u65f6\u53ef\u80fd\u53ea\u9700\u8981\u4fdd\u5b58\u548c\u52a0\u8f7d\u90e8\u5206\u53d8\u91cf\uff0c\u6bd4\u5982\uff0c\u6211\u4eec\u6709\u4e00\u4e2a\u8bad\u7ec3\u597d\u76845\u5c42\u7f51\u7edc\uff0c\u4f46\u73b0\u5728\u60f3\u5c1d\u8bd56\u5c42\u7684\u7f51\u7edc\uff0c\u90a3\u4e48\u53ef\u4ee5\u5c06\u524d5\u5c42\u53c2\u6570\u52a0\u8f7d\u8fdb\u6765\uff0c\u8bad\u7ec3\u6700\u540e\u4e00\u5c42\u7f51\u7edc\u5373\u53ef\uff08\u8fc1\u79fb\u5b66\u4e60\uff09\n\n\ntf.train.Saver\u7c7b\u53ef\u4ee5\u63d0\u4f9b\u4e00\u4e2a\u5217\u8868\u6765\u6307\u5b9a\u9700\u8981\u4fdd\u5b58\u548c\u52a0\u8f7d\u7684\u53d8\u91cf\uff0csaver = tf.train.Saver([v1]),\u53ea\u6709\u53d8\u91cfv1\u88ab\u52a0\u8f7d\u8fdb\u6765\n\n\n\n\n\u53d8\u91cf\u91cd\u547d\u540d\n\n\n\n\ntf.train.Saver\u652f\u6301\u4fdd\u5b58\u548c\u52a0\u8f7d\u65f6\u7684\u53d8\u91cf\u91cd\u547d\u540d\n\n\nv1 = tf.Variable(tf.constant(1.0,shape=[1]),name='other-v1')\nv2 = tf.Variable(tf.constant(2.0,shape=[1]),name='other-v2')\n\nsaver = tf.train.Saver({'v1':v1,'v2':v2})\n#\u539f\u6765\u540d\u79f0\u4e3av1\u7684\u53d8\u91cf\u73b0\u5728\u52a0\u8f7d\u5230\u53d8\u91cfv1\u4e2d\uff08\u540d\u79f0\u4e3aother-v1)\u3002\n\n\n\n\n\n\n\u5176\u4ed6\n\n\n\n\ntf.train.Saver\u4f1a\u4fdd\u5b58\u8fd0\u884cTF\u7a0b\u5e8f\u7684\u5168\u90e8\u4fe1\u606f\uff0c\u6709\u65f6\u5e76\u4e0d\u9700\u8981\uff0c\u6bd4\u5982\u5728\u6d4b\u8bd5\u6216\u79bb\u7ebf\u9884\u6d4b\u65f6\uff0c\u6211\u4eec\u53ea\u9700\u77e5\u9053\u795e\u7ecf\u7f51\u7edc\u7684\u524d\u5411\u4f20\u64ad\u8ba1\u7b97\u5230\u8f93\u51fa\u5c31\u53ef\u4ee5\u4e86\uff0c\u800c\u4e0d\u9700\u8981\u7c7b\u4f3c\u989d\u53d8\u91cf\u521d\u59cb\u5316\u7b49\u8f85\u52a9\u8282\u70b9\u4fe1\u606f\uff0c\u5728\u8fc1\u79fb\u5b66\u4e60\u4e2d\u4f1a\u9047\u5230\u8fd9\u4e9b\u95ee\u9898\uff0c\u4e8e\u662fTensorFlow\u63d0\u4f9b\u4e86convert_variables_to _constants\u51fd\u6570\uff0c\u901a\u8fc7\u8fd9\u4e2a\u51fd\u6570\u53ef\u4ee5\u5c06\u8ba1\u7b97\u56fe\u4e2d\u7684\u53d8\u91cf\u53ca\u5176\u53d6\u503c\u901a\u8fc7\u5e38\u91cf\u7684\u65b9\u5f0f\u4fdd\u5b58\uff0c\u8fd9\u6837TF\u8ba1\u7b97\u56fe\u53ef\u4ee5\u7edf\u4e00\u4fdd\u5b58\u5728\u4e00\u4e2a\u6587\u4ef6\u4e2d\n\n\nimort tensorflow as tf\n\nfrom tensrflow.python.framework import graph_util\n\nv1 = tf.Variable(tf.constant(1.0,shape=[1]),name='v1')\nv2 = tf.Variable(tf.constant(2.0,shape=[2]),name='v2')\n\nresult = v1 + v2\n\ninit_op = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init_op)\n    #\u5bfc\u51fa\u5f53\u524d\u8ba1\u7b97\u56fe\u7684GraphDef\u90e8\u5206\uff0c\u53ea\u9700\u8fd9\u4e0e\u90e8\u5206\u53ef\u4ee5\u5b8c\u6210\u4ece\u8f93\u5165\u5230\u8f93\u51fa\u7684\u8ba1\u7b97\u8fc7\u7a0b\n    graph_def  = tf.get_default_graph().as_graph_def()\n\n    output_graph_def = graph_util.convert_variables_to_constants(sess,graph_def,['add'])\n    #\u5c06\u5bfc\u51fa\u7684\u6a21\u578b\u4fdd\u5b58\u6210\u6587\u4ef6\n    with tf.gfile.GFile('C:/model.pb','wb') as f:\n        f.write(output_graph_def.SerializeToString())\n\n\n\n\nimport tensorflow as tf\nfrom tensorflow.python.platform import gfile\n\nwith tf.Session() as sess:\n    path = 'C:/model.pb'\n    #\u8bfb\u53d6\u4fdd\u5b58\u7684\u6587\u4ef6\uff0c\u5e76\u5c06\u6587\u4ef6\u89e3\u6790\u6210\u5bf9\u5e94\u7684GraphDef Protocol Buffer\n    with gfile.FastGFile(path,'rb') as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromeString(f.read())\n    result = tf.import_graph_def(graph_def,return_element=['add:0'])\n    print sess.run(result)",
            "title": "TensorFlow\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u4e3e\u4f8b"
        },
        {
            "location": "/chapter5/#tf",
            "text": "\u672c\u8282\u6211\u4eec\u4e3b\u8981\u770b\u4e00\u4e0bTensorFlow\u5982\u4f55\u6109\u5feb\u7684\u505a\u795e\u7ecf\u7f51\u7edc\uff01\u795e\u7ecf\u7f51\u7edc\u7684\u7ed3\u6784\u53ca\u8bad\u7ec3\u8fc7\u7a0b\u6211\u5c31\u4e0d\u8bf4\u4e86\uff0c\u6211\u4eec\u73b0\u5728\u53ef\u4ee5\u7528Python\u4e2d\u7684Numpy\u72ec\u7acb\u7684\u5b8c\u6210\u795e\u7ecf\u7f51\u8def\u7684\u8bbe\u8ba1\u8fc7\u7a0b\uff0c\u90a3\u4e48\u5982\u4f55\u7528tensorflow\u5b8c\u6210\u5462\uff1f  1.TF\u8bad\u7ec3DNN  \u8001\u89c4\u77e9\u76f4\u63a5\u89e3\u91ca\u4ee3\u7801\uff1a  \u6cd51\uff1a\u4ee5\u4e00\u79cd\u7b80\u5355\u7684\u5f62\u5f0f  import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport requests\nimport numpy as np\nsess = tf.Session()\n\ndef fully_connected(input_layer, weights, biases):\n    #1st\n    layer = tf.add(tf.matmul(input_layer, weights), biases)\n    return(tf.nn.relu(layer))\n\n    # 2 (25 hidden nodes)\n    weight_1 = init_weight(shape=[8, 25], st_dev=10.0)\n    bias_1 = init_bias(shape=[25], st_dev=10.0)\n    layer_1 = fully_connected(x_data, weight_1, bias_1)\n\n    # 3 (10 hidden nodes)\n    weight_2 = init_weight(shape=[25, 10], st_dev=10.0)\n    bias_2 = init_bias(shape=[10], st_dev=10.0)\n    layer_2 = fully_connected(layer_1, weight_2, bias_2)\n\n    # 4 (3 hidden nodes)\n    weight_3 = init_weight(shape=[10, 3], st_dev=10.0)\n    bias_3 = init_bias(shape=[3], st_dev=10.0)\n    layer_3 = fully_connected(layer_2, weight_3, bias_3)\n\n    # output layer (1 output value)\n    weight_4 = init_weight(shape=[3, 1], st_dev=10.0)\n    bias_4 = init_bias(shape=[1], st_dev=10.0)\n    final_output = fully_connected(layer_3, weight_4, bias_4)\n\nloss = tf.reduce_mean(tf.abs(y_target - final_output))\nmy_opt = tf.train.AdamOptimizer(0.05)\ntrain_step = my_opt.minimize(loss)\ninit = tf.initialize_all_variables()\nsess.run(init)\n\n# Initialize the loss vectors\nloss_vec = []\ntest_loss = []\nfor i in range(200):\n    # \u5212\u5206\u8bad\u7ec3\u96c6\n    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n\n    rand_x = x_vals_train[rand_index]\n    rand_y = np.transpose([y_vals_train[rand_index]])\n    # \u8bad\u7ec3\u6a21\u578b\n    sess.run(train_step, feed_dict={x_data: rand_x, y_target:rand_y})\n    #loss\n    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target:rand_y})\n    loss_vec.append(temp_loss)\n    # test loss\n    test_temp_loss = sess.run(loss, feed_dict={x_data: x_vals_test, y_target: np.transpose([y_vals_test])})\n    test_loss.append(test_temp_loss)\n    if (i+1)%25==0:\n        print('Generation: ' + str(i+1) + '. Loss = ' + str(temp_loss))\n\n# metrics\u7684\u53ef\u89c6\u5316\nplt.plot(loss_vec, 'k-', label='Train Loss')\nplt.plot(test_loss, 'r--', label='Test Loss')\nplt.title('Loss per Generation')\n\nplt.xlabel('Generation')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')\nplt.show()  \u4e0a\u9762\u7684\u4ee3\u7801\u5f88\u7b80\u5355\uff0c\u5982\u679c\u6211\u4eec\u7684DNN\u670950\u5c42\uff0c\u662f\u4e0d\u662f\u6211\u4eec\u8981\u5199\u597d\u591a\u53d8\u91cf\uff0cweight1,weight2,...\uff0c\u5728def\u4e2d\u8981\u7f57\u5217\u597d\u591a\u53d8\u91cf\uff0c\u81ea\u5df1\u53ef\u80fd\u5c31\u6655\u6389\u4e86\uff0c\u5728\u540e\u671f\u53ef\u89c6\u5316\u6a21\u578b\u65f6\u4e5f\u4e0d\u53ef\u4ee5\u3002\u5e76\u4e14\u6211\u4eec\u5e76\u6ca1\u6709\u91c7\u53d6\u4e00\u4e9b\u50cf\u6b63\u5219\u5316\uff0c\u53d8\u91cf\u7684\u6ed1\u52a8\u5e73\u5747\uff08\u63d0\u9ad8\u6d4b\u8bd5\u6570\u636e\u5728\u6a21\u578b\u4e2d\u7684\u7a33\u5065\u6027\uff0c\u63a5\u89e6\u8fc7\u65f6\u95f4\u5e8f\u5217\u53ef\u4ee5\u5bf9\u6b64\u6709\u66f4\u6df1\u5165\u7684\u7406\u89e3\uff0c\u8fd9\u91cc\u4e0d\u662f\u6211\u4eec\u7684\u91cd\u70b9\uff09\uff0cdropout\u7b49\u7684\u4e00\u4e9b\u8f85\u52a9\u4f18\u5316\u6280\u672f\uff0c\u5982\u679c\u52a0\u4e0a\u8fd9\u4e9b\u662f\u4e0d\u662f\u8fd9\u79cd\u529e\u6cd5\u663e\u7684\u66f4\u7b28\u62d9\uff1f  \u6cd52\uff1a\u5bf9\u4ee3\u4ee3\u7801\u505a\u53d8\u91cf\u7ba1\u7406  def inference(input_tensor,resuse=False):\n    #1st\n    with tf.variable_scope\uff08\"layer1\",resuse=resuse):\n        #\u6839\u636e\u4f20\u8fdb\u6765\u7684resuse\u6765\u5224\u65ad\u662f\u521b\u5efa\u65b0\u53d8\u91cf\u8fd8\u662f\u4f7f\u7528\u5df2\u7ecf\u521b\u5efa\u597d\u7684\uff0c\u5728\u7b2c\u4e00\u6b21\u6784\u9020\u7f51\u7edc\u65f6\n        #\u9700\u8981\u521b\u5efa\u65b0\u7684\u53d8\u91cf\uff0c\u4ee5\u540e\u6bcf\u6b21\u8c03\u7528\u8fd9\u4e2a\u51fd\u6570\u76f4\u63a5\u4f7f\u7528resuse=True\u5c31\u4e0d\u9700\u8981\u6bcf\u6b21\u5c06\u53d8\u91cf\u4f20\u8fdb\u6765\u4e86\n        weights = tf.get_variable('weights',[INPUT_NODE,LAYER1_NODE],\n            initializer = tf.truncated_normal_initializer(stddev = 0.1))\n        biases = tf.get_varible('biases',[LAYER1_NODE],initializer = tf.constant_initializer(0.))\n        layer1 = tf.nn.relu(tf.matmul(input_tensor,weights) + biases)\n    #\u7c7b\u4f3c\u7684\u5b9a\u4e49layer2\n    with tf.variable_scope\uff08\"layer2\",resuse=resuse):\n        #\u6839\u636e\u4f20\u8fdb\u6765\u7684resuse\u6765\u5224\u65ad\u662f\u521b\u5efa\u65b0\u53d8\u91cf\u8fd8\u662f\u4f7f\u7528\u5df2\u7ecf\u521b\u5efa\u597d\u7684\uff0c\u5728\u7b2c\u4e00\u6b21\u6784\u9020\u7f51\u7edc\u65f6\n        #\u9700\u8981\u521b\u5efa\u65b0\u7684\u53d8\u91cf\uff0c\u4ee5\u540e\u6bcf\u6b21\u8c03\u7528\u8fd9\u4e2a\u51fd\u6570\u76f4\u63a5\u4f7f\u7528resuse=True\u5c31\u4e0d\u9700\u8981\u6bcf\u6b21\u5c06\u53d8\u91cf\u4f20\u8fdb\u6765\u4e86\n        weights = tf.get_variable('weights',[INPUT_NODE,OUTPUT_NODE],\n            initializer = tf.truncated_normal_initializer(stddev = 0.1))\n        biases = tf.get_varible('biases',[OUTPUT_NODE],initializer = tf.constant_initializer(0.))\n        layer2 = tf.nn.relu(tf.matmul(input_tensor,weights) + biases)\n    #\u8fd4\u56de\u6700\u540e\u7684\u524d\u5411\u4f20\u64ad\u7ed3\u679c\n\n    return layer2\n\nx = tf.placeholder(tf.float32,[None,INPUT_NODE],name='x-input')\ny = inference(x)\n\n#\u5728\u7a0b\u5e8f\u4e2d\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u63a8\u5012\u65f6\uff0c\u53ef\u4ee5\u76f4\u63a5\u8c03\u7528inference(new_x,True)\n#\u5f53\u52a0\u5165\u6307\u6570\u6ed1\u52a8\u5e73\u5747\u7b49\u65b9\u6cd5\u65f6\uff0c\u53d8\u91cf\u7ba1\u7406\u673a\u5236\u4f1a\u4f1a\u4f53\u73b0\u51fa\u66f4\u65b9\u4fbf\u3002\n#\u6ce8\u610f\uff1a\u5f53resuse=True\u65f6\uff0ctf.get_variable\u51fd\u6570\u5c06\u76f4\u63a5\u83b7\u53d6\u5df2\u7ecf\u58f0\u660e\u7684\u53d8\u91cf\uff0c\u5982\u679c\u53d8\u91cf\u5728\u547d\u540d\u7a7a\u95f4\u4e2d\u6ca1\u6709\u88ab\u58f0\u660e\u8fc7\uff0c\u6b64\u65f6\u4f1a\u62a5\u9519\u3002   2.TF\u6a21\u578b\u7684\u6301\u4e45\u5316  \u6211\u4eec\u8bad\u7ec3\u4e00\u4e2a\u6df1\u5c42\u6a21\u578b\u53ef\u80fd\u9700\u8981\u51e0\u5468\u6216\u51e0\u4e2a\u6708\u7684\u65f6\u95f4\uff0c\u8bad\u7ec3\u5b8c\u4e86\uff0c\u5982\u679c\u4e0d\u53bb\u4fdd\u5b58\u4e0b\u6b21\u4f7f\u7528\u8fd8\u5f97\u51e0\u5468\u7684\u65f6\u95f4,\u6a21\u578b\u7684\u6301\u4e45\u5316\u5c31\u662f\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u77e5\u9053\u5728MXNet\u548cKeras\u4e2d\u90fd\u6709\u76f8\u5e94\u7684\u673a\u5236\uff0c\u8fd9\u4e5f\u4e3a\u8fc1\u79fb\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b9\u4fbf\u3002  TensorFlow\u63d0\u4f9b\u4e86\u4e00\u4e2a\u975e\u5e38\u7b80\u5355\u7684API\u6765\u4fdd\u5b58\u548c\u8fd8\u539f\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u8fd9\u4e2aAPI\u5c31\u662ftf.train.Saver\u7c7b  import tensorflow as tf\n\nv1 = tf.Variable(tf.constant(1.0,shape=[1]),name='v1')\nv2 = tf.Variable(tf.constant(2.0,shape=[1]),name='v2')\n\nresult = v1 + v2\ninit_op = tf.global_variables_initializer()\n\n#\u58f0\u660etf.train.Saver\u7c7b\u7528\u4e8e\u4fdd\u5b58\u6a21\u578b\n\nsaver = tf.train.Saver()\n\nwith tf.Session() as sess:\n    sess.run(init_op)\n    #\u5c06\u6a21\u578b\u4fdd\u5b58\u5728C:/model/model.ckpt\u6587\u4ef6\n    path = \"C:/model/model.ckpt\"\n    saver.save(sess,path)  TF\u6a21\u578b\u4e00\u822c\u4f1a\u4fdd\u5b58\u5728\u540e\u7f00\u4e3a.ckpt(CheckPoint),\u867d\u7136\u4e0a\u9762\u7684\u7a0b\u5e8f\u6307\u5b9a\u4e86\u4e00\u4e2a\u6587\u4ef6\u8def\u5f84\uff0c\u4f46\u5728\u8fd9\u4e2a\u6587\u4ef6\u8def\u5f84\u4e0b\u4f1a\u51fa\u73b0\u4e09\u4e2a\u6587\u4ef6\uff0c\u8fd9\u662f\u56e0\u4e3aTensorFlow\u4f1a\u5c06\u8ba1\u7b97\u56fe\u7684\u7ed3\u6784\u548c\u56fe\u4e0a\u53c2\u6570\u53d6\u503c\u5206\u5f00\u6765\u4fdd\u5b58    model.ckpt.meta\uff1a \u4fdd\u5b58\u4e86\u8ba1\u7b97\u56fe\u7684\u7ed3\u6784\uff08\u7b80\u5355\u7684\u53ef\u4ee5\u7406\u89e3\u4e3a\u795e\u7ecf\u7f51\u7edc\u7684\u7f51\u7edc\u7ed3\u6784\uff09    model.ckpt: \u8fd9\u4e2a\u6587\u4ef6\u4fdd\u5b58\u4e86TensorFlow\u7a0b\u5e8f\u4e2d\u6bcf\u4e00\u4e2a\u53d8\u91cf\u7684\u53d6\u503c    checkpoint\u6587\u4ef6\uff1a\u8fd9\u4e2a\u6587\u4ef6\u4fdd\u5b58\u4e86\u4e00\u4e2a\u76ee\u5f55\u4e0b\u6240\u6709\u7684\u6a21\u578b\u6587\u4ef6\u5217\u8868    \u4e86\u89e3\u66f4\u591a\u8fd9\u4e9b\u6587\u4ef6\u53ef\u641c\u7d22\u5927\u91cf\u7684\u4ecb\u7ecd\u4fe1\u606f   \u52a0\u8f7d\u5df2\u7ecf\u4fdd\u5b58\u7684TensorFlow\u6a21\u578b   import tensorflow as tf\n#\u4f7f\u7528\u548c\u4fdd\u5b58\u6a21\u578b\u4ee3\u7801\u4e2d\u4e00\u6837\u7684\u65b9\u5f0f\u6765\u58f0\u660e\u53d8\u91cf\n\nv1 = tf.Variable(tf.constant(1.0,shape=[1]),name='v1')\nv2 = tf.Variable(tf.constant(2.0,shape=[1]),name='v2')\n\nresult = v1 + v2\n\nsaver = tf.train.Saver()\n\nwith tf.Session() as sess:\n    #\u52a0\u8f7d\u4ee5\u4fdd\u5b58\u7684\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5df2\u4fdd\u5b58\u7684\u6a21\u578b\u4e2d\u7684\u53d8\u91cf\u6765\u8ba1\u7b97\u52a0\u6cd5\n    saver.restore(sess,path)\n    print sess.run(result)  \u533a\u522b\uff1a\u52a0\u8f7d\u6a21\u578b\u7684\u4ee3\u7801\u4e2d\u6ca1\u6709\u8fd0\u884c\u53d8\u91cf\u521d\u59cb\u5316\u8fc7\u7a0b\uff0c\u800c\u662f\u5c06\u53d8\u91cf\u7684\u503c\u901a\u8fc7\u5df2\u7ecf\u4fdd\u5b58\u7684\u5417\u6a21\u578b\u52a0\u8f7d\u8fdb\u6765\u3002   \u5982\u679c\u4e0d\u5e0c\u671b\u91cd\u590d\u5b9a\u4e49\u56fe\u4e0a\u7684\u8fd0\u7b97\uff0c\u53ef\u4ee5\u52a0\u8f7d\u5df2\u7ecf\u6301\u4e45\u5316\u7684\u56fe   import tensorflow as tf\n\n#\u76f4\u63a5\u52a0\u8f7d\u6301\u4e45\u5316\u7684\u56fe\nsaver = tf.train.import_meta_graph(path+'.meta')\nwith tf.Session() as sess:\n    saver.restore(ress,path)\n    #\u901a\u8fc7\u5f20\u91cf\u7684\u540d\u79f0\u6765\u83b7\u53d6\u5f20\u91cf\n    print sess.run(tf.get_default_graph().get_tensor_by_name('add:0'))\n\n#\u8f93\u51fa\u7ed3\u679c\uff1a[3.]   \u4fdd\u5b58\u6216\u52a0\u8f7d\u90e8\u5206\u53d8\u91cf   \u9ed8\u8ba4\u52a0\u8f7d\u548c\u4fdd\u5b58TF\u8ba1\u7b97\u56fe\u4e0a\u7684\u6240\u6709\u53d8\u91cf\uff0c\u4f46\u6709\u65f6\u53ef\u80fd\u53ea\u9700\u8981\u4fdd\u5b58\u548c\u52a0\u8f7d\u90e8\u5206\u53d8\u91cf\uff0c\u6bd4\u5982\uff0c\u6211\u4eec\u6709\u4e00\u4e2a\u8bad\u7ec3\u597d\u76845\u5c42\u7f51\u7edc\uff0c\u4f46\u73b0\u5728\u60f3\u5c1d\u8bd56\u5c42\u7684\u7f51\u7edc\uff0c\u90a3\u4e48\u53ef\u4ee5\u5c06\u524d5\u5c42\u53c2\u6570\u52a0\u8f7d\u8fdb\u6765\uff0c\u8bad\u7ec3\u6700\u540e\u4e00\u5c42\u7f51\u7edc\u5373\u53ef\uff08\u8fc1\u79fb\u5b66\u4e60\uff09  tf.train.Saver\u7c7b\u53ef\u4ee5\u63d0\u4f9b\u4e00\u4e2a\u5217\u8868\u6765\u6307\u5b9a\u9700\u8981\u4fdd\u5b58\u548c\u52a0\u8f7d\u7684\u53d8\u91cf\uff0csaver = tf.train.Saver([v1]),\u53ea\u6709\u53d8\u91cfv1\u88ab\u52a0\u8f7d\u8fdb\u6765   \u53d8\u91cf\u91cd\u547d\u540d   tf.train.Saver\u652f\u6301\u4fdd\u5b58\u548c\u52a0\u8f7d\u65f6\u7684\u53d8\u91cf\u91cd\u547d\u540d  v1 = tf.Variable(tf.constant(1.0,shape=[1]),name='other-v1')\nv2 = tf.Variable(tf.constant(2.0,shape=[1]),name='other-v2')\n\nsaver = tf.train.Saver({'v1':v1,'v2':v2})\n#\u539f\u6765\u540d\u79f0\u4e3av1\u7684\u53d8\u91cf\u73b0\u5728\u52a0\u8f7d\u5230\u53d8\u91cfv1\u4e2d\uff08\u540d\u79f0\u4e3aother-v1)\u3002   \u5176\u4ed6   tf.train.Saver\u4f1a\u4fdd\u5b58\u8fd0\u884cTF\u7a0b\u5e8f\u7684\u5168\u90e8\u4fe1\u606f\uff0c\u6709\u65f6\u5e76\u4e0d\u9700\u8981\uff0c\u6bd4\u5982\u5728\u6d4b\u8bd5\u6216\u79bb\u7ebf\u9884\u6d4b\u65f6\uff0c\u6211\u4eec\u53ea\u9700\u77e5\u9053\u795e\u7ecf\u7f51\u7edc\u7684\u524d\u5411\u4f20\u64ad\u8ba1\u7b97\u5230\u8f93\u51fa\u5c31\u53ef\u4ee5\u4e86\uff0c\u800c\u4e0d\u9700\u8981\u7c7b\u4f3c\u989d\u53d8\u91cf\u521d\u59cb\u5316\u7b49\u8f85\u52a9\u8282\u70b9\u4fe1\u606f\uff0c\u5728\u8fc1\u79fb\u5b66\u4e60\u4e2d\u4f1a\u9047\u5230\u8fd9\u4e9b\u95ee\u9898\uff0c\u4e8e\u662fTensorFlow\u63d0\u4f9b\u4e86convert_variables_to _constants\u51fd\u6570\uff0c\u901a\u8fc7\u8fd9\u4e2a\u51fd\u6570\u53ef\u4ee5\u5c06\u8ba1\u7b97\u56fe\u4e2d\u7684\u53d8\u91cf\u53ca\u5176\u53d6\u503c\u901a\u8fc7\u5e38\u91cf\u7684\u65b9\u5f0f\u4fdd\u5b58\uff0c\u8fd9\u6837TF\u8ba1\u7b97\u56fe\u53ef\u4ee5\u7edf\u4e00\u4fdd\u5b58\u5728\u4e00\u4e2a\u6587\u4ef6\u4e2d  imort tensorflow as tf\n\nfrom tensrflow.python.framework import graph_util\n\nv1 = tf.Variable(tf.constant(1.0,shape=[1]),name='v1')\nv2 = tf.Variable(tf.constant(2.0,shape=[2]),name='v2')\n\nresult = v1 + v2\n\ninit_op = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init_op)\n    #\u5bfc\u51fa\u5f53\u524d\u8ba1\u7b97\u56fe\u7684GraphDef\u90e8\u5206\uff0c\u53ea\u9700\u8fd9\u4e0e\u90e8\u5206\u53ef\u4ee5\u5b8c\u6210\u4ece\u8f93\u5165\u5230\u8f93\u51fa\u7684\u8ba1\u7b97\u8fc7\u7a0b\n    graph_def  = tf.get_default_graph().as_graph_def()\n\n    output_graph_def = graph_util.convert_variables_to_constants(sess,graph_def,['add'])\n    #\u5c06\u5bfc\u51fa\u7684\u6a21\u578b\u4fdd\u5b58\u6210\u6587\u4ef6\n    with tf.gfile.GFile('C:/model.pb','wb') as f:\n        f.write(output_graph_def.SerializeToString())  import tensorflow as tf\nfrom tensorflow.python.platform import gfile\n\nwith tf.Session() as sess:\n    path = 'C:/model.pb'\n    #\u8bfb\u53d6\u4fdd\u5b58\u7684\u6587\u4ef6\uff0c\u5e76\u5c06\u6587\u4ef6\u89e3\u6790\u6210\u5bf9\u5e94\u7684GraphDef Protocol Buffer\n    with gfile.FastGFile(path,'rb') as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromeString(f.read())\n    result = tf.import_graph_def(graph_def,return_element=['add:0'])\n    print sess.run(result)",
            "title": "TF\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u4e3e\u4f8b"
        },
        {
            "location": "/chapter6/",
            "text": "TF\u5b9e\u73b0CNN\u4e3e\u4f8b\n\n\n\u8fd9\u4e00\u90e8\u5206\u6211\u4eec\u770b\u4e00\u4e0b\u5982\u4f55\u4f7f\u7528TensorFlow\u5b9e\u73b0CNN(\u5377\u79ef\u795e\u7ecf\u7f51\u7edc)\uff0c\u6211\u4eec\u5728\u524d\u9762\u7684\u57f9\u8bad\u4e2d\u5df2\u7ecf\u5168\u9762\u7684\u4ecb\u7ecd\u4e86CNN\u7684\u77e5\u8bc6\uff0c\u5305\u62ec\u7ecf\u5178\u7684\u6a21\u578b\u50cfLeNet\uff0cAlexNet,Google Inception\uff0cResNet,VGG16(19),YOLO\u7b49\uff0c\n\u70b9\u8fd9\u91cc\u8fdb\u5165CNN\u5b66\u4e60\u6a21\u5f0f\n,\u8fd9\u91cc\u53ea\u4e3e\u4e24\u4e2a\u7b80\u5355\u7684\u6817\u5b50\u3002\n\n\n1. LeNet-5\n\n\nLeNet-5\u5927\u5bb6\u6700\u719f\u6089\u4e0d\u8fc7\u4e86\uff0c\u76f4\u63a5coding\n\n\n#x = tf.palceholder(tf.float32,[BATCH_SIZE,IAMGE_SIZE,IMAGE_SIZE,NUM_CHANNELS],name='x-input')\n\nimport trnsorflow as tf\n\nINPUT_NODE = 784\nOUTPUT_NODE = 10\n\nIMAGE_SIZE = 28\nNUM_CHANNELS = 1\nNUM_LABELS = 10\n\nCONV1_DEEP = 32\nCONV1_SIZE = 5\n\nCONV2_DEEP = 64\nCONV2_SIZE = 5\n\nFC_SIZE = 512\n\ndef inference(input_tensor,train,regularizer):\n    #layer1\n    with tf.variable_scope('layer1-conv1'):\n        conv1_weghts = tf.get_variable('weight',[CONV1_SIZE,CONV1_SIZE,NUM_SIZE,NUM_CHANNELS,CONV1_DEEP],initializer=tf.truncated_initializer(stddev=0.1))\n        conv1_biases = tf.get_variable('bias',[CONV1_DEEP],initializer=tf.constant_initializer(0.))\n\n        conv1 = tf.nn.conv2d(input_tensor,conv1_weights,strides=[1,1,1,1]padding='SAME')\n        relu1 = tf.nn.relu(tf.nn.bias_add(conv1,conv1_biases))\n    #pool1\n    with tf.name_scope('layer1-pool'):\n        pool1 = tf.nn.max_pool(relu1,ksize = [1,2,2,1],strides=[1,2,2,1],padding='SAME')\n\n    #layer2\n    with tf.variable_scope('layer2-conv2')\uff1a\n        conv2_weights = tf.get_variable('weight',[CONV2_SIZE,CONV2_DEEP,initalizer=tf.tuncated_normal_initalizer(stddev=0.1)])\n        conv2_biases = tf.get_variable('bias',[SONV2_DEEP],initalizer=tf.constant_initializer(0.0))\n        conv2 = tf.nn.conv2d(pool1,con2_weights,strides=[1,1,1,1],padding='SAME')\n        relu2 = tf.nn.relu(tf.nn.bias_add(conv2,conv2_biases))\n    #pool2\n    with tf.name_scope('layer2-pool2'):\n        pool2 = tf.nn.max_pool(relu2,ksize=[1,2,2,1],strides=[1,2,2,1],padding = 'SAME')\n\n    pool_shape = pool2.get_shape().as_list()\n    #[batch,size1,size2,deepsize(channels)]\n    nodes = pool_shape[1]*pool_shape[2]*pool_shape[3]\n    reshaped = tf.reshape(pool2,[pool_shape[0],nodes])\n\n    #FC_1\n    with tf.variable_scope('layer3-fc1'):\n        fc1_weights = tf.get_variable('weight',[nodes,FC_SIZE],initializer=tf.truncated_normal_initializer(steddev=0.1))\n        if regularizer != None:\n            tf.add_to_collection('losses',regularizer(fc1_weights))\n        fc1_biases = tf.get_variable('bias',[FC_SIZE],initializer=tf.constant_initializer(0.1))\n        fc1 = tf.nn.relu(tf.matmul(reshaped,fc1_weights)+fc1_biasws)\n        if train:\n            fc1 = tf.nn.dropout(fc1,0.5)\n    #\u8fd9\u91cc\u8981\u6ce8\u610f\u7684\u662f\uff1aCNN\u7684\u6b63\u5219\u5316\u662f\u52a0\u5728\u5168\u8fde\u63a5\u5c42\u7684\uff0cCNN\u7684dropout\u4e5f\u662f\u9488\u5bf9\u5168\u8fde\u63a5\u5c42\u7684\uff0c\u540e\u9762\u6211\u4eec\u4f1a\u5c06RNN\u7684dropout\u548cCNN\u4e0d\u540c\n\n    #FC_2\n    with tf.variable_scope('layer4-fc2'):\n        fc2_weights = tf.get_variable('weight',[FC_SIZE,NUM_LABELS],initializer=tf.truncated_normal_initializer(steddev=0.1))\n        if regularizer != None:\n            tf.add_to_collection('losses',regularizer(fc2_weights))\n        fc2_biases = tf.get_variable('bias',[NUM_LABELS],initializer=tf.constant_initilizer(0.1))\n        logit = tf.matmul(fc1,fc2_weights)+fc2_biases\n\n    return logit\n\n\n#\u8bad\u7ec3\u7684\u8fc7\u7a0b\u540c\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\u76f8\u540c\uff0c\u4e0d\u60f3\u518d\u8d58\u8ff0\n1.\u5b9a\u4e49placeholder()\n2.\u5b9a\u4e49\u8bc4\u4ef7\u6307\u6807\uff0c\u635f\u5931\u51fd\u6570\uff0c\u5b66\u4e60\u7387\uff0c\u6ed1\u52a8\u5e73\u5747\u64cd\u4f5c\uff0c\u53ca\u4f18\u5316\u65b9\u6cd5\n3. \u8bad\u7ec3\u8fc7\u7a0b\u6301\u4e45\u5316\u6a21\u578b\n4. \u6253\u5370\u8bad\u7ec3\u7ed3\u679c\n\n\u6ce8\u610f\u4e00\u70b9\u7684\u662f\uff1aloss = cross_entropy_mean+tf.add_n(tf.get_collection('losses'))\n\n\u8fd9\u4e9b\u90fd\u975e\u5e38\u7b80\u5355\uff0c\u5305\u62ecRNN\u4e5f\u662f\u540c\u6837\u7684\u8fc7\u7a0b\uff0c\u540c\u6837\u4e5f\u4e0d\u518d\u8d58\u8ff0\n\n\n\n\n\n\n\n2. Inception-v3\n\n\nGoogel Inception-v3\u6211\u4eec\u4e5f\u5f88\u719f\u6089\u4e86\uff0cInception-v3\u670946\u5c42\uff0c\u670911\u4e2aInception\u6a21\u5757\u7ec4\u6210\u3002\u4e0b\u56fe\u5c31\u662fInception\u6a21\u5757\u7684\u793a\u610f\u56fe\uff0c\u6211\u4eec\u4f1a\u7528TensorFlow\u5b9e\u73b0\u8be5\u6a21\u5757\u3002\n\n\n\n\n\u56fe1\uff1aInception-v3\u4e3b\u8981\u6784\u6210\u6a21\u5757\n\n\n\u6211\u4eec\u4f7f\u7528TensorFloe-Sli\u5de5\u5177\u6765\u66f4\u52a0\u7b80\u6d01\u7684\u5b9e\u73b0Inception,\u901a\u8fc7TF-Slim\u53ef\u4ee5\u5728\u4e00\u884c\u4ee3\u7801\u5b9e\u5fc3CNN\u7684\u524d\u5411\u4f20\u64ad\uff0cslim.conv2d\u6709\u4e09\u4e2a\u5fc5\u586b\u53c2\u6570\uff1a\u8f93\u5165\u8282\u70b9\u7684\u77e9\u9635\uff0c\u5f53\u524d\u5377\u79ef\u5c42\u8fc7\u6ee4\u5668\u7684\u6df1\u5ea6\uff08\u8fc7\u6ee4\u5668\u7684\u4e2a\u6570\uff09\uff0c\u8fc7\u6ee4\u5668\u7684\u5c3a\u5bf8\uff0c\u53ef\u9009\u7684\u53c2\u6570\u6709\u8fc7\u6ee4\u5668\u7684\u6b65\u957f\uff0c\u662f\u5426\u5168\u96f6\u586b\u5145\uff0c\u6fc0\u6d3b\u51fd\u6570\u7684\u9009\u62e9\uff0c\u53d8\u91cf\u7684\u547d\u540d\u7a7a\u95f4\u7b49\u3002\n\n\n\nwith slim.arg_scope([slim.conv2d,slim.max_pool2d,slim.avg_pool2d],stride=1,padding='SAME'):\n    #slim.arg_scope()\u7528\u4e8e\u8bbe\u7f6e\u9ed8\u8ba4\u7684\u53c2\u6570\u53d6\u503c\uff0c\u7b2c\u4e00\u4e2a\u53c2\u6570\u662f\u4e00\u4e2a\u51fd\u6570\u5217\u8868\uff0c\u5728\u8fd9\u4e2a\u5217\u8868\u4e2d\u7684\u51fd\u6570\u5c06\u4f7f\u7528\u53c2\u6570\u7684\u9ed8\u8ba4\u53d6\u503c\uff0c\u76ee\u7684\u662f\u4e3a\u4e86\u964d\u4f4ecoding\u7684\u5197\u4f59\u3002\n    #\u6b64\u5904\u7701\u53bbInception\u7684\u5176\u4ed6\u7ed3\u6784\uff0c\u5047\u8bbe\u8f93\u5165\u56fe\u7247\u7ecf\u8fc7\u4e4b\u524d\u7684\u7f51\u7edc\u4f20\u64ad\u7ed3\u679c\u4fdd\u5b58\u5728net\u4e2d\uff0cnet=\u4e0a\u4e00\u5c42\u7684\u8f93\u51fa\u8282\u70b9\u7684\u77e9\u9635\u3002\n\n    with tf.variable_scope('maxed_7c'):\n        with tf.variable_scope('Branch_0'):\n            branch_0 = slim.conv2d(net,320,[1,1],scope='Conv2d_0a_1X1')\n        with tf.variable_scope('Branch_1'):\n            branch_1 = slim.conv2d(net,384,[1,1],scope='Conv2d_0a_1X1')\n            branch_1 = tf.concat(3,[\n                slim.conv2d(branch_1,384,[1,3],scope='Conv2d_0b_1X3'),\n                slim.conv2d(branch_1,384,[3,1],scope='Conv2d_0c_3x1')\n                ])\n            #3\u4ee3\u8868\u77e9\u9635\u5728\u6df1\u5ea6\u8fd9\u4e2a\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u77e9\u9635\u94fe\u63a5\n\n        with tf.variable_scope('Branch_2'):\n            branch_2 = slim.conv2d(net,448,[1,1],scope='Conv2d_0a_1x1')\n            branch_2 = slim.conv2d(branch_2,384,[3,3],scope='Conv2d_0b_3x3')\n            branch_2 = tf.concat(3,[\n                slim.conv2d(branch_2,384,[1,3],scope='Conv2d_0c_1x3'),\n                slim.conv2d(branch_2,384,[3,1],scope='Conv2d_0c_3x1')\n                ])\n        with tf.variable_scope('Branch_3'):\n            branch_3 = slim.avg_pool2d(net,[3,3],scope='AvgPool_oa_3x3')\n            branch_3 = slim.conv2d(branch_3,182,[1,1],scope='Conv2d_0b_1x1')\n        net = tf.concat(3,[branch_0,branch_1,brnch_2,branch_3])\n\n\n\n\n\n\n\n3. \u8fc1\u79fb\u5b66\u4e60\n\n\n\u968f\u7740\u6a21\u578b\u5c42\u6570\u53ca\u590d\u6742\u5ea6\u7684\u589e\u52a0\uff0c\u8bad\u7ec3\u6df1\u5ea6\u6a21\u578b\u4f1a\u975e\u5e38\u56f0\u96be\uff0c\u4e00\u65b9\u9762\u9700\u8981\u6709\u5927\u91cf\u7684\u5e26\u6807\u7b7e\u6570\u636e\uff0c\u5373\u4f7f\u6536\u96c6\u5230\u4e86\u8fd9\u4e9b\u6d77\u91cf\u7684\u6709\u6807\u7b7e\u6570\u636e\uff0c\u8bad\u7ec3\u4e00\u4e2a\u590d\u6742\u7684\u6a21\u578b\u4e5f\u9700\u8981\u5c11\u5219\u51e0\u5929\u591a\u5219\u51e0\u5468\uff0c\u51e0\u4e2a\u6708\u7684\u65f6\u95f4\uff0c\u4e3a\u4e86\u89e3\u51b3\u6807\u6ce8\u6570\u636e\u548c\u8bad\u7ec3\u65f6\u95f4\u7684\u95ee\u9898\uff0c\u53ef\u4ee5\u4f7f\u7528\u8fc1\u79fb\u5b66\u4e60\u3002\n\n\n\u6240\u8c13\u8fc1\u79fb\u5b66\u4e60\u5c31\u662f\u5c06\u4e00\u4e2a\u95ee\u9898\u4e0a\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u901a\u8fc7\u7b80\u5355\u989d\u8c03\u6574\u4f7f\u5176\u9002\u7528\u4e8e\u4e00\u4e2a\u65b0\u7684\u95ee\u9898\u3002\n\n\ndef main(_):\n    # \u8bfb\u53d6\u6240\u6709\u56fe\u7247\u3002\n    image_lists = create_image_lists(TEST_PERCENTAGE, VALIDATION_PERCENTAGE)\n    n_classes = len(image_lists.keys())\n    # \u8bfb\u53d6\u5df2\u7ecf\u8bad\u7ec3\u597d\u7684Inception-v3\u6a21\u578b\u3002\n    # \u8c37\u6b4c\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u4fdd\u5b58\u5728\u4e86GraphDef Protocol Buffer\u4e2d\uff0c\u91cc\u9762\u4fdd\u5b58\u4e86\u6bcf\u4e00\u4e2a\u8282\u70b9\u53d6\u503c\u7684\u8ba1\u7b97\u65b9\u6cd5\u4ee5\u53ca\u53d8\u91cf\u7684\u53d6\u503c\u3002\n    # TensorFlow\u6a21\u578b\u6301\u4e45\u5316\u7684\u95ee\u9898\u5728\u7b2c5\u7ae0\u4e2d\u6709\u8be6\u7ec6\u7684\u4ecb\u7ecd\u3002\n    with gfile.FastGFile(os.path.join(MODEL_DIR, MODEL_FILE), 'rb') as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(f.read())\n    # \u52a0\u8f7d\u8bfb\u53d6\u7684Inception-v3\u6a21\u578b\uff0c\u5e76\u8fd4\u56de\u6570\u636e\u8f93\u5165\u6240\u5bf9\u5e94\u7684\u5f20\u91cf\u4ee5\u53ca\u8ba1\u7b97\u74f6\u9888\u5c42\u7ed3\u679c\u6240\u5bf9\u5e94\u7684\u5f20\u91cf\u3002\n    bottleneck_tensor, jpeg_data_tensor = tf.import_graph_def(graph_def, return_elements=[BOTTLENECK_TENSOR_NAME, JPEG_DATA_TENSOR_NAME])\n    # \u5b9a\u4e49\u65b0\u7684\u795e\u7ecf\u7f51\u7edc\u8f93\u5165\uff0c\u8fd9\u4e2a\u8f93\u5165\u5c31\u662f\u65b0\u7684\u56fe\u7247\u7ecf\u8fc7Inception-v3\u6a21\u578b\u524d\u5411\u4f20\u64ad\u5230\u8fbe\u74f6\u9888\u5c42\u65f6\u7684\u7ed3\u70b9\u53d6\u503c\u3002\n    # \u53ef\u4ee5\u5c06\u8fd9\u4e2a\u8fc7\u7a0b\u7c7b\u4f3c\u7684\u7406\u89e3\u4e3a\u4e00\u79cd\u7279\u5f81\u63d0\u53d6\u3002\n    bottleneck_input = tf.placeholder(tf.float32, [None, BOTTLENECK_TENSOR_SIZE], name='BottleneckInputPlaceholder')\n    # \u5b9a\u4e49\u65b0\u7684\u6807\u51c6\u7b54\u6848\u8f93\u5165\n    ground_truth_input = tf.placeholder(tf.float32, [None, n_classes], name='GroundTruthInput')\n    # \u5b9a\u4e49\u4e00\u5c42\u5168\u8fde\u63a5\u5c42\u6765\u89e3\u51b3\u65b0\u7684\u56fe\u7247\u5206\u7c7b\u95ee\u9898\u3002\n    # \u56e0\u4e3a\u8bad\u7ec3\u597d\u7684Inception-v3\u6a21\u578b\u5df2\u7ecf\u5c06\u539f\u59cb\u7684\u56fe\u7247\u62bd\u8c61\u4e3a\u4e86\u66f4\u52a0\u5bb9\u6613\u5206\u7c7b\u7684\u7279\u5f81\u5411\u91cf\u4e86\uff0c\u6240\u4ee5\u4e0d\u9700\u8981\u518d\u8bad\u7ec3\u90a3\u4e48\u590d\u6742\u7684\u795e\u7ecf\u7f51\u7edc\u6765\u5b8c\u6210\u8fd9\u4e2a\u65b0\u7684\u5206\u7c7b\u4efb\u52a1\u3002\n    with tf.name_scope('final_training_ops'):\n        weights = tf.Variable(tf.truncated_normal([BOTTLENECK_TENSOR_SIZE, n_classes], stddev=0.001))\n        biases = tf.Variable(tf.zeros([n_classes]))\n        logits = tf.matmul(bottleneck_input, weights) + biases\n        final_tensor = tf.nn.softmax(logits)\n    # \u5b9a\u4e49\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=ground_truth_input)\n    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n    train_step = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy_mean)\n    # \u8ba1\u7b97\u6b63\u786e\u7387\n    with tf.name_scope('evaluation'):\n        correct_prediction = tf.equal(tf.argmax(final_tensor, 1), tf.argmax(ground_truth_input, 1))\n        evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n    with tf.Session() as sess:\n        tf.global_variables_initializer().run()\n        # \u8bad\u7ec3\u8fc7\u7a0b\n        for i in range(STEPS):\n            # \u6bcf\u6b21\u83b7\u53d6\u4e00\u4e2abatch\u7684\u8bad\u7ec3\u6570\u636e\n            train_bottlenecks, train_ground_truth = get_random_cached_bottlenecks(\n                sess, n_classes, image_lists, BATCH, 'training', jpeg_data_tensor, bottleneck_tensor)\n            sess.run(train_step, feed_dict={bottleneck_input: train_bottlenecks, ground_truth_input: train_ground_truth})\n            # \u5728\u9a8c\u8bc1\u96c6\u4e0a\u6d4b\u8bd5\u6b63\u786e\u7387\u3002\n            if i%100 == 0 or i+1 == STEPS:\n                validation_bottlenecks, validation_ground_truth = get_random_cached_bottlenecks(\n                    sess, n_classes, image_lists, BATCH, 'validation', jpeg_data_tensor, bottleneck_tensor)\n                validation_accuracy = sess.run(evaluation_step, feed_dict={\n                    bottleneck_input:validation_bottlenecks, ground_truth_input: validation_ground_truth})\n                print('Step %d: Validation accuracy on random sampled %d examples = %.1f%%'\n                      % (i, BATCH, validation_accuracy*100))\n        # \u5728\u6700\u540e\u7684\u6d4b\u8bd5\u6570\u636e\u4e0a\u6d4b\u8bd5\u6b63\u786e\u7387\n        test_bottlenecks, test_ground_truth = get_test_bottlenecks(sess, image_lists, n_classes,\n                                                                       jpeg_data_tensor, bottleneck_tensor)\n        test_accuracy = sess.run(evaluation_step, feed_dict={bottleneck_input: test_bottlenecks,\n                                                                 ground_truth_input: test_ground_truth})\n        print('Final test accuracy = %.1f%%' % (test_accuracy * 100))",
            "title": "TensorFlow\u5b9e\u73b0CNN\u4e3e\u4f8b"
        },
        {
            "location": "/chapter6/#tfcnn",
            "text": "\u8fd9\u4e00\u90e8\u5206\u6211\u4eec\u770b\u4e00\u4e0b\u5982\u4f55\u4f7f\u7528TensorFlow\u5b9e\u73b0CNN(\u5377\u79ef\u795e\u7ecf\u7f51\u7edc)\uff0c\u6211\u4eec\u5728\u524d\u9762\u7684\u57f9\u8bad\u4e2d\u5df2\u7ecf\u5168\u9762\u7684\u4ecb\u7ecd\u4e86CNN\u7684\u77e5\u8bc6\uff0c\u5305\u62ec\u7ecf\u5178\u7684\u6a21\u578b\u50cfLeNet\uff0cAlexNet,Google Inception\uff0cResNet,VGG16(19),YOLO\u7b49\uff0c \u70b9\u8fd9\u91cc\u8fdb\u5165CNN\u5b66\u4e60\u6a21\u5f0f ,\u8fd9\u91cc\u53ea\u4e3e\u4e24\u4e2a\u7b80\u5355\u7684\u6817\u5b50\u3002  1. LeNet-5  LeNet-5\u5927\u5bb6\u6700\u719f\u6089\u4e0d\u8fc7\u4e86\uff0c\u76f4\u63a5coding  #x = tf.palceholder(tf.float32,[BATCH_SIZE,IAMGE_SIZE,IMAGE_SIZE,NUM_CHANNELS],name='x-input')\n\nimport trnsorflow as tf\n\nINPUT_NODE = 784\nOUTPUT_NODE = 10\n\nIMAGE_SIZE = 28\nNUM_CHANNELS = 1\nNUM_LABELS = 10\n\nCONV1_DEEP = 32\nCONV1_SIZE = 5\n\nCONV2_DEEP = 64\nCONV2_SIZE = 5\n\nFC_SIZE = 512\n\ndef inference(input_tensor,train,regularizer):\n    #layer1\n    with tf.variable_scope('layer1-conv1'):\n        conv1_weghts = tf.get_variable('weight',[CONV1_SIZE,CONV1_SIZE,NUM_SIZE,NUM_CHANNELS,CONV1_DEEP],initializer=tf.truncated_initializer(stddev=0.1))\n        conv1_biases = tf.get_variable('bias',[CONV1_DEEP],initializer=tf.constant_initializer(0.))\n\n        conv1 = tf.nn.conv2d(input_tensor,conv1_weights,strides=[1,1,1,1]padding='SAME')\n        relu1 = tf.nn.relu(tf.nn.bias_add(conv1,conv1_biases))\n    #pool1\n    with tf.name_scope('layer1-pool'):\n        pool1 = tf.nn.max_pool(relu1,ksize = [1,2,2,1],strides=[1,2,2,1],padding='SAME')\n\n    #layer2\n    with tf.variable_scope('layer2-conv2')\uff1a\n        conv2_weights = tf.get_variable('weight',[CONV2_SIZE,CONV2_DEEP,initalizer=tf.tuncated_normal_initalizer(stddev=0.1)])\n        conv2_biases = tf.get_variable('bias',[SONV2_DEEP],initalizer=tf.constant_initializer(0.0))\n        conv2 = tf.nn.conv2d(pool1,con2_weights,strides=[1,1,1,1],padding='SAME')\n        relu2 = tf.nn.relu(tf.nn.bias_add(conv2,conv2_biases))\n    #pool2\n    with tf.name_scope('layer2-pool2'):\n        pool2 = tf.nn.max_pool(relu2,ksize=[1,2,2,1],strides=[1,2,2,1],padding = 'SAME')\n\n    pool_shape = pool2.get_shape().as_list()\n    #[batch,size1,size2,deepsize(channels)]\n    nodes = pool_shape[1]*pool_shape[2]*pool_shape[3]\n    reshaped = tf.reshape(pool2,[pool_shape[0],nodes])\n\n    #FC_1\n    with tf.variable_scope('layer3-fc1'):\n        fc1_weights = tf.get_variable('weight',[nodes,FC_SIZE],initializer=tf.truncated_normal_initializer(steddev=0.1))\n        if regularizer != None:\n            tf.add_to_collection('losses',regularizer(fc1_weights))\n        fc1_biases = tf.get_variable('bias',[FC_SIZE],initializer=tf.constant_initializer(0.1))\n        fc1 = tf.nn.relu(tf.matmul(reshaped,fc1_weights)+fc1_biasws)\n        if train:\n            fc1 = tf.nn.dropout(fc1,0.5)\n    #\u8fd9\u91cc\u8981\u6ce8\u610f\u7684\u662f\uff1aCNN\u7684\u6b63\u5219\u5316\u662f\u52a0\u5728\u5168\u8fde\u63a5\u5c42\u7684\uff0cCNN\u7684dropout\u4e5f\u662f\u9488\u5bf9\u5168\u8fde\u63a5\u5c42\u7684\uff0c\u540e\u9762\u6211\u4eec\u4f1a\u5c06RNN\u7684dropout\u548cCNN\u4e0d\u540c\n\n    #FC_2\n    with tf.variable_scope('layer4-fc2'):\n        fc2_weights = tf.get_variable('weight',[FC_SIZE,NUM_LABELS],initializer=tf.truncated_normal_initializer(steddev=0.1))\n        if regularizer != None:\n            tf.add_to_collection('losses',regularizer(fc2_weights))\n        fc2_biases = tf.get_variable('bias',[NUM_LABELS],initializer=tf.constant_initilizer(0.1))\n        logit = tf.matmul(fc1,fc2_weights)+fc2_biases\n\n    return logit\n\n\n#\u8bad\u7ec3\u7684\u8fc7\u7a0b\u540c\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\u76f8\u540c\uff0c\u4e0d\u60f3\u518d\u8d58\u8ff0\n1.\u5b9a\u4e49placeholder()\n2.\u5b9a\u4e49\u8bc4\u4ef7\u6307\u6807\uff0c\u635f\u5931\u51fd\u6570\uff0c\u5b66\u4e60\u7387\uff0c\u6ed1\u52a8\u5e73\u5747\u64cd\u4f5c\uff0c\u53ca\u4f18\u5316\u65b9\u6cd5\n3. \u8bad\u7ec3\u8fc7\u7a0b\u6301\u4e45\u5316\u6a21\u578b\n4. \u6253\u5370\u8bad\u7ec3\u7ed3\u679c\n\n\u6ce8\u610f\u4e00\u70b9\u7684\u662f\uff1aloss = cross_entropy_mean+tf.add_n(tf.get_collection('losses'))\n\n\u8fd9\u4e9b\u90fd\u975e\u5e38\u7b80\u5355\uff0c\u5305\u62ecRNN\u4e5f\u662f\u540c\u6837\u7684\u8fc7\u7a0b\uff0c\u540c\u6837\u4e5f\u4e0d\u518d\u8d58\u8ff0   2. Inception-v3  Googel Inception-v3\u6211\u4eec\u4e5f\u5f88\u719f\u6089\u4e86\uff0cInception-v3\u670946\u5c42\uff0c\u670911\u4e2aInception\u6a21\u5757\u7ec4\u6210\u3002\u4e0b\u56fe\u5c31\u662fInception\u6a21\u5757\u7684\u793a\u610f\u56fe\uff0c\u6211\u4eec\u4f1a\u7528TensorFlow\u5b9e\u73b0\u8be5\u6a21\u5757\u3002   \u56fe1\uff1aInception-v3\u4e3b\u8981\u6784\u6210\u6a21\u5757  \u6211\u4eec\u4f7f\u7528TensorFloe-Sli\u5de5\u5177\u6765\u66f4\u52a0\u7b80\u6d01\u7684\u5b9e\u73b0Inception,\u901a\u8fc7TF-Slim\u53ef\u4ee5\u5728\u4e00\u884c\u4ee3\u7801\u5b9e\u5fc3CNN\u7684\u524d\u5411\u4f20\u64ad\uff0cslim.conv2d\u6709\u4e09\u4e2a\u5fc5\u586b\u53c2\u6570\uff1a\u8f93\u5165\u8282\u70b9\u7684\u77e9\u9635\uff0c\u5f53\u524d\u5377\u79ef\u5c42\u8fc7\u6ee4\u5668\u7684\u6df1\u5ea6\uff08\u8fc7\u6ee4\u5668\u7684\u4e2a\u6570\uff09\uff0c\u8fc7\u6ee4\u5668\u7684\u5c3a\u5bf8\uff0c\u53ef\u9009\u7684\u53c2\u6570\u6709\u8fc7\u6ee4\u5668\u7684\u6b65\u957f\uff0c\u662f\u5426\u5168\u96f6\u586b\u5145\uff0c\u6fc0\u6d3b\u51fd\u6570\u7684\u9009\u62e9\uff0c\u53d8\u91cf\u7684\u547d\u540d\u7a7a\u95f4\u7b49\u3002  \nwith slim.arg_scope([slim.conv2d,slim.max_pool2d,slim.avg_pool2d],stride=1,padding='SAME'):\n    #slim.arg_scope()\u7528\u4e8e\u8bbe\u7f6e\u9ed8\u8ba4\u7684\u53c2\u6570\u53d6\u503c\uff0c\u7b2c\u4e00\u4e2a\u53c2\u6570\u662f\u4e00\u4e2a\u51fd\u6570\u5217\u8868\uff0c\u5728\u8fd9\u4e2a\u5217\u8868\u4e2d\u7684\u51fd\u6570\u5c06\u4f7f\u7528\u53c2\u6570\u7684\u9ed8\u8ba4\u53d6\u503c\uff0c\u76ee\u7684\u662f\u4e3a\u4e86\u964d\u4f4ecoding\u7684\u5197\u4f59\u3002\n    #\u6b64\u5904\u7701\u53bbInception\u7684\u5176\u4ed6\u7ed3\u6784\uff0c\u5047\u8bbe\u8f93\u5165\u56fe\u7247\u7ecf\u8fc7\u4e4b\u524d\u7684\u7f51\u7edc\u4f20\u64ad\u7ed3\u679c\u4fdd\u5b58\u5728net\u4e2d\uff0cnet=\u4e0a\u4e00\u5c42\u7684\u8f93\u51fa\u8282\u70b9\u7684\u77e9\u9635\u3002\n\n    with tf.variable_scope('maxed_7c'):\n        with tf.variable_scope('Branch_0'):\n            branch_0 = slim.conv2d(net,320,[1,1],scope='Conv2d_0a_1X1')\n        with tf.variable_scope('Branch_1'):\n            branch_1 = slim.conv2d(net,384,[1,1],scope='Conv2d_0a_1X1')\n            branch_1 = tf.concat(3,[\n                slim.conv2d(branch_1,384,[1,3],scope='Conv2d_0b_1X3'),\n                slim.conv2d(branch_1,384,[3,1],scope='Conv2d_0c_3x1')\n                ])\n            #3\u4ee3\u8868\u77e9\u9635\u5728\u6df1\u5ea6\u8fd9\u4e2a\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u77e9\u9635\u94fe\u63a5\n\n        with tf.variable_scope('Branch_2'):\n            branch_2 = slim.conv2d(net,448,[1,1],scope='Conv2d_0a_1x1')\n            branch_2 = slim.conv2d(branch_2,384,[3,3],scope='Conv2d_0b_3x3')\n            branch_2 = tf.concat(3,[\n                slim.conv2d(branch_2,384,[1,3],scope='Conv2d_0c_1x3'),\n                slim.conv2d(branch_2,384,[3,1],scope='Conv2d_0c_3x1')\n                ])\n        with tf.variable_scope('Branch_3'):\n            branch_3 = slim.avg_pool2d(net,[3,3],scope='AvgPool_oa_3x3')\n            branch_3 = slim.conv2d(branch_3,182,[1,1],scope='Conv2d_0b_1x1')\n        net = tf.concat(3,[branch_0,branch_1,brnch_2,branch_3])   3. \u8fc1\u79fb\u5b66\u4e60  \u968f\u7740\u6a21\u578b\u5c42\u6570\u53ca\u590d\u6742\u5ea6\u7684\u589e\u52a0\uff0c\u8bad\u7ec3\u6df1\u5ea6\u6a21\u578b\u4f1a\u975e\u5e38\u56f0\u96be\uff0c\u4e00\u65b9\u9762\u9700\u8981\u6709\u5927\u91cf\u7684\u5e26\u6807\u7b7e\u6570\u636e\uff0c\u5373\u4f7f\u6536\u96c6\u5230\u4e86\u8fd9\u4e9b\u6d77\u91cf\u7684\u6709\u6807\u7b7e\u6570\u636e\uff0c\u8bad\u7ec3\u4e00\u4e2a\u590d\u6742\u7684\u6a21\u578b\u4e5f\u9700\u8981\u5c11\u5219\u51e0\u5929\u591a\u5219\u51e0\u5468\uff0c\u51e0\u4e2a\u6708\u7684\u65f6\u95f4\uff0c\u4e3a\u4e86\u89e3\u51b3\u6807\u6ce8\u6570\u636e\u548c\u8bad\u7ec3\u65f6\u95f4\u7684\u95ee\u9898\uff0c\u53ef\u4ee5\u4f7f\u7528\u8fc1\u79fb\u5b66\u4e60\u3002  \u6240\u8c13\u8fc1\u79fb\u5b66\u4e60\u5c31\u662f\u5c06\u4e00\u4e2a\u95ee\u9898\u4e0a\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u901a\u8fc7\u7b80\u5355\u989d\u8c03\u6574\u4f7f\u5176\u9002\u7528\u4e8e\u4e00\u4e2a\u65b0\u7684\u95ee\u9898\u3002  def main(_):\n    # \u8bfb\u53d6\u6240\u6709\u56fe\u7247\u3002\n    image_lists = create_image_lists(TEST_PERCENTAGE, VALIDATION_PERCENTAGE)\n    n_classes = len(image_lists.keys())\n    # \u8bfb\u53d6\u5df2\u7ecf\u8bad\u7ec3\u597d\u7684Inception-v3\u6a21\u578b\u3002\n    # \u8c37\u6b4c\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u4fdd\u5b58\u5728\u4e86GraphDef Protocol Buffer\u4e2d\uff0c\u91cc\u9762\u4fdd\u5b58\u4e86\u6bcf\u4e00\u4e2a\u8282\u70b9\u53d6\u503c\u7684\u8ba1\u7b97\u65b9\u6cd5\u4ee5\u53ca\u53d8\u91cf\u7684\u53d6\u503c\u3002\n    # TensorFlow\u6a21\u578b\u6301\u4e45\u5316\u7684\u95ee\u9898\u5728\u7b2c5\u7ae0\u4e2d\u6709\u8be6\u7ec6\u7684\u4ecb\u7ecd\u3002\n    with gfile.FastGFile(os.path.join(MODEL_DIR, MODEL_FILE), 'rb') as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(f.read())\n    # \u52a0\u8f7d\u8bfb\u53d6\u7684Inception-v3\u6a21\u578b\uff0c\u5e76\u8fd4\u56de\u6570\u636e\u8f93\u5165\u6240\u5bf9\u5e94\u7684\u5f20\u91cf\u4ee5\u53ca\u8ba1\u7b97\u74f6\u9888\u5c42\u7ed3\u679c\u6240\u5bf9\u5e94\u7684\u5f20\u91cf\u3002\n    bottleneck_tensor, jpeg_data_tensor = tf.import_graph_def(graph_def, return_elements=[BOTTLENECK_TENSOR_NAME, JPEG_DATA_TENSOR_NAME])\n    # \u5b9a\u4e49\u65b0\u7684\u795e\u7ecf\u7f51\u7edc\u8f93\u5165\uff0c\u8fd9\u4e2a\u8f93\u5165\u5c31\u662f\u65b0\u7684\u56fe\u7247\u7ecf\u8fc7Inception-v3\u6a21\u578b\u524d\u5411\u4f20\u64ad\u5230\u8fbe\u74f6\u9888\u5c42\u65f6\u7684\u7ed3\u70b9\u53d6\u503c\u3002\n    # \u53ef\u4ee5\u5c06\u8fd9\u4e2a\u8fc7\u7a0b\u7c7b\u4f3c\u7684\u7406\u89e3\u4e3a\u4e00\u79cd\u7279\u5f81\u63d0\u53d6\u3002\n    bottleneck_input = tf.placeholder(tf.float32, [None, BOTTLENECK_TENSOR_SIZE], name='BottleneckInputPlaceholder')\n    # \u5b9a\u4e49\u65b0\u7684\u6807\u51c6\u7b54\u6848\u8f93\u5165\n    ground_truth_input = tf.placeholder(tf.float32, [None, n_classes], name='GroundTruthInput')\n    # \u5b9a\u4e49\u4e00\u5c42\u5168\u8fde\u63a5\u5c42\u6765\u89e3\u51b3\u65b0\u7684\u56fe\u7247\u5206\u7c7b\u95ee\u9898\u3002\n    # \u56e0\u4e3a\u8bad\u7ec3\u597d\u7684Inception-v3\u6a21\u578b\u5df2\u7ecf\u5c06\u539f\u59cb\u7684\u56fe\u7247\u62bd\u8c61\u4e3a\u4e86\u66f4\u52a0\u5bb9\u6613\u5206\u7c7b\u7684\u7279\u5f81\u5411\u91cf\u4e86\uff0c\u6240\u4ee5\u4e0d\u9700\u8981\u518d\u8bad\u7ec3\u90a3\u4e48\u590d\u6742\u7684\u795e\u7ecf\u7f51\u7edc\u6765\u5b8c\u6210\u8fd9\u4e2a\u65b0\u7684\u5206\u7c7b\u4efb\u52a1\u3002\n    with tf.name_scope('final_training_ops'):\n        weights = tf.Variable(tf.truncated_normal([BOTTLENECK_TENSOR_SIZE, n_classes], stddev=0.001))\n        biases = tf.Variable(tf.zeros([n_classes]))\n        logits = tf.matmul(bottleneck_input, weights) + biases\n        final_tensor = tf.nn.softmax(logits)\n    # \u5b9a\u4e49\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=ground_truth_input)\n    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n    train_step = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy_mean)\n    # \u8ba1\u7b97\u6b63\u786e\u7387\n    with tf.name_scope('evaluation'):\n        correct_prediction = tf.equal(tf.argmax(final_tensor, 1), tf.argmax(ground_truth_input, 1))\n        evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n    with tf.Session() as sess:\n        tf.global_variables_initializer().run()\n        # \u8bad\u7ec3\u8fc7\u7a0b\n        for i in range(STEPS):\n            # \u6bcf\u6b21\u83b7\u53d6\u4e00\u4e2abatch\u7684\u8bad\u7ec3\u6570\u636e\n            train_bottlenecks, train_ground_truth = get_random_cached_bottlenecks(\n                sess, n_classes, image_lists, BATCH, 'training', jpeg_data_tensor, bottleneck_tensor)\n            sess.run(train_step, feed_dict={bottleneck_input: train_bottlenecks, ground_truth_input: train_ground_truth})\n            # \u5728\u9a8c\u8bc1\u96c6\u4e0a\u6d4b\u8bd5\u6b63\u786e\u7387\u3002\n            if i%100 == 0 or i+1 == STEPS:\n                validation_bottlenecks, validation_ground_truth = get_random_cached_bottlenecks(\n                    sess, n_classes, image_lists, BATCH, 'validation', jpeg_data_tensor, bottleneck_tensor)\n                validation_accuracy = sess.run(evaluation_step, feed_dict={\n                    bottleneck_input:validation_bottlenecks, ground_truth_input: validation_ground_truth})\n                print('Step %d: Validation accuracy on random sampled %d examples = %.1f%%'\n                      % (i, BATCH, validation_accuracy*100))\n        # \u5728\u6700\u540e\u7684\u6d4b\u8bd5\u6570\u636e\u4e0a\u6d4b\u8bd5\u6b63\u786e\u7387\n        test_bottlenecks, test_ground_truth = get_test_bottlenecks(sess, image_lists, n_classes,\n                                                                       jpeg_data_tensor, bottleneck_tensor)\n        test_accuracy = sess.run(evaluation_step, feed_dict={bottleneck_input: test_bottlenecks,\n                                                                 ground_truth_input: test_ground_truth})\n        print('Final test accuracy = %.1f%%' % (test_accuracy * 100))",
            "title": "TF\u5b9e\u73b0CNN\u4e3e\u4f8b"
        },
        {
            "location": "/chapter7/",
            "text": "TF\u5b9e\u73b0RNN\u4e3e\u4f8b\n\n\n\u5173\u4e8eRNN\u6211\u4eec\u5728\u524d\u671f\u7684\u57f9\u8bad\u4e2d\u5df2\u7ecf\u4ecb\u7ecd\uff0c\u5305\u62ec\u57fa\u672c\u7684RNN\u7ed3\u6784\uff0cLSTM,GRU\uff0c\u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff0c\u6df1\u5c42\u795e\u7ecf\u7f51\u7edc\u7b49\uff0c\n\u8981\u5b66\u4e60RNN\u8bf7\u79fb\u6b65\u5230\u8fd9\n,\u56e0\u4e3a\u7b80\u5355\u7684RNN\u7ed3\u6784\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5e76\u4e0d\u5e38\u7528\uff0c\u6240\u4ee5\u672c\u8282\u4e3b\u8981\u4ecb\u7ecd\uff1aLSTM\uff0c\u6df1\u5c42\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff0cGRU,\u53ca\u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u57fa\u672c\u7528\u6cd5,\u5176\u4e2d\u540e\u4e24\u8005\u4ec5\u63d0\u4f9b\u51fd\u6570API\uff0c\u7528\u6cd5\u4e0e\u524d\u4e24\u8005\u76f8\u540c\u3002\n\n\n1.LSTM\n\n\n\u5b9a\u4e49\u4e00\u4e2aLSTM\u7ed3\u6784\uff0c\u5728TF\u4e2d\u901a\u8fc7\u4e00\u53e5\u7b80\u5355\u7684\u547d\u4ee4\u5c31\u53ef\u4ee5\u5b9e\u73b0\u4e00\u4e2a\u5b8c\u6574\u7684LSTM\u7ed3\u6784\u3002LSTM\u4e2d\u4f7f\u7528\u7684\u53d8\u91cf\u4e5f\u4f1a\u5728\u8be5\u51fd\u6570\u4e2d\u81ea\u52a8\u58f0\u660e\n\n\n\n\n\u56fe1\uff1aLSTM\u793a\u610f\u56fe\n\n\n\nlstm_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units, forget_bias=1.0, input_size=None, state_is_tupe=Flase, activation=tanh)\n#num_units:\u56fe\u4e00\u4e2dht\u7684\u7ef4\u6570\uff0c\u5982\u679cnum_units=10,\u90a3\u4e48ht\u5c31\u662f10\u7ef4\u884c\u5411\u91cf\n#forget_bias\uff1a\u9057\u5fd8\u95e8\u7684\u504f\u6267\u9879\n#input_size:[batch_size, max_time, size]\u3002\u5047\u8bbe\u8981\u8f93\u5165\u4e00\u53e5\u8bdd\uff0c\u8fd9\u53e5\u8bdd\u7684\u957f\u5ea6\u662f\u4e0d\u56fa\u5b9a\u7684\uff0cmax_time\u5c31\u4ee3\u8868\u6700\u957f\u7684\u90a3\u53e5\u8bdd\u662f\u591a\u957f\uff0csize\u8868\u793a\u4f60\u6253\u7b97\u7528\u591a\u957f\u7684\u5411\u91cf\u4ee3\u8868\u4e00\u4e2aword\uff0c\u5373embedding_size\uff08embedding_size\u548csize\u7684\u503c\u4e0d\u4e00\u5b9a\u8981\u4e00\u6837\uff09\n#state_is_tuple:true\u7684\u8bdd\uff0c\u8fd4\u56de\u7684\u72b6\u6001\u662f\u4e00\u4e2atuple:(c=array([[]]), h=array([[]]):\u5176\u4e2dc\u4ee3\u8868Ct\u7684\u6700\u540e\u65f6\u95f4\u7684\u8f93\u51fa\uff0ch\u4ee3\u8868Ht\u6700\u540e\u65f6\u95f4\u7684\u8f93\u51fa\uff0ch\u662f\u7b49\u4e8e\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u7684output\u7684\n#\u56fe\u4e09\u5411\u4e0a\u6307\u7684ht\u79f0\u4e3aoutput\n#\u6b64\u51fd\u6570\u8fd4\u56de\u4e00\u4e2alstm_cell\uff0c\u5373\u56fe\u4e00\u4e2d\u7684\u4e00\u4e2aA,\u8bf4\u767d\u4e86\u5c31\u662f\u4e00\u4e2aLSTM\u7ed3\u6784\n\n\u521d\u59cb\u5316LSTM\u7684\u521d\u59cb\u72b6\u6001\uff08ct,\u8bb0\u5fc6\u5355\u5143\uff0c\u72b6\u6001\u5355\u5143\uff09\nstate = lstm_cell.zero_state(batch_size,tf.float32)\n\n#\u5b9a\u4e49\u635f\u5931\nloss = 0.0\n#\u7406\u8bba\u4e0aRNN\u53ef\u4ee5\u5904\u7406\u4efb\u610f\u957f\u5ea6\u7684\u5e8f\u5217\uff0c\u4f46\u5728\u8bad\u7ec3\u65f6\u4e3a\u4e86\u907f\u514d\u68af\u5ea6\u7206\u70b8\u6216\u5f25\u6563\uff0c\u56de\u8d35\u5b9a\u4e00\u4e2a\u6700\u5927\u7684\u5e8f\u5217\u957f\u5ea6\uff0c\u5c31\u662f\u8fd9\u91cc\u7684num_steps\n\nfor i in range(num_steps):\n    #\u6ce8\u610flstm\u7684\u6743\u503c\u5171\u4eab\uff0c\u5b57\u4e4b\u540e\u7684\u65f6\u523b\u90fd\u5c06\u590d\u7528\u4e4b\u524d\u5b9a\u4e49\u597d\u7684\u53d8\u91cf\n    if i > 1:\n        tf.get_variables_scope().resuse_variable()\n    #\u6bcf\u4e00\u6b65\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u4e00\u4e2a\u65f6\u523b\u3002\u5c06\u5f53\u524d\u65f6\u523b\u7684\u8f93\u5165\u548c\u4e0a\u4e00\u65f6\u523b\u7684\u72b6\u6001\uff08state)\u4f20\u5165\u5b9a\u4e49\u597d\u7684lstm_cell\u5f97\u5230\u5f53\u524dLSTM\u7ed3\u6784\u7684\u8f93\u51fa\u66f4\u65b0\u540e\u7684\u72b6\u6001\uff08newstate)\n    lstm_output,state = lstm_cell(current_input,state)\n    #loss\u662f\u6240\u6709\u8f93\u51faloss\u7684\u548c\n    loss += calc_loss(finial_output,expected_outut)\n\n    #\u6ce8\u610f\uff1afinial_output\u662flstm_output\u7ecf\u8fc7\u5168\u8fde\u63a5\u5f97\u5230\u6216\u7ebf\u6027\u53d8\u6362\u5f97\u5230\n    #\u6fc0\u6d3b\u51fd\u6570\u5f0f\u5728\u8ba1\u7b97\u5f53\u524d\u8bb0\u5fc6\u5355\u5143\u548cht\u65f6\u8981\u7528\u5230\u7684\u6fc0\u6d3b\u51fd\u6570\u3002\n\n\u8bad\u7ec3\u65b9\u6cd5\u540cDNN,CNN\n\n\n\n\n\n\n\n2.\u6df1\u5c42LSTM\n\n\n\u6df1\u5c42LSTM\u5728RNN\u7684\u57f9\u8bad\u4e2d\u5fc3\u6211\u4eec\u53ea\u662f\u63d0\u4e86\u6982\u5ff5\u5e76\u6ca1\u6709\u7ec6\u8bb2\u3002deepRNN\u662f\u4e3a\u4e86\u589e\u5f3a\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u53ef\u4ee5\u5c06\u6bcf\u4e00\u4e2a\u65f6\u523b\u4e0a\u7684\u5faa\u73af\u4f53\u91cd\u590d\u591a\u6b21\u3002\n\n\n\n\n\u56fe2\uff1a\u6df1\u5ea6LSTM\u7ed3\u6784\n\n\n#\u5b9a\u4e49\u4e00\u4e2a\u57fa\u672c\u7684LSTM\u7ed3\u6784\u4f5c\u4e3a\u5faa\u73af\u4f53\u7684\u57fa\u7840\u7ed3\u6784\u3002\u6df1\u5c42\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u4e5f\u652f\u6301\u4f7f\u7528\u5176\u4ed6\u5faa\u73af\u7ed3\u6784\nlstm = tf.nn.rnn_cell.BasicLSTMCell(num_units, forget_bias=1.0, input_size=None, state_is_tupe=Flase, activation=tanh)\n#\u901a\u8fc7MultiRNNCell\u7c7b\u5b9e\u73b0\u6df1\u5c42\u5faa\u73af\u7f51\u7edc\u7684\u6bcf\u4e00\u4e2a\u65f6\u523b\u7684\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\u3002\u5176\u4e2dnumber_of_layers\u8868\u793a\u6709\u591a\u5c11\u5c42\uff0c\u4e5f\u5c31\u662f\u56fe\u4e00\u4e2d\u7684xt\u5230ht\u9700\u8981\u7ecf\u8fc7\u591a\u5c11\u4e2aLSTM\u7ed3\u6784\u3002\n\nstacked_lstm = tf.nn.rnn_cell.MultiRNNCell([lstm]*number_of_layers)\n\nstate = stacked_lstm.zero_state(batch_size,tf.float32)\n\nfor i in range(len(num_steps)):\n    if i > 0:\n        tf.get_variable_scope().reuse_variables()\n    stacked_lstm_output,state = stacked_lstm(current_input,state)\n    final_output = fully_connected(stacked_lstm_output)\n    loss += calc_loss(final_output,expected_output)\n\n\n\n\n\u4ece\u4ee3\u7801\u4e0a\u6765\u770b\uff0cTensorFlow\u53ea\u9700\u8981\u5728BasicLSTMCell\u7684\u57fa\u7840\u4e0a\u5728\u5c01\u88c5\u4e00\u5c42MultiRNNCell\u5c31\u5f88\u5bb9\u6613\u5b9e\u73b0deepRNN\u3002\n\n\n\u8fd9\u91cc\u9700\u8981\u6307\u51fa\u7684\u662fRNN\u7684dropout,\u5728CNN\u4e2d\u5df2\u7ecf\u6307\u51fa\u4e86CNN\u7684dropout,dropout\u7684\u529f\u80fd\u6ca1\u6709\u53d1\u751f\u53d8\u5316\uff0c\u4f46\u662f\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u53ea\u5728\u4e0d\u540c\u5faa\u73af\u4f53\u7ed3\u6784\u4e4b\u95f4\u4f7f\u7528dropout,\u800c\u4e0d\u5728\u540c\u4e00\u5c42\u7684\u5faa\u73af\u4f53\u7ed3\u6784\u4e4b\u95f4\u4f7f\u7528\uff0c\u4e5f\u5c31\u662f\u8bf4\u5728t-1\u65f6\u523b\u4f20\u9012\u5230t\u65f6\u523b\uff0c\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u4e0d\u4f1a\u8fdb\u884c\u72b6\u6001\u7684dropout\uff0c\u76f4\u89c2\u7684\u7406\u89e3\u53ef\u4ee5\u770b\u5230\u56fe2\uff0c\u56fe2\u4e2d\u5b9e\u7ebf\u7684\u7bad\u5934\u662f\u4e0d\u80fd\u8fdb\u884cdropout\u7684\uff0c\u865a\u7ebf\u7bad\u5934\u662f\u53ef\u4ee5\u8fdb\u884cdropout\u7684\u3002\n\n\nlstm = tf.nn.rnn_cell.BasicLSTMCell(......)\n\n#\u4f7f\u7528DropoutWrapper\u6765\u5b9e\u73b0dropout\u529f\u80fd\uff0c\u4e24\u4e2a\u53c2\u6570\uff0c\u4e00\u4e2a\u662finput_keep_prob\uff0c\u63a7\u5236dropout\u7684\u6982\u7387\uff0c\u4e00\u4e2a\u662foutput_keep_prob\u53ef\u4ee5\u63a7\u5236\u8f93\u51fa\u7684dropout\u6982\u7387\n\ndropout_lstm = tf.nn.rnn_cell.DropoutWrapper(lstm,output_keep_prob=0.5)\n\n#\u5728\u4f7f\u7528dropout\u7684\u57fa\u7840\u4e0a\u5b9a\u4e49\n\nstacked_lstm = tf.nn.rnn_cell.MultiRNNCell([dropout_lstm]*number_of_layers)\n\n\n\n\n\u5728\u6b64\u63d0\u793a\uff0c\u8fd9\u4e9b\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u8bc4\u4ef7\u548c\u524d\u9762\u6559\u5bfc\u7684\u6a21\u578b\u65f6\u76f8\u540c\u7684\uff0c\u4e0d\u518d\u8d58\u8ff0\n\n\n3.GRU\u53ca\u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\n\n\ntenforflow\u63d0\u4f9b\u4e86tf.nn.rnn_cell.GRUCell()\u6784\u5efa\u4e00\u4e2aGRU\u5355\u5143\n\n\n\n\u56fe3\uff1aGRU\u793a\u610f\u56fe\n\n\ngru_cell = tf.nn.rnn_cell.GRUCell(num_units, input_size=None, activation=tanh)\n#\u53c2\u6570\u53c2\u8003lstm cell \u4f7f\u7528\n\n\n\n\n\u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u6211\u4eec\u5728RNN\u57f9\u8bad\u4e2d\u5fc3\u4e5f\u5df2\u7ecf\u8bb2\u5230\n\n\n\n\n\u56fe4\uff1a\u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u793a\u610f\u56fe\n\n\nAPI\uff1a\nbidirectional_dynamic_rnn(\n    cell_fw, #\u524d\u5411 rnn cell\n    cell_bw, #\u53cd\u5411 rnn cell\n    inputs, #\u8f93\u5165\u5e8f\u5217.\n    sequence_length=None,# \u5e8f\u5217\u957f\u5ea6\n    initial_state_fw=None,#\u524d\u5411rnn_cell\u7684\u521d\u59cb\u72b6\u6001\n    initial_state_bw=None,#\u53cd\u5411rnn_cell\u7684\u521d\u59cb\u72b6\u6001\n    dtype=None,#\u6570\u636e\u7c7b\u578b\n    parallel_iterations=None,\n    swap_memory=False,\n    time_major=False,\n    scope=None\n)\n\n#------------------------------------\n\ndef BiRNN(x,weights,biases):\n    x = tf.transpose(x,[1,0,2])\n    x = tf.reshape(x,[-1,n_input])\n    x = tf.split(0,n_steps,x)\n    lstm_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden,state_is_tuple=True)\n    lstm_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden,state_is_tuple=True)\n    outputs,_,_ = tf.nn.bidirectional_rnn(lstm_fw_cell,lstm_bw_cell,x,dtype=tf.float32)\n    return tf.matmul(outputs[-1],weights['out'])+biases['out']\n\n#\u6ce8\u610f\uff1a\u201c_\u201d\u4f5c\u4e3a\u4e34\u65f6\u6027\u7684\u540d\u79f0\u4f7f\u7528\u3002\n#\u8fd9\u6837\uff0c\u5f53\u5176\u4ed6\u4eba\u9605\u8bfb\u4f60\u7684\u4ee3\u7801\u65f6\u5c06\u4f1a\u77e5\u9053\uff0c\u4f60\u5206\u914d\u4e86\u4e00\u4e2a\u7279\u5b9a\u7684\u540d\u79f0\uff0c\u4f46\u662f\u5e76\u4e0d\u4f1a\u5728\u540e\u9762\u518d\u6b21\u7528\u5230\u8be5\u540d\u79f0\u3002\n#\u4f8b\u5982\uff0c\u4e0a\u9762\u4f8b\u5b50\u4e2d\uff0c\u4f60\u53ef\u80fd\u5bf9outputs\u540e\u9762\u7684\u53d8\u91cf\u503c\u4e0d\u611f\u5174\u8da3\uff0c\u6b64\u65f6\u5c31\u53ef\u4ee5\u4f7f\u7528\u201c_\u201d\u3002\n\n\n\n\n\n\u5176\u4ed6\uff1a\n\n\n#\u7b80\u5355RNN\u7684API\ntf.nn.rnn_cell.BasicRNNCell()\n\n#\u4e0d\u53d8\u957f\u8f93\u5165\ntf.nn.static_rnn()\n\n#\u53d8\u957f\u8f93\u5165\noutputs, state = tf.nn.dynamic_rnn(cell, inputs, sequence_length=None)\n\u6ce8\uff1adynamic_rnn \u4e0e static_rnn \u7684\u4e3b\u8981\u533a\u522b\u662f\uff1a\u524d\u8005\u53ef\u4ee5\u63a5\u6536\u5177\u6709\u4e0d\u540c\u957f\u5ea6\u7684 mini-batch \u5e8f\u5217\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\u5728\u540c\u4e00 mini-batch \u5185\u7684\u5e8f\u5217\u8fd8\u662f\u8981 pad \u6210\u540c\u4e00\u957f\u5ea6\n\n#\ntf.contrib.rnn.XXX()\n\n\n\n\n\n\u66f4\u591a\u5185\u5bb9\u53c2\u8003\uff1a\n\n\nhttps://mp.weixin.qq.com/s/PNkaX93uqPp1K5zVj4i03g\n\n\nhttps://mp.weixin.qq.com/s/8hw6pAzUhoXrX4mD9HqIZQ\n\n\nhttps://mp.weixin.qq.com/s/Mv-e8Pslm7v9VqfjSnkBwQ\n\n\nhttps://mp.weixin.qq.com/s/W0MO4k3IDect9aOSzu7-Zg",
            "title": "TensorFlow\u5b9e\u73b0RNN\u4e3e\u4f8b"
        },
        {
            "location": "/chapter7/#tfrnn",
            "text": "\u5173\u4e8eRNN\u6211\u4eec\u5728\u524d\u671f\u7684\u57f9\u8bad\u4e2d\u5df2\u7ecf\u4ecb\u7ecd\uff0c\u5305\u62ec\u57fa\u672c\u7684RNN\u7ed3\u6784\uff0cLSTM,GRU\uff0c\u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff0c\u6df1\u5c42\u795e\u7ecf\u7f51\u7edc\u7b49\uff0c \u8981\u5b66\u4e60RNN\u8bf7\u79fb\u6b65\u5230\u8fd9 ,\u56e0\u4e3a\u7b80\u5355\u7684RNN\u7ed3\u6784\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5e76\u4e0d\u5e38\u7528\uff0c\u6240\u4ee5\u672c\u8282\u4e3b\u8981\u4ecb\u7ecd\uff1aLSTM\uff0c\u6df1\u5c42\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff0cGRU,\u53ca\u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u57fa\u672c\u7528\u6cd5,\u5176\u4e2d\u540e\u4e24\u8005\u4ec5\u63d0\u4f9b\u51fd\u6570API\uff0c\u7528\u6cd5\u4e0e\u524d\u4e24\u8005\u76f8\u540c\u3002  1.LSTM  \u5b9a\u4e49\u4e00\u4e2aLSTM\u7ed3\u6784\uff0c\u5728TF\u4e2d\u901a\u8fc7\u4e00\u53e5\u7b80\u5355\u7684\u547d\u4ee4\u5c31\u53ef\u4ee5\u5b9e\u73b0\u4e00\u4e2a\u5b8c\u6574\u7684LSTM\u7ed3\u6784\u3002LSTM\u4e2d\u4f7f\u7528\u7684\u53d8\u91cf\u4e5f\u4f1a\u5728\u8be5\u51fd\u6570\u4e2d\u81ea\u52a8\u58f0\u660e   \u56fe1\uff1aLSTM\u793a\u610f\u56fe  \nlstm_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units, forget_bias=1.0, input_size=None, state_is_tupe=Flase, activation=tanh)\n#num_units:\u56fe\u4e00\u4e2dht\u7684\u7ef4\u6570\uff0c\u5982\u679cnum_units=10,\u90a3\u4e48ht\u5c31\u662f10\u7ef4\u884c\u5411\u91cf\n#forget_bias\uff1a\u9057\u5fd8\u95e8\u7684\u504f\u6267\u9879\n#input_size:[batch_size, max_time, size]\u3002\u5047\u8bbe\u8981\u8f93\u5165\u4e00\u53e5\u8bdd\uff0c\u8fd9\u53e5\u8bdd\u7684\u957f\u5ea6\u662f\u4e0d\u56fa\u5b9a\u7684\uff0cmax_time\u5c31\u4ee3\u8868\u6700\u957f\u7684\u90a3\u53e5\u8bdd\u662f\u591a\u957f\uff0csize\u8868\u793a\u4f60\u6253\u7b97\u7528\u591a\u957f\u7684\u5411\u91cf\u4ee3\u8868\u4e00\u4e2aword\uff0c\u5373embedding_size\uff08embedding_size\u548csize\u7684\u503c\u4e0d\u4e00\u5b9a\u8981\u4e00\u6837\uff09\n#state_is_tuple:true\u7684\u8bdd\uff0c\u8fd4\u56de\u7684\u72b6\u6001\u662f\u4e00\u4e2atuple:(c=array([[]]), h=array([[]]):\u5176\u4e2dc\u4ee3\u8868Ct\u7684\u6700\u540e\u65f6\u95f4\u7684\u8f93\u51fa\uff0ch\u4ee3\u8868Ht\u6700\u540e\u65f6\u95f4\u7684\u8f93\u51fa\uff0ch\u662f\u7b49\u4e8e\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u7684output\u7684\n#\u56fe\u4e09\u5411\u4e0a\u6307\u7684ht\u79f0\u4e3aoutput\n#\u6b64\u51fd\u6570\u8fd4\u56de\u4e00\u4e2alstm_cell\uff0c\u5373\u56fe\u4e00\u4e2d\u7684\u4e00\u4e2aA,\u8bf4\u767d\u4e86\u5c31\u662f\u4e00\u4e2aLSTM\u7ed3\u6784\n\n\u521d\u59cb\u5316LSTM\u7684\u521d\u59cb\u72b6\u6001\uff08ct,\u8bb0\u5fc6\u5355\u5143\uff0c\u72b6\u6001\u5355\u5143\uff09\nstate = lstm_cell.zero_state(batch_size,tf.float32)\n\n#\u5b9a\u4e49\u635f\u5931\nloss = 0.0\n#\u7406\u8bba\u4e0aRNN\u53ef\u4ee5\u5904\u7406\u4efb\u610f\u957f\u5ea6\u7684\u5e8f\u5217\uff0c\u4f46\u5728\u8bad\u7ec3\u65f6\u4e3a\u4e86\u907f\u514d\u68af\u5ea6\u7206\u70b8\u6216\u5f25\u6563\uff0c\u56de\u8d35\u5b9a\u4e00\u4e2a\u6700\u5927\u7684\u5e8f\u5217\u957f\u5ea6\uff0c\u5c31\u662f\u8fd9\u91cc\u7684num_steps\n\nfor i in range(num_steps):\n    #\u6ce8\u610flstm\u7684\u6743\u503c\u5171\u4eab\uff0c\u5b57\u4e4b\u540e\u7684\u65f6\u523b\u90fd\u5c06\u590d\u7528\u4e4b\u524d\u5b9a\u4e49\u597d\u7684\u53d8\u91cf\n    if i > 1:\n        tf.get_variables_scope().resuse_variable()\n    #\u6bcf\u4e00\u6b65\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u4e00\u4e2a\u65f6\u523b\u3002\u5c06\u5f53\u524d\u65f6\u523b\u7684\u8f93\u5165\u548c\u4e0a\u4e00\u65f6\u523b\u7684\u72b6\u6001\uff08state)\u4f20\u5165\u5b9a\u4e49\u597d\u7684lstm_cell\u5f97\u5230\u5f53\u524dLSTM\u7ed3\u6784\u7684\u8f93\u51fa\u66f4\u65b0\u540e\u7684\u72b6\u6001\uff08newstate)\n    lstm_output,state = lstm_cell(current_input,state)\n    #loss\u662f\u6240\u6709\u8f93\u51faloss\u7684\u548c\n    loss += calc_loss(finial_output,expected_outut)\n\n    #\u6ce8\u610f\uff1afinial_output\u662flstm_output\u7ecf\u8fc7\u5168\u8fde\u63a5\u5f97\u5230\u6216\u7ebf\u6027\u53d8\u6362\u5f97\u5230\n    #\u6fc0\u6d3b\u51fd\u6570\u5f0f\u5728\u8ba1\u7b97\u5f53\u524d\u8bb0\u5fc6\u5355\u5143\u548cht\u65f6\u8981\u7528\u5230\u7684\u6fc0\u6d3b\u51fd\u6570\u3002\n\n\u8bad\u7ec3\u65b9\u6cd5\u540cDNN,CNN   2.\u6df1\u5c42LSTM  \u6df1\u5c42LSTM\u5728RNN\u7684\u57f9\u8bad\u4e2d\u5fc3\u6211\u4eec\u53ea\u662f\u63d0\u4e86\u6982\u5ff5\u5e76\u6ca1\u6709\u7ec6\u8bb2\u3002deepRNN\u662f\u4e3a\u4e86\u589e\u5f3a\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u53ef\u4ee5\u5c06\u6bcf\u4e00\u4e2a\u65f6\u523b\u4e0a\u7684\u5faa\u73af\u4f53\u91cd\u590d\u591a\u6b21\u3002   \u56fe2\uff1a\u6df1\u5ea6LSTM\u7ed3\u6784  #\u5b9a\u4e49\u4e00\u4e2a\u57fa\u672c\u7684LSTM\u7ed3\u6784\u4f5c\u4e3a\u5faa\u73af\u4f53\u7684\u57fa\u7840\u7ed3\u6784\u3002\u6df1\u5c42\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u4e5f\u652f\u6301\u4f7f\u7528\u5176\u4ed6\u5faa\u73af\u7ed3\u6784\nlstm = tf.nn.rnn_cell.BasicLSTMCell(num_units, forget_bias=1.0, input_size=None, state_is_tupe=Flase, activation=tanh)\n#\u901a\u8fc7MultiRNNCell\u7c7b\u5b9e\u73b0\u6df1\u5c42\u5faa\u73af\u7f51\u7edc\u7684\u6bcf\u4e00\u4e2a\u65f6\u523b\u7684\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\u3002\u5176\u4e2dnumber_of_layers\u8868\u793a\u6709\u591a\u5c11\u5c42\uff0c\u4e5f\u5c31\u662f\u56fe\u4e00\u4e2d\u7684xt\u5230ht\u9700\u8981\u7ecf\u8fc7\u591a\u5c11\u4e2aLSTM\u7ed3\u6784\u3002\n\nstacked_lstm = tf.nn.rnn_cell.MultiRNNCell([lstm]*number_of_layers)\n\nstate = stacked_lstm.zero_state(batch_size,tf.float32)\n\nfor i in range(len(num_steps)):\n    if i > 0:\n        tf.get_variable_scope().reuse_variables()\n    stacked_lstm_output,state = stacked_lstm(current_input,state)\n    final_output = fully_connected(stacked_lstm_output)\n    loss += calc_loss(final_output,expected_output)  \u4ece\u4ee3\u7801\u4e0a\u6765\u770b\uff0cTensorFlow\u53ea\u9700\u8981\u5728BasicLSTMCell\u7684\u57fa\u7840\u4e0a\u5728\u5c01\u88c5\u4e00\u5c42MultiRNNCell\u5c31\u5f88\u5bb9\u6613\u5b9e\u73b0deepRNN\u3002  \u8fd9\u91cc\u9700\u8981\u6307\u51fa\u7684\u662fRNN\u7684dropout,\u5728CNN\u4e2d\u5df2\u7ecf\u6307\u51fa\u4e86CNN\u7684dropout,dropout\u7684\u529f\u80fd\u6ca1\u6709\u53d1\u751f\u53d8\u5316\uff0c\u4f46\u662f\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u53ea\u5728\u4e0d\u540c\u5faa\u73af\u4f53\u7ed3\u6784\u4e4b\u95f4\u4f7f\u7528dropout,\u800c\u4e0d\u5728\u540c\u4e00\u5c42\u7684\u5faa\u73af\u4f53\u7ed3\u6784\u4e4b\u95f4\u4f7f\u7528\uff0c\u4e5f\u5c31\u662f\u8bf4\u5728t-1\u65f6\u523b\u4f20\u9012\u5230t\u65f6\u523b\uff0c\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u4e0d\u4f1a\u8fdb\u884c\u72b6\u6001\u7684dropout\uff0c\u76f4\u89c2\u7684\u7406\u89e3\u53ef\u4ee5\u770b\u5230\u56fe2\uff0c\u56fe2\u4e2d\u5b9e\u7ebf\u7684\u7bad\u5934\u662f\u4e0d\u80fd\u8fdb\u884cdropout\u7684\uff0c\u865a\u7ebf\u7bad\u5934\u662f\u53ef\u4ee5\u8fdb\u884cdropout\u7684\u3002  lstm = tf.nn.rnn_cell.BasicLSTMCell(......)\n\n#\u4f7f\u7528DropoutWrapper\u6765\u5b9e\u73b0dropout\u529f\u80fd\uff0c\u4e24\u4e2a\u53c2\u6570\uff0c\u4e00\u4e2a\u662finput_keep_prob\uff0c\u63a7\u5236dropout\u7684\u6982\u7387\uff0c\u4e00\u4e2a\u662foutput_keep_prob\u53ef\u4ee5\u63a7\u5236\u8f93\u51fa\u7684dropout\u6982\u7387\n\ndropout_lstm = tf.nn.rnn_cell.DropoutWrapper(lstm,output_keep_prob=0.5)\n\n#\u5728\u4f7f\u7528dropout\u7684\u57fa\u7840\u4e0a\u5b9a\u4e49\n\nstacked_lstm = tf.nn.rnn_cell.MultiRNNCell([dropout_lstm]*number_of_layers)  \u5728\u6b64\u63d0\u793a\uff0c\u8fd9\u4e9b\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u8bc4\u4ef7\u548c\u524d\u9762\u6559\u5bfc\u7684\u6a21\u578b\u65f6\u76f8\u540c\u7684\uff0c\u4e0d\u518d\u8d58\u8ff0  3.GRU\u53ca\u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc  tenforflow\u63d0\u4f9b\u4e86tf.nn.rnn_cell.GRUCell()\u6784\u5efa\u4e00\u4e2aGRU\u5355\u5143  \u56fe3\uff1aGRU\u793a\u610f\u56fe  gru_cell = tf.nn.rnn_cell.GRUCell(num_units, input_size=None, activation=tanh)\n#\u53c2\u6570\u53c2\u8003lstm cell \u4f7f\u7528  \u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u6211\u4eec\u5728RNN\u57f9\u8bad\u4e2d\u5fc3\u4e5f\u5df2\u7ecf\u8bb2\u5230   \u56fe4\uff1a\u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u793a\u610f\u56fe  API\uff1a\nbidirectional_dynamic_rnn(\n    cell_fw, #\u524d\u5411 rnn cell\n    cell_bw, #\u53cd\u5411 rnn cell\n    inputs, #\u8f93\u5165\u5e8f\u5217.\n    sequence_length=None,# \u5e8f\u5217\u957f\u5ea6\n    initial_state_fw=None,#\u524d\u5411rnn_cell\u7684\u521d\u59cb\u72b6\u6001\n    initial_state_bw=None,#\u53cd\u5411rnn_cell\u7684\u521d\u59cb\u72b6\u6001\n    dtype=None,#\u6570\u636e\u7c7b\u578b\n    parallel_iterations=None,\n    swap_memory=False,\n    time_major=False,\n    scope=None\n)\n\n#------------------------------------\n\ndef BiRNN(x,weights,biases):\n    x = tf.transpose(x,[1,0,2])\n    x = tf.reshape(x,[-1,n_input])\n    x = tf.split(0,n_steps,x)\n    lstm_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden,state_is_tuple=True)\n    lstm_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden,state_is_tuple=True)\n    outputs,_,_ = tf.nn.bidirectional_rnn(lstm_fw_cell,lstm_bw_cell,x,dtype=tf.float32)\n    return tf.matmul(outputs[-1],weights['out'])+biases['out']\n\n#\u6ce8\u610f\uff1a\u201c_\u201d\u4f5c\u4e3a\u4e34\u65f6\u6027\u7684\u540d\u79f0\u4f7f\u7528\u3002\n#\u8fd9\u6837\uff0c\u5f53\u5176\u4ed6\u4eba\u9605\u8bfb\u4f60\u7684\u4ee3\u7801\u65f6\u5c06\u4f1a\u77e5\u9053\uff0c\u4f60\u5206\u914d\u4e86\u4e00\u4e2a\u7279\u5b9a\u7684\u540d\u79f0\uff0c\u4f46\u662f\u5e76\u4e0d\u4f1a\u5728\u540e\u9762\u518d\u6b21\u7528\u5230\u8be5\u540d\u79f0\u3002\n#\u4f8b\u5982\uff0c\u4e0a\u9762\u4f8b\u5b50\u4e2d\uff0c\u4f60\u53ef\u80fd\u5bf9outputs\u540e\u9762\u7684\u53d8\u91cf\u503c\u4e0d\u611f\u5174\u8da3\uff0c\u6b64\u65f6\u5c31\u53ef\u4ee5\u4f7f\u7528\u201c_\u201d\u3002  \u5176\u4ed6\uff1a  #\u7b80\u5355RNN\u7684API\ntf.nn.rnn_cell.BasicRNNCell()\n\n#\u4e0d\u53d8\u957f\u8f93\u5165\ntf.nn.static_rnn()\n\n#\u53d8\u957f\u8f93\u5165\noutputs, state = tf.nn.dynamic_rnn(cell, inputs, sequence_length=None)\n\u6ce8\uff1adynamic_rnn \u4e0e static_rnn \u7684\u4e3b\u8981\u533a\u522b\u662f\uff1a\u524d\u8005\u53ef\u4ee5\u63a5\u6536\u5177\u6709\u4e0d\u540c\u957f\u5ea6\u7684 mini-batch \u5e8f\u5217\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\u5728\u540c\u4e00 mini-batch \u5185\u7684\u5e8f\u5217\u8fd8\u662f\u8981 pad \u6210\u540c\u4e00\u957f\u5ea6\n\n#\ntf.contrib.rnn.XXX()  \u66f4\u591a\u5185\u5bb9\u53c2\u8003\uff1a  https://mp.weixin.qq.com/s/PNkaX93uqPp1K5zVj4i03g  https://mp.weixin.qq.com/s/8hw6pAzUhoXrX4mD9HqIZQ  https://mp.weixin.qq.com/s/Mv-e8Pslm7v9VqfjSnkBwQ  https://mp.weixin.qq.com/s/W0MO4k3IDect9aOSzu7-Zg",
            "title": "TF\u5b9e\u73b0RNN\u4e3e\u4f8b"
        },
        {
            "location": "/chapter9/",
            "text": "TensorBoard\u53ef\u89c6\u5316\n\n\n\u4e3a\u4e86\u66f4\u597d\u7684\u8bad\u7ec3\u548c\u4f18\u5316\u6a21\u578b\uff0cTensorFlow\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u89c6\u5316\u5de5\u5177TensorBoard\u3002TensorFlow\u53ef\u4ee5\u6709\u6548\u7684\u5c55\u793aTensorFlow\u5728\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u7684\u8ba1\u7b97\u56fe\uff0c\u5404\u79cd\u6307\u6807\u968f\u7740\u65f6\u95f4\u7684\u53d8\u5316\u8d8b\u52bf\u4ee5\u53ca\u8bad\u7ec3\u4e2d\u4f7f\u7528\u5230\u7684\u56fe\u50cf\u4fe1\u606f\u7b49\u3002\n\n\n1.TensorBoard\u7b80\u4ecb\n\n\nTensorBoard\u662fTensorFlow\u7684\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u5b83\u53ef\u4ee5\u901a\u8fc7TensorFlow\u7a0b\u5e8f\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u8f93\u51fa\u7684\u65e5\u5fd7\u6587\u4ef6\u53ef\u89c6\u5316TensorFlow\u7a0b\u5e8f\u7684\u8fd0\u884c\u72b6\u6001\uff0cTensorBoard\u4f1a\u81ea\u52a8\u8bfb\u53d6\u6700\u65b0\u7684TensorFlow\u65e5\u5fd7\u6587\u4ef6\uff0c\u5e76\u5448\u73b0\u5f53\u524dTensorFlow\u7a0b\u5e8f\u8fd0\u884c\u7684\u6700\u65b0\u72b6\u6001\u3002\n\n\nimport tensorflow as tf\n\ninput1 = tf.constant([1.,2.,3.0],name='input1')\ninput2 = tf.Variable(tf.random_uniform([3]),name='input2')\n\noutput = tf.add_n([input1,input2],name='add')\n\n#\u751f\u6210\u4e00\u4e2a\u65e5\u5fd7\u7684writer,\u5e76\u5c06\u5f53\u524d\u7684TensoFlow\u8ba1\u7b97\u56fe\u5199\u5165\u65e5\u5fd7\uff0cTF\u63d0\u4f9b\u4e86\u591a\u79cd\u4e9b\u65e5\u5fd7\u6587\u4ef6\u7684API\n\nwriter = tf.summary.FileWriter('path/log',tf.get_default_graph())\nwriter.close()\n\n\n\n\n\u5728\u7ec8\u7aef\u4e2d\u8fd0\u884c\ntensorboard --logdir=path/log\n\u9ed8\u8ba4\u7aef\u53e3\u53f7\u4e3a6006\uff0c\u5728\u6d4f\u89c8\u5668\u4e2d\u8f93\u5165localhost:6006,\u4f1a\u770b\u5230\u5982\u4e0b\u7ed3\u679c\n\n\n\n\n\u56fe1\uff1a\u4f7f\u7528TensorBoard\u53ef\u89c6\u5316\u5411\u91cf\u76f8\u52a0\u7a0b\u5e8fTensorFlow\u8ba1\u7b97\u56fe\u7ed3\u679c\n\n\n\u53ef\u4ee5\u770b\u5230\u754c\u9762\u4e0a\u65b9\u6709SCALARS, IMAGES, AUDIO, GRAPHS, DISTRIBUTIONS, HISTOGRAMS, EMBEDDINGS, TEXT\uff0cTensorBoard \u4e2d\u6bcf\u4e00\u680f\u90fd\u5bf9\u5e94\u4e86\u4e00\u7c7b\u4fe1\u606f\u7684\u53ef\u89c6\u5316\u7ed3\u679c\uff0c\u540e\u8fb9\u4f1a\u8bb2\u6bcf\u4e00\u90e8\u5206\u7684\u529f\u80fd\u3002\n\n\n\n\n2. TensorFlow\u8ba1\u7b97\u56fe\u53ef\u89c6\u5316\n\n\nTensorBoard\u53ef\u89c6\u5316\u5f97\u5230\u7684\u56fe\u5e76\u4e0d\u4ec5\u662f\u5c06TensorFlow\u8ba1\u7b97\u56fe\u4e2d\u7684\u8282\u70b9\u548c\u8fb9\u76f4\u63a5\u53ef\u89c6\u5316\uff0c\u5b83\u4f1a\u6839\u636e\u6bcf\u4e2aTensorFlow\u8ba1\u7b97\u8282\u70b9\u7684\u547d\u540d\u7a7a\u95f4\u6765\u6574\u7406\u53ef\u89c6\u5316\u5f97\u5230\u7684\u6548\u679c\u56fe\uff0c\u4f7f\u5f97\u795e\u7ecf\u7f51\u7edc\u7684\u6574\u4f53\u7ed3\u6784\u4e0d\u4f1a\u88ab\u8fc7\u591a\u7684\u7ec6\u8282\u6240\u6df9\u6ca1\u3002\n\n\n\n\n\u547d\u540d\u7a7a\u95f4\u4e0eTensorBoard\u56fe\u4e0a\u8282\u70b9\n\n\n\n\nTensorFlow\u8ba1\u7b97\u56fe\u4e2d\u540c\u4e00\u4e2a\u547d\u540d\u7a7a\u95f4\u4e0b\u7684\u6240\u6709\u8282\u70b9\u4f1a\u88ab\u7f29\u7565\u6210\u4e00\u4e2a\u8282\u70b9\uff0c\u53ea\u6709\u9876\u5c42\u7684\u547d\u540d\u7a7a\u95f4\u4e2d\u7684\u8282\u70b9\u624d\u4f1a\u88ab\u663e\u793a\u5728tensorBoard\u53ef\u89c6\u5316\u6548\u679c\u56fe\u4e0a\u3002\n\n\nimport tensorflow as tf \n\nwith tf.name_scope('input1'):\n    input1 = tf.constant([1.,2.,3.],name='input1')\n\nwith tf.name_scope('input2'):\n    input2 = tf.Variable(tf.random_uniform([3]),name='input2')\noutput = tf.add_n([input1,input2],name='add')\n\nwriter = tf.summary.FileWriter('log1',tf.get_default_graph())\nwriter.close()\n\n\n\n\ntensoboard --logdir=path/log\n,\u5bf9\u6bd4\u4e0e\u56fe1\u7684\u533a\u522b\n\n\n\n\n\u56fe2\uff1a\u6539\u8fdb\u540e\u7684\u52a0\u6cd5\u7a0b\u5e8fTensorFlow\u8ba1\u7b97\u56fe\u4e0a\u7684\u53ef\u89c6\u5316\u6548\u679c\u56fe\n\n\n\n\n\u8282\u70b9\u4fe1\u606f\n\n\n\n\nTensorBoard\u53ef\u4ee5\u5c55\u793aTensorFlow\u8ba1\u7b97\u56fe\u4e0a\u6bcf\u4e2a\u8282\u70b9\u7684\u57fa\u672c\u4fe1\u606f\u4ee5\u53ca\u8fd0\u884c\u65f6\u6d88\u8017\u7684\u65f6\u95f4\u548c\u7a7a\u95f4\u3002\n\n\nwith tf.Session() as sess:\n    tf.global_variable_initializer().run()\n    for i in range(TRANING_STEPS):\n        xs,ys = mnist.train.next_batch(BATCH_SIZE)\n\n        for i % 1000 ==0\uff1a\n            #\u914d\u7f6e\u8fd0\u884c\u65f6\u6240\u9700\u8981\u8bb0\u5f55\u7684\u4fe1\u606f\n            run_options = tf.RunOptions(trace_level = tf.RunOptions.FULL_TRACE)\n            #\u8fd0\u884c\u65f6\u8bb0\u5f55\u8fd0\u884c\u4fe1\u606f\u7684proto\n            run_metadata = tf,RubMetadata()\n            #\u5c06\u914d\u7f6e\u4fe1\u606f\u4e0e\u8bb0\u5f55\u8fd0\u884c\u4fe1\u606f\u7684proto\u4f20\u5165\u8fd0\u884c\u7684\u8fc7\u7a0b\uff0c\u4ece\u800c\u8bb0\u5f55\u8fd0\u884c\u65f6\u6bcf\u4e00\u4e2a\u8282\u70b9\u7684\u65f6\u95f4\uff0c\u7a7a\u95f4\u5f00\u9500\u4fe1\u606f\n\n            _,loss_value,step = sess.run([train_op,loss,global_step],feed_dict={x:xs,y:ys},options = run_options,run_metadata=run_metadata)\n            #\u5c06\u8282\u70b9\u5728\u8fd0\u884c\u65f6\u7684\u4fe1\u606f\u5199\u5165\u65e5\u5fd7\u6587\u4ef6\n            train_writer.add_run_metadata(run_metadata,'steps%03d' % i)\n            print('After %d training step(s), loss on training batch is %g. ' % (step,loss_value))\n\n        else:\n            _,loss_value,step = sess.run([train_op,loss,global_step],feed_dict={x:xs,y:ys})\n\n\n\n\n\n\n\n3. \u76d1\u63a7\u6307\u6807\u53ef\u89c6\u5316\n\n\n\u4e0a\u9762\u4e3b\u8981\u662f\u901a\u8fc7TensorBoard\u7684GRAPHS\u680f\u53ef\u89c6\u5316TensorFlow\u8ba1\u7b97\u56fe\u7684\u7ed3\u6784\u4ee5\u53ca\u5728\u8ba1\u7b97\u56fe\u4e0a\u7684\u4fe1\u606f\uff0cTensorBoard\u9664\u4e86\u53ef\u4ee5\u53ef\u89c6\u5316TensorFlow\u7684\u8ba1\u7b97\u56fe\uff0c\u8fd8\u53ef\u4ee5\u53ef\u89c6\u5316TensorFlow\u7a0b\u5e8f\u8fd0\u884c\u8fc7\u7a0b\u7684\u5404\u79cd\u6709\u52a9\u4e8e\u4e86\u89e3\u7a0b\u5e8f\u8fd0\u884c\u72b6\u6001\u7684\u76d1\u6d4b\u6307\u6807\u3002\n\n\nimport tensorflow as tf\n\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nSUMMARY_DIR='LOG'\nBATCH_SIZE = 100\nTRAIN_STEPS = 30000\n\n#\u751f\u6210\u53d8\u91cf\u76d1\u63a7\u4fe1\u606f\uff0c\u5e76\u5b9a\u4e49\u6210\u76d1\u63a7\u4fe1\u606f\u65e5\u5fd7\u7684\u64cd\u4f5c\u3002\u5176\u4e2dvar\u7ed9\u51fa\u4e86\u9700\u8981\u8bb0\u5f55\u7684\u5f20\u91cf\uff0cname\u7ed9\u51fa\u4e86\u53ef\u89c6\u5316\u7ed3\u679c\u4e2d\u663e\u793a\u7684\u56fe\u6807\u540d\u79f0\uff0c\u8fd9\u4e2a\u540d\u79f0\u4e00\u822c\u4e0e\u53d8\u91cf\u540d\u79f0\u4e00\u81f4\u2018\n\ndef variable_summaries(var,name):\n    with tf.name_scope('summaries'):\n        tf.summary.histogram(name,var)\n        mean = tf.reduce_mean(var)\n        tf.summary.scalar('mean/'+name,mean)\n        stddev = tf.sqrt(tf.reduce_mean(tf.square(var-mean)))\n        tf.summary.scalar('steddev/'+name,stddev)\n\n#\u751f\u6210\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\u7684\u795e\u7ecf\u7f51\u7edc\n\ndef nn_layer(input_tensor,input_dim,output_dim,layer_name,act = tf.nn.relu):\n    with tf.name_scope(layer_name):\n        with tf.name_scope('weights'):\n            weights = tf.Variable(tf.truncated_normal([input_dim,output_dim],stddev=0.1))\n            variable_summaries(weights,layer_name+'/weights')\n        with tf.name_scope('biases'):\n            biases = tf.Variable(tf.constant(0.0,shape=[output_dim]))\n            variable_summaries(biases,layer_name+'/biases')\n\n        with tf.name_scope('Wx_plus_b'):\n            preactivate = tf.matmul(input_tensor,weights) + biases\n            tf.summary.histogram(layer_name+'preactivations',preactivate)\n        activations = act(preactivate,name='activation')\n        tf.summary.histogram(layer_name+'/activations',activations)\n        return activations\n\n\ndef main(_):\n    mnists = input_data.read_data_sets('data',one_hot = True)\n\n    with tf.name_scope('input'):\n        x = tf.placeholder(tf.float32,[None,784],name='x-input')\n        y_ = tf.placeholder(tf.float32,[None,10],name='y-input')\n\n    with tf.name_scope('input_reshape'):\n        image_shape_input = tf.reshape(x,[-1,28,28,1])\n        tf.summary.image('input',image_shape_input,10)\n\n    hidden1 = nn_layer(x,784,500,'layer1')\n    y = nn_layer(hidden1,500,10,'layer2',act = tf.identity)\n\n    with tf.name_scope('cross_entropy'):\n        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y,logits = y_))\n        tf.summary.scalar('cross entropy',cross_entropy)\n    with tf.name_scope('train'):\n        train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n\n    with tf.name_scope('accuracy'):\n        with tf.name_scope('correct_prediction'):\n            correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n        with tf.name_scope('accuracy'):\n            accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n\n        tf.summary.scalar('accuracy',accuracy)\n    #\u7a0b\u5e8f\u4e2d\u5b9a\u4e49\u7684\u5199\u65e5\u5fd7\u7684\u6587\u4ef6\u6bd4\u4ef7\u591a\uff0c\u4e00\u4e00\u8c03\u7528\u6bd4\u8f83\u9ebb\u70e6\uff0c\u6240\u4ee5\u63d0\u4f9b\u4e86tf.summary.merge_all\u51fd\u6570\u6765\u6574\u7406\u6240\u6709\u7684\u65e5\u5fd7\u751f\u6210\u64cd\u4f5c\u3002\n\n    merged = tf.summary.merge_all()\n\n    with tf.Session() as sess:\n        summary_writer = tf.summary.FileWriter(SUMMARY_DIR,sess.graph)\n        tf.global_variable_initializers().run()\n\n        for i in range(TRAIN_STEPS):\n            xs,ys = mnist.train.next_batch(BATCH_SIZE)\n            #\u8fd0\u884c\u8bad\u7ec3\u6b65\u9aa4\u4ee5\u53ca\u6240\u6709\u7684\u65e5\u5fd7\u751f\u6210\u64cd\u4f5c\uff0c\u5f97\u5230\u8fd9\u6b21\u64cd\u4f5c\u7684\u65e5\u5fd7\n            summary,_ = sess.run([merged,train_step],feed_dict = {x:xs,y:ys})\n            #\u5c06\u65e5\u5fd7\u5199\u5165\u6587\u4ef6\uff0cTB\u53ef\u4ee5\u62ff\u5230\u8fd9\u6b21\u8fd0\u884c\u6240\u6709\u7684\u8fd0\u884c\u4fe1\u606f\n\n            summary_writer.add_summary(summary,i)\n        summary_writer.close()\n\n\n\n\n\n\n4. \u4e3e\u4e2a\u6817\u5b50\n\n\n# -*- coding: utf-8 -*-\n\nimport os\nimport io\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n# \u521d\u59cb\u5316\u56fe\uff0c\u4f1a\u8bdd\nsess = tf.Session()\n\n# \u521b\u5efa\u65e5\u5fd7\u6587\u4ef6\nsummary_writer = tf.summary.FileWriter('tensorboard', tf.get_default_graph())\n\n# \u521b\u5efatensorboard\u6587\u4ef6\u5939\uff0c\u5b9e\u9645\u6ca1\u5fc5\u8981\nif not os.path.exists('tensorboard'):\n    os.makedirs('tensorboard')\nprint('Running a slowed down linear regression. '\n      'Run the command: $tensorboard --logdir=\"tensorboard\"  '\n      ' Then navigate to http://127.0.0.0:6006')\n\n# You can also specify a port option with --port 6006\n\n# Wait a few seconds for user to run tensorboard commands\ntime.sleep(3)\n\n# \u53c2\u6570\u8bbe\u7f6e\nbatch_size = 50\ngenerations = 100\n\n# \u8f93\u5165\u6570\u636e\nx_data = np.arange(1000)/10.\ntrue_slope = 2.\ny_data = x_data * true_slope + np.random.normal(loc=0.0, scale=25, size=1000)\n\n# \u6362\u5206\u8bad\u7ec3/\u6d4b\u8bd5\u6570\u636e\u96c6\ntrain_ix = np.random.choice(len(x_data), size=int(len(x_data)*0.9), replace=False)\ntest_ix = np.setdiff1d(np.arange(1000), train_ix)\nx_data_train, y_data_train = x_data[train_ix], y_data[train_ix]\nx_data_test, y_data_test = x_data[test_ix], y_data[test_ix]\n\n# \u58f0\u660e placeholders\nx_graph_input = tf.placeholder(tf.float32, [None])\ny_graph_input = tf.placeholder(tf.float32, [None])\n\n# \u58f0\u660e\u6a21\u578b\u53d8\u91cf\nm = tf.Variable(tf.random_normal([1], dtype=tf.float32), name='Slope')\n\n# \u58f0\u660e\u6a21\u578b\noutput = tf.multiply(m, x_graph_input, name='Batch_Multiplication')\n\n# \u58f0\u660e\u635f\u5931\u51fd\u6570(L1)\nresiduals = output - y_graph_input\nl1_loss = tf.reduce_mean(tf.abs(residuals), name=\"L1_Loss\")\n\n# \u58f0\u660e\u6700\u4f18\u5316\u65b9\u6848\nmy_optim = tf.train.GradientDescentOptimizer(0.01)\ntrain_step = my_optim.minimize(l1_loss)\n\n# \u53ef\u89c6\u5316scalar\uff08\u6807\u91cf\u53ef\u89c6\u5316\uff09\nwith tf.name_scope('Slope_Estimate'):\n    tf.summary.scalar('Slope_Estimate', tf.squeeze(m))\n\n# \u53ef\u89c6\u5316 histogram (errors)\uff08\u53ef\u89c6\u5316\u53c2\u6570\u7684\u5206\u5e03\uff09\nwith tf.name_scope('Loss_and_Residuals'):\n    tf.summary.histogram('Histogram_Errors', l1_loss)\n    tf.summary.histogram('Histogram_Residuals', residuals)\n\n\n\n# \u5408\u5e76\u6240\u6709\u7684\u8fd0\u884c\u65e5\u5fd7\nsummary_op = tf.summary.merge_all()\n\n# \u521d\u59cb\u5316\u53d8\u91cf\ninit = tf.global_variables_initializer()\nsess.run(init)\n\nfor i in range(generations):\n    batch_indices = np.random.choice(len(x_data_train), size=batch_size)\n    x_batch = x_data_train[batch_indices]\n    y_batch = y_data_train[batch_indices]\n    _, train_loss, summary = sess.run([train_step, l1_loss, summary_op],\n                             feed_dict={x_graph_input: x_batch,\n                                        y_graph_input: y_batch})\n\n    test_loss, test_resids = sess.run([l1_loss, residuals], feed_dict={x_graph_input: x_data_test,\n                                                                       y_graph_input: y_data_test})\n\n    if (i+1)%10==0:\n        print('Generation {} of {}. Train Loss: {:.3}, Test Loss: {:.3}.'.format(i+1, generations, train_loss, test_loss))\n\n    log_writer = tf.summary.FileWriter('tensorboard')\n    log_writer.add_summary(summary, i)\n    time.sleep(0.5)\n\n#\u5b9a\u4e49\u4e00\u4e2a\u51fd\u6570\u6765\u4fdd\u5b58 protobuf bytes \u7248\u672c\u7684\u56fe\u50cf\ndef gen_linear_plot(slope):\n    linear_prediction = x_data * slope\n    plt.plot(x_data, y_data, 'b.', label='data')\n    plt.plot(x_data, linear_prediction, 'r-', linewidth=3, label='predicted line')\n    plt.legend(loc='upper left')\n    buf = io.BytesIO()\n    plt.savefig(buf, format='png')\n    buf.seek(0)\n    return(buf)\n\n# \u5728\u65e5\u5fd7\u4e2d\u6dfb\u52a0\u56fe (plot the linear fit!)\nslope = sess.run(m)\nplot_buf = gen_linear_plot(slope[0])\n# Convert PNG buffer to TF image\nimage = tf.image.decode_png(plot_buf.getvalue(), channels=4)\n# Add the batch dimension\nimage = tf.expand_dims(image, 0)\n# Add image summary\nimage_summary_op = tf.summary.image(\"Linear Plot\", image)\nimage_summary = sess.run(image_summary_op)\nlog_writer.add_summary(image_summary, i)\nlog_writer.close()\n\n\n\n\n\u8fd0\u884c\u7ed3\u679c\u793a\u610f\u56fe\n\n\n\n\n\u56fe3\uff1ascalar\n\n\n\n\n\u56fe4\uff1aimages\n\n\n\n\n\u56fe5\uff1adistribution\n\n\n\n\n\u56fe6\uff1ahistogram",
            "title": "TensorBoard\u53ef\u89c6\u5316"
        },
        {
            "location": "/chapter9/#tensorboard",
            "text": "\u4e3a\u4e86\u66f4\u597d\u7684\u8bad\u7ec3\u548c\u4f18\u5316\u6a21\u578b\uff0cTensorFlow\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u89c6\u5316\u5de5\u5177TensorBoard\u3002TensorFlow\u53ef\u4ee5\u6709\u6548\u7684\u5c55\u793aTensorFlow\u5728\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u7684\u8ba1\u7b97\u56fe\uff0c\u5404\u79cd\u6307\u6807\u968f\u7740\u65f6\u95f4\u7684\u53d8\u5316\u8d8b\u52bf\u4ee5\u53ca\u8bad\u7ec3\u4e2d\u4f7f\u7528\u5230\u7684\u56fe\u50cf\u4fe1\u606f\u7b49\u3002  1.TensorBoard\u7b80\u4ecb  TensorBoard\u662fTensorFlow\u7684\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u5b83\u53ef\u4ee5\u901a\u8fc7TensorFlow\u7a0b\u5e8f\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u8f93\u51fa\u7684\u65e5\u5fd7\u6587\u4ef6\u53ef\u89c6\u5316TensorFlow\u7a0b\u5e8f\u7684\u8fd0\u884c\u72b6\u6001\uff0cTensorBoard\u4f1a\u81ea\u52a8\u8bfb\u53d6\u6700\u65b0\u7684TensorFlow\u65e5\u5fd7\u6587\u4ef6\uff0c\u5e76\u5448\u73b0\u5f53\u524dTensorFlow\u7a0b\u5e8f\u8fd0\u884c\u7684\u6700\u65b0\u72b6\u6001\u3002  import tensorflow as tf\n\ninput1 = tf.constant([1.,2.,3.0],name='input1')\ninput2 = tf.Variable(tf.random_uniform([3]),name='input2')\n\noutput = tf.add_n([input1,input2],name='add')\n\n#\u751f\u6210\u4e00\u4e2a\u65e5\u5fd7\u7684writer,\u5e76\u5c06\u5f53\u524d\u7684TensoFlow\u8ba1\u7b97\u56fe\u5199\u5165\u65e5\u5fd7\uff0cTF\u63d0\u4f9b\u4e86\u591a\u79cd\u4e9b\u65e5\u5fd7\u6587\u4ef6\u7684API\n\nwriter = tf.summary.FileWriter('path/log',tf.get_default_graph())\nwriter.close()  \u5728\u7ec8\u7aef\u4e2d\u8fd0\u884c tensorboard --logdir=path/log \u9ed8\u8ba4\u7aef\u53e3\u53f7\u4e3a6006\uff0c\u5728\u6d4f\u89c8\u5668\u4e2d\u8f93\u5165localhost:6006,\u4f1a\u770b\u5230\u5982\u4e0b\u7ed3\u679c   \u56fe1\uff1a\u4f7f\u7528TensorBoard\u53ef\u89c6\u5316\u5411\u91cf\u76f8\u52a0\u7a0b\u5e8fTensorFlow\u8ba1\u7b97\u56fe\u7ed3\u679c  \u53ef\u4ee5\u770b\u5230\u754c\u9762\u4e0a\u65b9\u6709SCALARS, IMAGES, AUDIO, GRAPHS, DISTRIBUTIONS, HISTOGRAMS, EMBEDDINGS, TEXT\uff0cTensorBoard \u4e2d\u6bcf\u4e00\u680f\u90fd\u5bf9\u5e94\u4e86\u4e00\u7c7b\u4fe1\u606f\u7684\u53ef\u89c6\u5316\u7ed3\u679c\uff0c\u540e\u8fb9\u4f1a\u8bb2\u6bcf\u4e00\u90e8\u5206\u7684\u529f\u80fd\u3002   2. TensorFlow\u8ba1\u7b97\u56fe\u53ef\u89c6\u5316  TensorBoard\u53ef\u89c6\u5316\u5f97\u5230\u7684\u56fe\u5e76\u4e0d\u4ec5\u662f\u5c06TensorFlow\u8ba1\u7b97\u56fe\u4e2d\u7684\u8282\u70b9\u548c\u8fb9\u76f4\u63a5\u53ef\u89c6\u5316\uff0c\u5b83\u4f1a\u6839\u636e\u6bcf\u4e2aTensorFlow\u8ba1\u7b97\u8282\u70b9\u7684\u547d\u540d\u7a7a\u95f4\u6765\u6574\u7406\u53ef\u89c6\u5316\u5f97\u5230\u7684\u6548\u679c\u56fe\uff0c\u4f7f\u5f97\u795e\u7ecf\u7f51\u7edc\u7684\u6574\u4f53\u7ed3\u6784\u4e0d\u4f1a\u88ab\u8fc7\u591a\u7684\u7ec6\u8282\u6240\u6df9\u6ca1\u3002   \u547d\u540d\u7a7a\u95f4\u4e0eTensorBoard\u56fe\u4e0a\u8282\u70b9   TensorFlow\u8ba1\u7b97\u56fe\u4e2d\u540c\u4e00\u4e2a\u547d\u540d\u7a7a\u95f4\u4e0b\u7684\u6240\u6709\u8282\u70b9\u4f1a\u88ab\u7f29\u7565\u6210\u4e00\u4e2a\u8282\u70b9\uff0c\u53ea\u6709\u9876\u5c42\u7684\u547d\u540d\u7a7a\u95f4\u4e2d\u7684\u8282\u70b9\u624d\u4f1a\u88ab\u663e\u793a\u5728tensorBoard\u53ef\u89c6\u5316\u6548\u679c\u56fe\u4e0a\u3002  import tensorflow as tf \n\nwith tf.name_scope('input1'):\n    input1 = tf.constant([1.,2.,3.],name='input1')\n\nwith tf.name_scope('input2'):\n    input2 = tf.Variable(tf.random_uniform([3]),name='input2')\noutput = tf.add_n([input1,input2],name='add')\n\nwriter = tf.summary.FileWriter('log1',tf.get_default_graph())\nwriter.close()  tensoboard --logdir=path/log ,\u5bf9\u6bd4\u4e0e\u56fe1\u7684\u533a\u522b   \u56fe2\uff1a\u6539\u8fdb\u540e\u7684\u52a0\u6cd5\u7a0b\u5e8fTensorFlow\u8ba1\u7b97\u56fe\u4e0a\u7684\u53ef\u89c6\u5316\u6548\u679c\u56fe   \u8282\u70b9\u4fe1\u606f   TensorBoard\u53ef\u4ee5\u5c55\u793aTensorFlow\u8ba1\u7b97\u56fe\u4e0a\u6bcf\u4e2a\u8282\u70b9\u7684\u57fa\u672c\u4fe1\u606f\u4ee5\u53ca\u8fd0\u884c\u65f6\u6d88\u8017\u7684\u65f6\u95f4\u548c\u7a7a\u95f4\u3002  with tf.Session() as sess:\n    tf.global_variable_initializer().run()\n    for i in range(TRANING_STEPS):\n        xs,ys = mnist.train.next_batch(BATCH_SIZE)\n\n        for i % 1000 ==0\uff1a\n            #\u914d\u7f6e\u8fd0\u884c\u65f6\u6240\u9700\u8981\u8bb0\u5f55\u7684\u4fe1\u606f\n            run_options = tf.RunOptions(trace_level = tf.RunOptions.FULL_TRACE)\n            #\u8fd0\u884c\u65f6\u8bb0\u5f55\u8fd0\u884c\u4fe1\u606f\u7684proto\n            run_metadata = tf,RubMetadata()\n            #\u5c06\u914d\u7f6e\u4fe1\u606f\u4e0e\u8bb0\u5f55\u8fd0\u884c\u4fe1\u606f\u7684proto\u4f20\u5165\u8fd0\u884c\u7684\u8fc7\u7a0b\uff0c\u4ece\u800c\u8bb0\u5f55\u8fd0\u884c\u65f6\u6bcf\u4e00\u4e2a\u8282\u70b9\u7684\u65f6\u95f4\uff0c\u7a7a\u95f4\u5f00\u9500\u4fe1\u606f\n\n            _,loss_value,step = sess.run([train_op,loss,global_step],feed_dict={x:xs,y:ys},options = run_options,run_metadata=run_metadata)\n            #\u5c06\u8282\u70b9\u5728\u8fd0\u884c\u65f6\u7684\u4fe1\u606f\u5199\u5165\u65e5\u5fd7\u6587\u4ef6\n            train_writer.add_run_metadata(run_metadata,'steps%03d' % i)\n            print('After %d training step(s), loss on training batch is %g. ' % (step,loss_value))\n\n        else:\n            _,loss_value,step = sess.run([train_op,loss,global_step],feed_dict={x:xs,y:ys})   3. \u76d1\u63a7\u6307\u6807\u53ef\u89c6\u5316  \u4e0a\u9762\u4e3b\u8981\u662f\u901a\u8fc7TensorBoard\u7684GRAPHS\u680f\u53ef\u89c6\u5316TensorFlow\u8ba1\u7b97\u56fe\u7684\u7ed3\u6784\u4ee5\u53ca\u5728\u8ba1\u7b97\u56fe\u4e0a\u7684\u4fe1\u606f\uff0cTensorBoard\u9664\u4e86\u53ef\u4ee5\u53ef\u89c6\u5316TensorFlow\u7684\u8ba1\u7b97\u56fe\uff0c\u8fd8\u53ef\u4ee5\u53ef\u89c6\u5316TensorFlow\u7a0b\u5e8f\u8fd0\u884c\u8fc7\u7a0b\u7684\u5404\u79cd\u6709\u52a9\u4e8e\u4e86\u89e3\u7a0b\u5e8f\u8fd0\u884c\u72b6\u6001\u7684\u76d1\u6d4b\u6307\u6807\u3002  import tensorflow as tf\n\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nSUMMARY_DIR='LOG'\nBATCH_SIZE = 100\nTRAIN_STEPS = 30000\n\n#\u751f\u6210\u53d8\u91cf\u76d1\u63a7\u4fe1\u606f\uff0c\u5e76\u5b9a\u4e49\u6210\u76d1\u63a7\u4fe1\u606f\u65e5\u5fd7\u7684\u64cd\u4f5c\u3002\u5176\u4e2dvar\u7ed9\u51fa\u4e86\u9700\u8981\u8bb0\u5f55\u7684\u5f20\u91cf\uff0cname\u7ed9\u51fa\u4e86\u53ef\u89c6\u5316\u7ed3\u679c\u4e2d\u663e\u793a\u7684\u56fe\u6807\u540d\u79f0\uff0c\u8fd9\u4e2a\u540d\u79f0\u4e00\u822c\u4e0e\u53d8\u91cf\u540d\u79f0\u4e00\u81f4\u2018\n\ndef variable_summaries(var,name):\n    with tf.name_scope('summaries'):\n        tf.summary.histogram(name,var)\n        mean = tf.reduce_mean(var)\n        tf.summary.scalar('mean/'+name,mean)\n        stddev = tf.sqrt(tf.reduce_mean(tf.square(var-mean)))\n        tf.summary.scalar('steddev/'+name,stddev)\n\n#\u751f\u6210\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\u7684\u795e\u7ecf\u7f51\u7edc\n\ndef nn_layer(input_tensor,input_dim,output_dim,layer_name,act = tf.nn.relu):\n    with tf.name_scope(layer_name):\n        with tf.name_scope('weights'):\n            weights = tf.Variable(tf.truncated_normal([input_dim,output_dim],stddev=0.1))\n            variable_summaries(weights,layer_name+'/weights')\n        with tf.name_scope('biases'):\n            biases = tf.Variable(tf.constant(0.0,shape=[output_dim]))\n            variable_summaries(biases,layer_name+'/biases')\n\n        with tf.name_scope('Wx_plus_b'):\n            preactivate = tf.matmul(input_tensor,weights) + biases\n            tf.summary.histogram(layer_name+'preactivations',preactivate)\n        activations = act(preactivate,name='activation')\n        tf.summary.histogram(layer_name+'/activations',activations)\n        return activations\n\n\ndef main(_):\n    mnists = input_data.read_data_sets('data',one_hot = True)\n\n    with tf.name_scope('input'):\n        x = tf.placeholder(tf.float32,[None,784],name='x-input')\n        y_ = tf.placeholder(tf.float32,[None,10],name='y-input')\n\n    with tf.name_scope('input_reshape'):\n        image_shape_input = tf.reshape(x,[-1,28,28,1])\n        tf.summary.image('input',image_shape_input,10)\n\n    hidden1 = nn_layer(x,784,500,'layer1')\n    y = nn_layer(hidden1,500,10,'layer2',act = tf.identity)\n\n    with tf.name_scope('cross_entropy'):\n        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y,logits = y_))\n        tf.summary.scalar('cross entropy',cross_entropy)\n    with tf.name_scope('train'):\n        train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n\n    with tf.name_scope('accuracy'):\n        with tf.name_scope('correct_prediction'):\n            correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n        with tf.name_scope('accuracy'):\n            accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n\n        tf.summary.scalar('accuracy',accuracy)\n    #\u7a0b\u5e8f\u4e2d\u5b9a\u4e49\u7684\u5199\u65e5\u5fd7\u7684\u6587\u4ef6\u6bd4\u4ef7\u591a\uff0c\u4e00\u4e00\u8c03\u7528\u6bd4\u8f83\u9ebb\u70e6\uff0c\u6240\u4ee5\u63d0\u4f9b\u4e86tf.summary.merge_all\u51fd\u6570\u6765\u6574\u7406\u6240\u6709\u7684\u65e5\u5fd7\u751f\u6210\u64cd\u4f5c\u3002\n\n    merged = tf.summary.merge_all()\n\n    with tf.Session() as sess:\n        summary_writer = tf.summary.FileWriter(SUMMARY_DIR,sess.graph)\n        tf.global_variable_initializers().run()\n\n        for i in range(TRAIN_STEPS):\n            xs,ys = mnist.train.next_batch(BATCH_SIZE)\n            #\u8fd0\u884c\u8bad\u7ec3\u6b65\u9aa4\u4ee5\u53ca\u6240\u6709\u7684\u65e5\u5fd7\u751f\u6210\u64cd\u4f5c\uff0c\u5f97\u5230\u8fd9\u6b21\u64cd\u4f5c\u7684\u65e5\u5fd7\n            summary,_ = sess.run([merged,train_step],feed_dict = {x:xs,y:ys})\n            #\u5c06\u65e5\u5fd7\u5199\u5165\u6587\u4ef6\uff0cTB\u53ef\u4ee5\u62ff\u5230\u8fd9\u6b21\u8fd0\u884c\u6240\u6709\u7684\u8fd0\u884c\u4fe1\u606f\n\n            summary_writer.add_summary(summary,i)\n        summary_writer.close()  4. \u4e3e\u4e2a\u6817\u5b50  # -*- coding: utf-8 -*-\n\nimport os\nimport io\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n# \u521d\u59cb\u5316\u56fe\uff0c\u4f1a\u8bdd\nsess = tf.Session()\n\n# \u521b\u5efa\u65e5\u5fd7\u6587\u4ef6\nsummary_writer = tf.summary.FileWriter('tensorboard', tf.get_default_graph())\n\n# \u521b\u5efatensorboard\u6587\u4ef6\u5939\uff0c\u5b9e\u9645\u6ca1\u5fc5\u8981\nif not os.path.exists('tensorboard'):\n    os.makedirs('tensorboard')\nprint('Running a slowed down linear regression. '\n      'Run the command: $tensorboard --logdir=\"tensorboard\"  '\n      ' Then navigate to http://127.0.0.0:6006')\n\n# You can also specify a port option with --port 6006\n\n# Wait a few seconds for user to run tensorboard commands\ntime.sleep(3)\n\n# \u53c2\u6570\u8bbe\u7f6e\nbatch_size = 50\ngenerations = 100\n\n# \u8f93\u5165\u6570\u636e\nx_data = np.arange(1000)/10.\ntrue_slope = 2.\ny_data = x_data * true_slope + np.random.normal(loc=0.0, scale=25, size=1000)\n\n# \u6362\u5206\u8bad\u7ec3/\u6d4b\u8bd5\u6570\u636e\u96c6\ntrain_ix = np.random.choice(len(x_data), size=int(len(x_data)*0.9), replace=False)\ntest_ix = np.setdiff1d(np.arange(1000), train_ix)\nx_data_train, y_data_train = x_data[train_ix], y_data[train_ix]\nx_data_test, y_data_test = x_data[test_ix], y_data[test_ix]\n\n# \u58f0\u660e placeholders\nx_graph_input = tf.placeholder(tf.float32, [None])\ny_graph_input = tf.placeholder(tf.float32, [None])\n\n# \u58f0\u660e\u6a21\u578b\u53d8\u91cf\nm = tf.Variable(tf.random_normal([1], dtype=tf.float32), name='Slope')\n\n# \u58f0\u660e\u6a21\u578b\noutput = tf.multiply(m, x_graph_input, name='Batch_Multiplication')\n\n# \u58f0\u660e\u635f\u5931\u51fd\u6570(L1)\nresiduals = output - y_graph_input\nl1_loss = tf.reduce_mean(tf.abs(residuals), name=\"L1_Loss\")\n\n# \u58f0\u660e\u6700\u4f18\u5316\u65b9\u6848\nmy_optim = tf.train.GradientDescentOptimizer(0.01)\ntrain_step = my_optim.minimize(l1_loss)\n\n# \u53ef\u89c6\u5316scalar\uff08\u6807\u91cf\u53ef\u89c6\u5316\uff09\nwith tf.name_scope('Slope_Estimate'):\n    tf.summary.scalar('Slope_Estimate', tf.squeeze(m))\n\n# \u53ef\u89c6\u5316 histogram (errors)\uff08\u53ef\u89c6\u5316\u53c2\u6570\u7684\u5206\u5e03\uff09\nwith tf.name_scope('Loss_and_Residuals'):\n    tf.summary.histogram('Histogram_Errors', l1_loss)\n    tf.summary.histogram('Histogram_Residuals', residuals)\n\n\n\n# \u5408\u5e76\u6240\u6709\u7684\u8fd0\u884c\u65e5\u5fd7\nsummary_op = tf.summary.merge_all()\n\n# \u521d\u59cb\u5316\u53d8\u91cf\ninit = tf.global_variables_initializer()\nsess.run(init)\n\nfor i in range(generations):\n    batch_indices = np.random.choice(len(x_data_train), size=batch_size)\n    x_batch = x_data_train[batch_indices]\n    y_batch = y_data_train[batch_indices]\n    _, train_loss, summary = sess.run([train_step, l1_loss, summary_op],\n                             feed_dict={x_graph_input: x_batch,\n                                        y_graph_input: y_batch})\n\n    test_loss, test_resids = sess.run([l1_loss, residuals], feed_dict={x_graph_input: x_data_test,\n                                                                       y_graph_input: y_data_test})\n\n    if (i+1)%10==0:\n        print('Generation {} of {}. Train Loss: {:.3}, Test Loss: {:.3}.'.format(i+1, generations, train_loss, test_loss))\n\n    log_writer = tf.summary.FileWriter('tensorboard')\n    log_writer.add_summary(summary, i)\n    time.sleep(0.5)\n\n#\u5b9a\u4e49\u4e00\u4e2a\u51fd\u6570\u6765\u4fdd\u5b58 protobuf bytes \u7248\u672c\u7684\u56fe\u50cf\ndef gen_linear_plot(slope):\n    linear_prediction = x_data * slope\n    plt.plot(x_data, y_data, 'b.', label='data')\n    plt.plot(x_data, linear_prediction, 'r-', linewidth=3, label='predicted line')\n    plt.legend(loc='upper left')\n    buf = io.BytesIO()\n    plt.savefig(buf, format='png')\n    buf.seek(0)\n    return(buf)\n\n# \u5728\u65e5\u5fd7\u4e2d\u6dfb\u52a0\u56fe (plot the linear fit!)\nslope = sess.run(m)\nplot_buf = gen_linear_plot(slope[0])\n# Convert PNG buffer to TF image\nimage = tf.image.decode_png(plot_buf.getvalue(), channels=4)\n# Add the batch dimension\nimage = tf.expand_dims(image, 0)\n# Add image summary\nimage_summary_op = tf.summary.image(\"Linear Plot\", image)\nimage_summary = sess.run(image_summary_op)\nlog_writer.add_summary(image_summary, i)\nlog_writer.close()  \u8fd0\u884c\u7ed3\u679c\u793a\u610f\u56fe   \u56fe3\uff1ascalar   \u56fe4\uff1aimages   \u56fe5\uff1adistribution   \u56fe6\uff1ahistogram",
            "title": "TensorBoard\u53ef\u89c6\u5316"
        },
        {
            "location": "/chapter10/",
            "text": "Reference\n\n\n[1] TensorFlow\u5b9e\u6218google\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6[M]. \u7535\u5b50\u5de5\u4e1a\u51fa\u7248\u793e\uff082017\uff09\n\n\n[2] TensorFlow\u5b98\u65b9\u6587\u6863\u4e2d\u6587\u7248\u5168\u56fd\u9996\u53d1[M]. \u6781\u5ba2\u5b66\u9662\u51fa\u7248(2017)\n\n\n[3] GitHub\u8d44\u6e90(https://github.com/DataXujing/)\u53ca\u5404\u79cd\u7f51\u7edc\u8d44\u6e90\n\n\n[4] http://wiki.jikexueyuan.com/project/tensorflow-zh/api_docs/python/sparse_ops.html#SparseTensor\n\n\n[5] TensorFlow\u4e2d\u6587\u793e\u533a\uff08http://www.tensorfly.cn/\uff09\n\n\n[6] TensorFlow Machine Learning Cookbook[M]\uff082017\uff09\n\n\n[7] TensorFlow\u767d\u76ae\u4e66\n\n\n[8] https://tensorflow.google.cn/(\u4e2d\u95ee\u6587\u6863\u7f51\u7ad9)\n\n\n[9] TensorFlow\u5b9e\u6218[M].(2017\u5e742\u67081\u65e5)\n\n\n\u5173\u4e8eTensorFlow\u7684\u7f51\u7edc\u5b66\u4e60\u8d44\u6e90\u53ca\u4e66\u7c4d\u975e\u5e38\u591a\uff0c\u5efa\u8bae\u4ee51-2\u672c\u53c2\u8003\u4e66\u7c4d\u7ec6\u81f4\u5b66\u4e60\u5e76\u914d\u5408\u7f51\u7edc\u8d44\u6e90\u4e86\u5f00\u9614\u89c6\u91ce\u3002",
            "title": "TensorFlow\u5b66\u4e60\u8d44\u6e90\u63a8\u8350"
        },
        {
            "location": "/about/",
            "text": "\u5728\u54ea\u53ef\u4ee5\u627e\u5230\u6211\n\n\n\n\n\u5173\u4e8ePython, R\uff0c\u7684\u9ad8\u7ea7\u7f16\u7a0b\u53ca\u673a\u5668\u5b66\u4e60\uff0c\u6df1\u5ea6\u5b66\u4e60\u7684\u5b66\u4e60\u5fc3\u5f97\u53ef\u5728\u6211\u7684\u4e2a\u4eba\u4e3b\u9875:https://dataxujing.github.io/\uff0chttps://dataxujing.coding.me/(\u5e1d\u56fd\u56fd\u5185\u5efa\u8bae\u767b\u5f55\u8be5URL)\n\n\n\n\n\n\n\n\n\u6211\u5e73\u65f6\u6d3b\u8dc3\u5728 GitHub: https://github.com/DataXujing/(\u6211\u5927\u90e8\u5206\u7684R\u5305\u53caPython\u6a21\u5757\u4f1a\u6258\u7ba1\u5728Github\uff0c\u76f8\u5173\u95ee\u9898Github\u4e0a\u6709\u5927\u725b\u53ef\u4ee5\u4ea4\u6d41)\n\n\n\n\n\n\n\n\n\u6211\u8fd8\u4f1a\u5728Pypi\u4e0a\u6d3b\u8dc3\uff0c\u6211\u7684Python\u5305\u548c\u6a21\u5757\u4f1a\u6709\u4e00\u4efd\u5728Pypi\u4e0a\uff0c\u53ef\u4ee5\u901a\u8fc7pip install pkgname\u4e0b\u8f7d\u4f7f\u7528\n\n\n\n\n\n\n\n\n\u672c\u8282\u6559\u7a0b\u5df2\u5f00\u6e90\u5728\u7f51\u7edc\uff1ahttps://dataxujing.github.io/tflearn1/\n\n\n\n\n\n\n\n\n\u5c0f\u7f16\u6c34\u5e73\u6709\u9650\uff0c\u5bf9TensorFlow\u7406\u89e3\u4e5f\u4e0d\u662f\u5f88\u6df1\u5165\uff0c\u6587\u6863\u4e2d\u6709\u9519\u8bef\u6216\u4e0d\u5f53\u7684\u5730\u65b9\uff0c\u8bf7\u79fb\u6b65\u5230\n\u6211\u7684TensorFlow\u9879\u76ee\n\u8fdb\u884c\u7559\u8a00\u6307\u6b63\uff0c\u5c0f\u7f16\u5728\u6b64\u4e00\u5e76\u8c22\u8fc7\u3002\n\n\n\n\n\n\n\n\n\u540e\u671f\u4f1a\u6301\u7eed\u66f4\u65b0\u3002\u3002\u3002\u3002\u3002\u3002",
            "title": "\u5173\u4e8e"
        },
        {
            "location": "/about/#_1",
            "text": "\u5173\u4e8ePython, R\uff0c\u7684\u9ad8\u7ea7\u7f16\u7a0b\u53ca\u673a\u5668\u5b66\u4e60\uff0c\u6df1\u5ea6\u5b66\u4e60\u7684\u5b66\u4e60\u5fc3\u5f97\u53ef\u5728\u6211\u7684\u4e2a\u4eba\u4e3b\u9875:https://dataxujing.github.io/\uff0chttps://dataxujing.coding.me/(\u5e1d\u56fd\u56fd\u5185\u5efa\u8bae\u767b\u5f55\u8be5URL)     \u6211\u5e73\u65f6\u6d3b\u8dc3\u5728 GitHub: https://github.com/DataXujing/(\u6211\u5927\u90e8\u5206\u7684R\u5305\u53caPython\u6a21\u5757\u4f1a\u6258\u7ba1\u5728Github\uff0c\u76f8\u5173\u95ee\u9898Github\u4e0a\u6709\u5927\u725b\u53ef\u4ee5\u4ea4\u6d41)     \u6211\u8fd8\u4f1a\u5728Pypi\u4e0a\u6d3b\u8dc3\uff0c\u6211\u7684Python\u5305\u548c\u6a21\u5757\u4f1a\u6709\u4e00\u4efd\u5728Pypi\u4e0a\uff0c\u53ef\u4ee5\u901a\u8fc7pip install pkgname\u4e0b\u8f7d\u4f7f\u7528     \u672c\u8282\u6559\u7a0b\u5df2\u5f00\u6e90\u5728\u7f51\u7edc\uff1ahttps://dataxujing.github.io/tflearn1/     \u5c0f\u7f16\u6c34\u5e73\u6709\u9650\uff0c\u5bf9TensorFlow\u7406\u89e3\u4e5f\u4e0d\u662f\u5f88\u6df1\u5165\uff0c\u6587\u6863\u4e2d\u6709\u9519\u8bef\u6216\u4e0d\u5f53\u7684\u5730\u65b9\uff0c\u8bf7\u79fb\u6b65\u5230 \u6211\u7684TensorFlow\u9879\u76ee \u8fdb\u884c\u7559\u8a00\u6307\u6b63\uff0c\u5c0f\u7f16\u5728\u6b64\u4e00\u5e76\u8c22\u8fc7\u3002     \u540e\u671f\u4f1a\u6301\u7eed\u66f4\u65b0\u3002\u3002\u3002\u3002\u3002\u3002",
            "title": "\u5728\u54ea\u53ef\u4ee5\u627e\u5230\u6211"
        }
    ]
}